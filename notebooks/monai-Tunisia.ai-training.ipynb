{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../rsnaresnet10/working/create_folds.py --n_folds 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_T1wCE_0\n",
      "Loading the best images indexes for all the cases...\n",
      "Loading the best images indexes for all the cases...\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-28 23:07:22.170950: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [03:47<00:00,  1.94s/it, batch_loss=0.506, loss=0.714]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:41<00:00,  1.39s/it, batch_loss=0.137, loss=0.701]\n",
      "EPOCH 0/15: Validation average loss: 0.7012121265133222 + AUC SCORE = 0.5387096774193548 + AUC SCORE THRESH 0.6938775510204082 = 0.5472140762463343\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [09:47<00:00,  5.02s/it, batch_loss=0.705, loss=0.709]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:46<00:00,  1.57s/it, batch_loss=0.558, loss=0.692]\n",
      "EPOCH 1/15: Validation average loss: 0.6924694299697876 + AUC SCORE = 0.49149560117302055 + AUC SCORE THRESH 0.5102040816326531 = 0.5304985337243402\n",
      "100%|███████████| 117/117 [10:55<00:00,  5.60s/it, batch_loss=0.692, loss=0.696]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:52<00:00,  1.76s/it, batch_loss=0.738, loss=0.689]\n",
      "EPOCH 2/15: Validation average loss: 0.6894651691118876 + AUC SCORE = 0.5390029325513197 + AUC SCORE THRESH 0.5306122448979591 = 0.5558651026392962\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [10:58<00:00,  5.63s/it, batch_loss=0.619, loss=0.693]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.97s/it, batch_loss=0.189, loss=0.738]\n",
      "EPOCH 3/15: Validation average loss: 0.7383265644311905 + AUC SCORE = 0.5167155425219941 + AUC SCORE THRESH 0.42857142857142855 = 0.5582111436950148\n",
      "100%|███████████| 117/117 [11:19<00:00,  5.80s/it, batch_loss=0.596, loss=0.693]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.79s/it, batch_loss=0.961, loss=0.699]\n",
      "EPOCH 4/15: Validation average loss: 0.6985847502946854 + AUC SCORE = 0.5384164222873901 + AUC SCORE THRESH 0.5306122448979591 = 0.5577712609970674\n",
      "100%|███████████| 117/117 [11:15<00:00,  5.78s/it, batch_loss=0.623, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|███████████████| 30/30 [00:58<00:00,  1.95s/it, batch_loss=1.4, loss=0.744]\n",
      "EPOCH 5/15: Validation average loss: 0.7437388370434443 + AUC SCORE = 0.5428152492668622 + AUC SCORE THRESH 0.6326530612244897 = 0.5759530791788856\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:16<00:00,  5.78s/it, batch_loss=0.568, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:54<00:00,  1.81s/it, batch_loss=1.23, loss=0.767]\n",
      "EPOCH 6/15: Validation average loss: 0.766578687230746 + AUC SCORE = 0.5126099706744868 + AUC SCORE THRESH 0.673469387755102 = 0.5639296187683285\n",
      "100%|███████████| 117/117 [11:03<00:00,  5.67s/it, batch_loss=0.766, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|████████████████| 30/30 [01:01<00:00,  2.05s/it, batch_loss=0.68, loss=0.7]\n",
      "EPOCH 7/15: Validation average loss: 0.6997993469238282 + AUC SCORE = 0.5249266862170088 + AUC SCORE THRESH 0.5714285714285714 = 0.5501466275659824\n",
      "100%|███████████| 117/117 [11:11<00:00,  5.74s/it, batch_loss=0.686, loss=0.682]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.94s/it, batch_loss=0.915, loss=0.765]\n",
      "EPOCH 8/15: Validation average loss: 0.7648158838351568 + AUC SCORE = 0.46920821114369504 + AUC SCORE THRESH 0.673469387755102 = 0.5335777126099707\n",
      "100%|████████████| 117/117 [11:10<00:00,  5.73s/it, batch_loss=0.61, loss=0.675]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.95s/it, batch_loss=0.605, loss=0.796]\n",
      "EPOCH 9/15: Validation average loss: 0.7956684321165085 + AUC SCORE = 0.5457478005865103 + AUC SCORE THRESH 0.5102040816326531 = 0.5784457478005864\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:18<00:00,  5.80s/it, batch_loss=0.645, loss=0.679]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|███████████████| 30/30 [00:54<00:00,  1.82s/it, batch_loss=0.611, loss=0.7]\n",
      "EPOCH 10/15: Validation average loss: 0.6997048377990722 + AUC SCORE = 0.506158357771261 + AUC SCORE THRESH 0.5306122448979591 = 0.5416422287390029\n",
      "100%|███████████| 117/117 [11:29<00:00,  5.89s/it, batch_loss=0.658, loss=0.669]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.95s/it, batch_loss=0.617, loss=0.701]\n",
      "EPOCH 11/15: Validation average loss: 0.7005097776651382 + AUC SCORE = 0.5099706744868034 + AUC SCORE THRESH 0.5102040816326531 = 0.5587976539589443\n",
      "100%|████████████| 117/117 [11:27<00:00,  5.87s/it, batch_loss=0.825, loss=0.67]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.705, loss=0.726]\n",
      "EPOCH 12/15: Validation average loss: 0.7262069682280222 + AUC SCORE = 0.4501466275659824 + AUC SCORE THRESH 0.7142857142857142 = 0.52316715542522\n",
      "100%|███████████| 117/117 [11:34<00:00,  5.93s/it, batch_loss=0.668, loss=0.662]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.376, loss=0.709]\n",
      "EPOCH 13/15: Validation average loss: 0.7085824747880299 + AUC SCORE = 0.4436950146627566 + AUC SCORE THRESH 0.36734693877551017 = 0.5303519061583578\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.547, loss=0.647]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:59<00:00,  1.99s/it, batch_loss=0.999, loss=0.724]\n",
      "EPOCH 14/15: Validation average loss: 0.7243539830048878 + AUC SCORE = 0.4838709677419355 + AUC SCORE THRESH 0.4897959183673469 = 0.5375366568914957\n",
      "0.5457478005865103\n",
      "train_T1wCE_1\n",
      "Loading the best images indexes for all the cases...\n",
      "Loading the best images indexes for all the cases...\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 02:01:30.486845: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|████████████| 117/117 [11:25<00:00,  5.86s/it, batch_loss=0.835, loss=0.74]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.524, loss=0.692]\n",
      "EPOCH 0/15: Validation average loss: 0.6922847022612889 + AUC SCORE = 0.5859237536656892 + AUC SCORE THRESH 0.6530612244897959 = 0.5913489736070381\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:29<00:00,  5.89s/it, batch_loss=0.763, loss=0.705]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:59<00:00,  1.97s/it, batch_loss=1.07, loss=0.768]\n",
      "EPOCH 1/15: Validation average loss: 0.7676209251085917 + AUC SCORE = 0.5782991202346042 + AUC SCORE THRESH 0.3877551020408163 = 0.6013196480938416\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.725, loss=0.694]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.79s/it, batch_loss=0.699, loss=0.693]\n",
      "EPOCH 2/15: Validation average loss: 0.6932193716367085 + AUC SCORE = 0.547800586510264 + AUC SCORE THRESH 0.5714285714285714 = 0.6155425219941348\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.778, loss=0.695]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.92s/it, batch_loss=0.899, loss=0.706]\n",
      "EPOCH 3/15: Validation average loss: 0.7055632929007213 + AUC SCORE = 0.5363636363636364 + AUC SCORE THRESH 0.5306122448979591 = 0.5590909090909091\n",
      "100%|███████████| 117/117 [11:34<00:00,  5.94s/it, batch_loss=0.712, loss=0.686]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:59<00:00,  1.97s/it, batch_loss=0.974, loss=0.711]\n",
      "EPOCH 4/15: Validation average loss: 0.7113186558087666 + AUC SCORE = 0.5129032258064516 + AUC SCORE THRESH 0.4897959183673469 = 0.5439882697947215\n",
      "100%|████████████| 117/117 [11:33<00:00,  5.93s/it, batch_loss=0.695, loss=0.69]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.98, loss=0.714]\n",
      "EPOCH 5/15: Validation average loss: 0.7143624901771546 + AUC SCORE = 0.48856304985337246 + AUC SCORE THRESH 0.4693877551020408 = 0.5598240469208211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████| 117/117 [11:33<00:00,  5.93s/it, batch_loss=0.606, loss=0.685]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|███████████████| 30/30 [01:00<00:00,  2.02s/it, batch_loss=0.738, loss=0.7]\n",
      "EPOCH 6/15: Validation average loss: 0.7001098175843556 + AUC SCORE = 0.5683284457478006 + AUC SCORE THRESH 0.5102040816326531 = 0.569941348973607\n",
      "100%|███████████| 117/117 [11:19<00:00,  5.81s/it, batch_loss=0.719, loss=0.682]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [01:04<00:00,  2.16s/it, batch_loss=1.13, loss=0.723]\n",
      "EPOCH 7/15: Validation average loss: 0.7226691484451294 + AUC SCORE = 0.5624633431085043 + AUC SCORE THRESH 0.4081632653061224 = 0.5649560117302054\n",
      "100%|████████████| 117/117 [11:25<00:00,  5.86s/it, batch_loss=0.59, loss=0.681]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.03s/it, batch_loss=0.661, loss=0.709]\n",
      "EPOCH 8/15: Validation average loss: 0.7088729550441106 + AUC SCORE = 0.48651026392961877 + AUC SCORE THRESH 0.5102040816326531 = 0.5587976539589443\n",
      "100%|███████████| 117/117 [11:24<00:00,  5.85s/it, batch_loss=0.727, loss=0.675]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.92s/it, batch_loss=0.832, loss=0.713]\n",
      "EPOCH 9/15: Validation average loss: 0.7130532304445902 + AUC SCORE = 0.4988269794721407 + AUC SCORE THRESH 0.5510204081632653 = 0.5611436950146628\n",
      "100%|████████████| 117/117 [11:37<00:00,  5.96s/it, batch_loss=0.547, loss=0.65]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|██████████████| 30/30 [00:52<00:00,  1.76s/it, batch_loss=0.48, loss=0.722]\n",
      "EPOCH 10/15: Validation average loss: 0.7216970870892206 + AUC SCORE = 0.4683284457478005 + AUC SCORE THRESH 0.36734693877551017 = 0.5181818181818182\n",
      "100%|████████████| 117/117 [11:34<00:00,  5.93s/it, batch_loss=0.839, loss=0.64]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:56<00:00,  1.89s/it, batch_loss=0.826, loss=0.752]\n",
      "EPOCH 11/15: Validation average loss: 0.7520661314328512 + AUC SCORE = 0.4516129032258065 + AUC SCORE THRESH 0.26530612244897955 = 0.5101173020527859\n",
      "100%|███████████| 117/117 [11:31<00:00,  5.91s/it, batch_loss=0.539, loss=0.621]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:55<00:00,  1.85s/it, batch_loss=0.374, loss=0.737]\n",
      "EPOCH 12/15: Validation average loss: 0.7371406267086665 + AUC SCORE = 0.4718475073313783 + AUC SCORE THRESH 0.44897959183673464 = 0.5385630498533724\n",
      "100%|███████████| 117/117 [11:32<00:00,  5.92s/it, batch_loss=0.486, loss=0.598]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.01s/it, batch_loss=0.675, loss=0.778]\n",
      "EPOCH 13/15: Validation average loss: 0.7776127388079961 + AUC SCORE = 0.48621700879765395 + AUC SCORE THRESH 0.7346938775510203 = 0.5381231671554252\n",
      "100%|████████████| 117/117 [11:25<00:00,  5.86s/it, batch_loss=0.34, loss=0.569]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.03s/it, batch_loss=0.644, loss=0.888]\n",
      "EPOCH 14/15: Validation average loss: 0.8879576275746027 + AUC SCORE = 0.4967741935483871 + AUC SCORE THRESH 0.8775510204081632 = 0.5260997067448681\n",
      "0.5859237536656892\n",
      "train_T1wCE_2\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 468/468 [01:09<00:00,  6.74it/s]\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 117/117 [00:15<00:00,  7.36it/s]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 05:10:09.547425: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [07:09<00:00,  3.67s/it, batch_loss=0.624, loss=0.723]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|███████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.559, loss=0.9]\n",
      "EPOCH 0/15: Validation average loss: 0.9003540525833765 + AUC SCORE = 0.5172716627634661 + AUC SCORE THRESH 0.5102040816326531 = 0.5522540983606558\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:29<00:00,  5.89s/it, batch_loss=0.555, loss=0.703]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.73s/it, batch_loss=0.882, loss=0.743]\n",
      "EPOCH 1/15: Validation average loss: 0.7425178209940593 + AUC SCORE = 0.5529859484777517 + AUC SCORE THRESH 0.5918367346938775 = 0.5651346604215457\n",
      "Saving the model...\n",
      "100%|████████████| 117/117 [11:23<00:00,  5.84s/it, batch_loss=0.891, loss=0.69]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:56<00:00,  1.88s/it, batch_loss=0.55, loss=0.802]\n",
      "EPOCH 2/15: Validation average loss: 0.8022603332996369 + AUC SCORE = 0.5283957845433256 + AUC SCORE THRESH 0.4897959183673469 = 0.5440573770491803\n",
      "100%|███████████| 117/117 [11:22<00:00,  5.84s/it, batch_loss=0.712, loss=0.693]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.93s/it, batch_loss=0.711, loss=0.729]\n",
      "EPOCH 3/15: Validation average loss: 0.7292274077733357 + AUC SCORE = 0.4997072599531616 + AUC SCORE THRESH 0.5102040816326531 = 0.5642564402810304\n",
      "100%|███████████| 117/117 [11:17<00:00,  5.79s/it, batch_loss=0.765, loss=0.692]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:55<00:00,  1.85s/it, batch_loss=0.725, loss=0.809]\n",
      "EPOCH 4/15: Validation average loss: 0.8094078809022903 + AUC SCORE = 0.5117096018735362 + AUC SCORE THRESH 0.5714285714285714 = 0.5418618266978923\n",
      "100%|███████████| 117/117 [11:27<00:00,  5.88s/it, batch_loss=0.748, loss=0.691]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [01:02<00:00,  2.09s/it, batch_loss=0.607, loss=0.694]\n",
      "EPOCH 5/15: Validation average loss: 0.6943311750888824 + AUC SCORE = 0.527224824355972 + AUC SCORE THRESH 0.5714285714285714 = 0.5715749414519906\n",
      "100%|███████████| 117/117 [11:05<00:00,  5.69s/it, batch_loss=0.697, loss=0.689]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.97s/it, batch_loss=0.577, loss=0.713]\n",
      "EPOCH 6/15: Validation average loss: 0.7127797623475393 + AUC SCORE = 0.5456674473067915 + AUC SCORE THRESH 0.4693877551020408 = 0.5636709601873536\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.656, loss=0.685]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:55<00:00,  1.86s/it, batch_loss=0.48, loss=0.724]\n",
      "EPOCH 7/15: Validation average loss: 0.7241149435440699 + AUC SCORE = 0.5204918032786885 + AUC SCORE THRESH 0.5102040816326531 = 0.5447892271662764\n",
      "100%|████████████| 117/117 [11:06<00:00,  5.70s/it, batch_loss=0.604, loss=0.68]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:50<00:00,  1.69s/it, batch_loss=0.79, loss=0.736]\n",
      "EPOCH 8/15: Validation average loss: 0.7357085029284159 + AUC SCORE = 0.5333723653395784 + AUC SCORE THRESH 0.5714285714285714 = 0.5509367681498829\n",
      "100%|███████████| 117/117 [11:05<00:00,  5.69s/it, batch_loss=0.789, loss=0.681]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:52<00:00,  1.77s/it, batch_loss=0.692, loss=0.707]\n",
      "EPOCH 9/15: Validation average loss: 0.7074600338935852 + AUC SCORE = 0.514344262295082 + AUC SCORE THRESH 0.5510204081632653 = 0.5620608899297423\n",
      "100%|███████████| 117/117 [10:58<00:00,  5.62s/it, batch_loss=0.675, loss=0.679]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:48<00:00,  1.62s/it, batch_loss=0.578, loss=0.697]\n",
      "EPOCH 10/15: Validation average loss: 0.6972469369570414 + AUC SCORE = 0.5196135831381733 + AUC SCORE THRESH 0.5714285714285714 = 0.5493266978922716\n",
      "100%|███████████| 117/117 [10:51<00:00,  5.57s/it, batch_loss=0.791, loss=0.675]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.566, loss=0.702]\n",
      "EPOCH 11/15: Validation average loss: 0.7024828513463338 + AUC SCORE = 0.5067330210772834 + AUC SCORE THRESH 0.5510204081632653 = 0.5403981264637002\n",
      "100%|████████████| 117/117 [10:47<00:00,  5.54s/it, batch_loss=0.834, loss=0.67]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 30/30 [00:48<00:00,  1.62s/it, batch_loss=0.762, loss=0.715]\n",
      "EPOCH 12/15: Validation average loss: 0.7148974816004435 + AUC SCORE = 0.5257611241217799 + AUC SCORE THRESH 0.5510204081632653 = 0.5613290398126464\n",
      "100%|███████████| 117/117 [10:27<00:00,  5.36s/it, batch_loss=0.698, loss=0.676]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:50<00:00,  1.68s/it, batch_loss=0.625, loss=0.724]\n",
      "EPOCH 13/15: Validation average loss: 0.7237817148367564 + AUC SCORE = 0.5117096018735363 + AUC SCORE THRESH 0.6122448979591836 = 0.5529859484777517\n",
      "100%|███████████| 117/117 [10:48<00:00,  5.54s/it, batch_loss=0.662, loss=0.668]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.698, loss=0.713]\n",
      "EPOCH 14/15: Validation average loss: 0.7131009519100189 + AUC SCORE = 0.5102459016393442 + AUC SCORE THRESH 0.673469387755102 = 0.537324355971897\n",
      "0.5529859484777517\n",
      "train_T1wCE_3\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 468/468 [01:07<00:00,  6.98it/s]\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 117/117 [00:17<00:00,  6.54it/s]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 08:07:34.083197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [08:15<00:00,  4.23s/it, batch_loss=0.615, loss=0.719]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.597, loss=0.687]\n",
      "EPOCH 0/15: Validation average loss: 0.6874020646015803 + AUC SCORE = 0.4944379391100703 + AUC SCORE THRESH 0.3877551020408163 = 0.5661592505854801\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [10:52<00:00,  5.57s/it, batch_loss=0.743, loss=0.705]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:50<00:00,  1.68s/it, batch_loss=1.13, loss=0.682]\n",
      "EPOCH 1/15: Validation average loss: 0.681970696647962 + AUC SCORE = 0.6548594847775177 + AUC SCORE THRESH 0.42857142857142855 = 0.6627634660421545\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [10:43<00:00,  5.50s/it, batch_loss=0.675, loss=0.702]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.65s/it, batch_loss=0.741, loss=0.683]\n",
      "EPOCH 2/15: Validation average loss: 0.6826387484868367 + AUC SCORE = 0.603337236533958 + AUC SCORE THRESH 0.44897959183673464 = 0.6412470725995316\n",
      "100%|███████████| 117/117 [10:43<00:00,  5.50s/it, batch_loss=0.788, loss=0.696]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:54<00:00,  1.80s/it, batch_loss=1.02, loss=0.708]\n",
      "EPOCH 3/15: Validation average loss: 0.7079744189977646 + AUC SCORE = 0.6009953161592506 + AUC SCORE THRESH 0.42857142857142855 = 0.6001170960187353\n",
      "100%|███████████| 117/117 [10:31<00:00,  5.40s/it, batch_loss=0.822, loss=0.694]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.761, loss=0.681]\n",
      "EPOCH 4/15: Validation average loss: 0.6810800532499949 + AUC SCORE = 0.601288056206089 + AUC SCORE THRESH 0.4897959183673469 = 0.5913348946135831\n",
      "100%|███████████| 117/117 [10:28<00:00,  5.37s/it, batch_loss=0.679, loss=0.687]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:49<00:00,  1.64s/it, batch_loss=1.11, loss=0.727]\n",
      "EPOCH 5/15: Validation average loss: 0.7268936266501744 + AUC SCORE = 0.6387587822014053 + AUC SCORE THRESH 0.36734693877551017 = 0.6359777517564402\n",
      "100%|███████████| 117/117 [10:45<00:00,  5.52s/it, batch_loss=0.657, loss=0.692]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.65s/it, batch_loss=0.623, loss=0.677]\n",
      "EPOCH 6/15: Validation average loss: 0.6772445728381474 + AUC SCORE = 0.5872365339578454 + AUC SCORE THRESH 0.5102040816326531 = 0.6203161592505855\n",
      "100%|████████████| 117/117 [10:48<00:00,  5.54s/it, batch_loss=0.636, loss=0.69]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.63s/it, batch_loss=0.591, loss=0.708]\n",
      "EPOCH 7/15: Validation average loss: 0.7076821188131969 + AUC SCORE = 0.5117096018735363 + AUC SCORE THRESH 0.5306122448979591 = 0.545228337236534\n",
      "100%|███████████| 117/117 [10:59<00:00,  5.64s/it, batch_loss=0.713, loss=0.688]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:54<00:00,  1.80s/it, batch_loss=0.682, loss=0.696]\n",
      "EPOCH 8/15: Validation average loss: 0.6964038878679275 + AUC SCORE = 0.5433255269320842 + AUC SCORE THRESH 0.4897959183673469 = 0.5690866510538641\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.695, loss=0.686]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.947, loss=0.743]\n",
      "EPOCH 9/15: Validation average loss: 0.7430156379938125 + AUC SCORE = 0.4651639344262295 + AUC SCORE THRESH 0.3469387755102041 = 0.5579625292740047\n",
      "100%|███████████| 117/117 [11:09<00:00,  5.73s/it, batch_loss=0.644, loss=0.669]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.66s/it, batch_loss=0.842, loss=0.726]\n",
      "EPOCH 10/15: Validation average loss: 0.7262662470340728 + AUC SCORE = 0.4475995316159251 + AUC SCORE THRESH 0.673469387755102 = 0.5163934426229508\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.743, loss=0.661]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:59<00:00,  1.97s/it, batch_loss=0.984, loss=0.767]\n",
      "EPOCH 11/15: Validation average loss: 0.7670036474863688 + AUC SCORE = 0.4142271662763466 + AUC SCORE THRESH 0.7755102040816326 = 0.5163934426229508\n",
      "100%|████████████| 117/117 [11:02<00:00,  5.66s/it, batch_loss=0.615, loss=0.66]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:55<00:00,  1.86s/it, batch_loss=0.638, loss=0.756]\n",
      "EPOCH 12/15: Validation average loss: 0.7560017724831899 + AUC SCORE = 0.4461358313817331 + AUC SCORE THRESH 0.5102040816326531 = 0.5117096018735363\n",
      "100%|███████████| 117/117 [11:09<00:00,  5.72s/it, batch_loss=0.768, loss=0.645]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.77s/it, batch_loss=0.748, loss=0.762]\n",
      "EPOCH 13/15: Validation average loss: 0.7621376474698385 + AUC SCORE = 0.474824355971897 + AUC SCORE THRESH 0.3877551020408163 = 0.5281030444964872\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.71s/it, batch_loss=0.608, loss=0.638]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.66s/it, batch_loss=0.651, loss=0.778]\n",
      "EPOCH 14/15: Validation average loss: 0.7779558042685191 + AUC SCORE = 0.39900468384074944 + AUC SCORE THRESH 0.0 = 0.5\n",
      "0.6548594847775177\n",
      "train_T1wCE_4\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 468/468 [01:07<00:00,  6.93it/s]\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 117/117 [00:17<00:00,  6.78it/s]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 11:02:55.481912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [07:37<00:00,  3.91s/it, batch_loss=0.681, loss=0.729]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.236, loss=0.69]\n",
      "EPOCH 0/15: Validation average loss: 0.6898635506629944 + AUC SCORE = 0.5685011709601874 + AUC SCORE THRESH 0.5306122448979591 = 0.5979215456674473\n",
      "Saving the model...\n",
      "100%|█████████████| 117/117 [11:02<00:00,  5.66s/it, batch_loss=0.769, loss=0.7]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.778, loss=0.694]\n",
      "EPOCH 1/15: Validation average loss: 0.6942250847816467 + AUC SCORE = 0.5377634660421545 + AUC SCORE THRESH 0.5918367346938775 = 0.5343969555035128\n",
      "100%|███████████| 117/117 [11:04<00:00,  5.68s/it, batch_loss=0.709, loss=0.703]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 30/30 [00:52<00:00,  1.76s/it, batch_loss=0.853, loss=0.713]\n",
      "EPOCH 2/15: Validation average loss: 0.7134011109670003 + AUC SCORE = 0.5362997658079625 + AUC SCORE THRESH 0.5918367346938775 = 0.5645491803278688\n",
      "100%|███████████| 117/117 [11:06<00:00,  5.70s/it, batch_loss=0.744, loss=0.699]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:50<00:00,  1.69s/it, batch_loss=0.375, loss=0.704]\n",
      "EPOCH 3/15: Validation average loss: 0.7035461147626241 + AUC SCORE = 0.5620608899297425 + AUC SCORE THRESH 0.44897959183673464 = 0.5769906323185011\n",
      "100%|███████████| 117/117 [11:05<00:00,  5.69s/it, batch_loss=0.766, loss=0.685]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:50<00:00,  1.69s/it, batch_loss=0.388, loss=0.697]\n",
      "EPOCH 4/15: Validation average loss: 0.6969916254281998 + AUC SCORE = 0.539519906323185 + AUC SCORE THRESH 0.5918367346938775 = 0.5560597189695549\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.462, loss=0.689]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.66s/it, batch_loss=0.229, loss=0.721]\n",
      "EPOCH 5/15: Validation average loss: 0.721374407907327 + AUC SCORE = 0.5544496487119438 + AUC SCORE THRESH 0.5510204081632653 = 0.5665983606557377\n",
      "100%|███████████| 117/117 [11:14<00:00,  5.76s/it, batch_loss=0.525, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.02s/it, batch_loss=0.629, loss=0.721]\n",
      "EPOCH 6/15: Validation average loss: 0.7210925231377284 + AUC SCORE = 0.5559133489461358 + AUC SCORE THRESH 0.6122448979591836 = 0.571135831381733\n",
      "100%|███████████| 117/117 [11:18<00:00,  5.80s/it, batch_loss=0.805, loss=0.688]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.73s/it, batch_loss=0.461, loss=0.694]\n",
      "EPOCH 7/15: Validation average loss: 0.6943967928489049 + AUC SCORE = 0.5415690866510539 + AUC SCORE THRESH 0.5714285714285714 = 0.5739168618266979\n",
      "100%|███████████| 117/117 [11:11<00:00,  5.74s/it, batch_loss=0.509, loss=0.673]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:52<00:00,  1.75s/it, batch_loss=0.779, loss=0.71]\n",
      "EPOCH 8/15: Validation average loss: 0.7098765790462493 + AUC SCORE = 0.5128805620608898 + AUC SCORE THRESH 0.6122448979591836 = 0.5352751756440282\n",
      "100%|████████████| 117/117 [11:30<00:00,  5.90s/it, batch_loss=0.864, loss=0.68]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.78s/it, batch_loss=0.783, loss=0.723]\n",
      "EPOCH 9/15: Validation average loss: 0.7228919426600139 + AUC SCORE = 0.5272248243559718 + AUC SCORE THRESH 0.5510204081632653 = 0.5584016393442623\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.595, loss=0.665]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|██████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.74, loss=0.742]\n",
      "EPOCH 10/15: Validation average loss: 0.7418981492519379 + AUC SCORE = 0.498536299765808 + AUC SCORE THRESH 0.5918367346938775 = 0.5383489461358314\n",
      "100%|███████████| 117/117 [11:34<00:00,  5.93s/it, batch_loss=0.704, loss=0.657]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.03s/it, batch_loss=0.374, loss=0.738]\n",
      "EPOCH 11/15: Validation average loss: 0.7378725240627925 + AUC SCORE = 0.4795081967213115 + AUC SCORE THRESH 0.5306122448979591 = 0.5449355971896955\n",
      "100%|███████████| 117/117 [11:30<00:00,  5.90s/it, batch_loss=0.548, loss=0.652]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:01<00:00,  2.04s/it, batch_loss=0.774, loss=0.786]\n",
      "EPOCH 12/15: Validation average loss: 0.7856268147627513 + AUC SCORE = 0.42798594847775173 + AUC SCORE THRESH 0.836734693877551 = 0.5081967213114754\n",
      "100%|███████████| 117/117 [11:26<00:00,  5.87s/it, batch_loss=0.569, loss=0.651]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|██████████████| 30/30 [01:00<00:00,  2.02s/it, batch_loss=1.16, loss=0.806]\n",
      "EPOCH 13/15: Validation average loss: 0.8058923304080963 + AUC SCORE = 0.44057377049180335 + AUC SCORE THRESH 0.5306122448979591 = 0.5251756440281031\n",
      "100%|███████████| 117/117 [11:37<00:00,  5.96s/it, batch_loss=0.712, loss=0.631]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.796, loss=0.943]\n",
      "EPOCH 14/15: Validation average loss: 0.9430062651634217 + AUC SCORE = 0.4142271662763466 + AUC SCORE THRESH 0.18367346938775508 = 0.5177107728337236\n",
      "0.5685011709601874\n"
     ]
    }
   ],
   "source": [
    "!python3 ../rsnaresnet10/working/train.py --fold 0 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 1 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 2 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 3 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 4 --type T1wCE --model_name resnet10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../rsnaresnet10/working/validation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.dataset_utils import *\n",
    "from utils.classifier_utils import *\n",
    "\n",
    "import os\n",
    "\n",
    "import monai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#import config\n",
    "#from dataset import BrainRSNADataset\n",
    "\n",
    "dir_path = \"../../RSNA-BTC-Datasets/train_mat\"\n",
    "test_dir_path = \"../../RSNA-BTC-Datasets/test_mat\"\n",
    "tumor_only_dir_path = \"../../RSNA-BTC-Datasets/ec_train_mat\"\n",
    "tumor_only_test_dir_path = \"../../RSNA-BTC-Datasets/ec_test_mat\"\n",
    "no_tumor_dir_path = \"../../RSNA-BTC-Datasets/no_tumor_train_mat\"\n",
    "#ext_test_1_dir_path = \"../../RSNA-BTC-Datasets/brats18_mat\"\n",
    "#ext_test_0_dir_path = \"../../RSNA-BTC-Datasets/OpenNeuroDS000221_ss_mat\"\n",
    "new_dir_path = \"../../RSNA-BTC-Datasets/UPENN-GBM_mat\"\n",
    "\n",
    "def generate_datasets(types):\n",
    "    data_packs = {}\n",
    "    ext = \"mat\"\n",
    "    transform = None\n",
    "    dims = 3\n",
    "    sel_slices = None\n",
    "    for t in types:\n",
    "        print(\"Type: \"+t)\n",
    "        # Competition Train + Val + Test\n",
    "        m_dataset_0 = Dataset(dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        logging.info(\"Train/Val datasets size: {}\".format(len(m_dataset_0)))\n",
    "\n",
    "        m_dataset_1 = Dataset(dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "        \n",
    "        logging.info(\"Train/Val datasets size: {}\".format(len(m_dataset_1)))\n",
    "\n",
    "        # External Train + Val + Test\n",
    "        #t_dataset_0 = Dataset(ext_test_0_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        #logging.info(\"Train/Val datasets size: {}\".format(len(t_dataset_0)))\n",
    "\n",
    "        #t_dataset_1 = Dataset(ext_test_1_dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        #logging.info(\"Train/Val datasets size: {}\".format(len(t_dataset_1)))\n",
    "\n",
    "        # UPENN Train + Val + Test\n",
    "        n_dataset_0 = Dataset(new_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        logging.info(\"Train/Val datasets size: {}\".format(len(n_dataset_0)))\n",
    "\n",
    "        n_dataset_1 = Dataset(new_dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "        \n",
    "        logging.info(\"Train/Val datasets size: {}\".format(len(n_dataset_1)))\n",
    "        \n",
    "        if t == \"KLF\" or t == \"T1wCE\":\n",
    "            # Competition (Tumor Only) Train + Val + Test\n",
    "            f_dataset_0 = Dataset(tumor_only_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "            logging.info(\"Train/Val datasets size: {}\".format(len(f_dataset_0)))\n",
    "\n",
    "            f_dataset_1 = Dataset(tumor_only_dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "            logging.info(\"Train/Val datasets size: {}\".format(len(f_dataset_1)))\n",
    "            \n",
    "            # Competition (No Tumor) Train + Val + Test\n",
    "            h_dataset_0 = Dataset(no_tumor_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "            logging.info(\"Train/Val datasets size: {}\".format(len(h_dataset_0)))\n",
    "            \n",
    "            # Competition (Tumor Only) + UPENN Train + Val + Test\n",
    "            fn_dataset_0 = Dataset().concat_datasets(f_dataset_0, n_dataset_0)\n",
    "            \n",
    "            logging.info(\"Train/Val datasets size: {}\".format(len(fn_dataset_0)))\n",
    "            \n",
    "            fn_dataset_1 = Dataset().concat_datasets(f_dataset_1, n_dataset_1)\n",
    "            \n",
    "            logging.info(\"Train/Val datasets size: {}\".format(len(fn_dataset_1)))\n",
    "        \n",
    "        if t == \"KLF\" or t == \"T1wCE\":\n",
    "            data_packs[t] = {\n",
    "                \"m_dataset_0\": m_dataset_0,\n",
    "                \"m_dataset_1\": m_dataset_1,\n",
    "                \"f_dataset_0\": f_dataset_0,\n",
    "                \"f_dataset_1\": f_dataset_1,\n",
    "                \"h_dataset_0\": h_dataset_0,\n",
    "                #\"t_dataset_0\": t_dataset_0,\n",
    "                #\"t_dataset_1\": t_dataset_1,\n",
    "                \"n_dataset_0\": n_dataset_0,\n",
    "                \"n_dataset_1\": n_dataset_1,\n",
    "                \"fn_dataset_0\": fn_dataset_0,\n",
    "                \"fn_dataset_1\": fn_dataset_1\n",
    "            }\n",
    "        else:\n",
    "            data_packs[t] = {\n",
    "                \"m_dataset_0\": m_dataset_0,\n",
    "                \"m_dataset_1\": m_dataset_1,\n",
    "                #\"t_dataset_0\": t_dataset_0,\n",
    "                #\"t_dataset_1\": t_dataset_1,\n",
    "                \"n_dataset_0\": n_dataset_0,\n",
    "                \"n_dataset_1\": n_dataset_1\n",
    "            }\n",
    "    return data_packs\n",
    "\n",
    "import importlib\n",
    "from utils import dataset_utils\n",
    "importlib.reload(dataset_utils)\n",
    "\n",
    "def get_merged_dataset(dataset_0, dataset_1, k=5):\n",
    "    dataset_merged = Dataset().concat_datasets(dataset_0, dataset_1)\n",
    "    dataset_merged_no_tr = Dataset().concat_datasets(dataset_0, dataset_1, import_transform=False)\n",
    "\n",
    "    val_total_ratio = 0.2\n",
    "    is_5_fold = True\n",
    "    splits = dataset_utils.get_splits(dataset_0, dataset_1, val_total_ratio, is_5_fold, 0.1, k)\n",
    "    print(splits)\n",
    "    return dataset_merged, dataset_merged_no_tr, splits\n",
    "\n",
    "def train_model(train_dl, validation_dl, fold_number, mri_type, model_name, epochs):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.5, last_epoch=-1, verbose=True)\n",
    "\n",
    "    model.zero_grad()\n",
    "    model.to(device)\n",
    "    best_loss = 9999\n",
    "    best_auc = 0\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    train_writer = SummaryWriter()\n",
    "    for counter in range(epochs):\n",
    "\n",
    "        epoch_iterator_train = tqdm(train_dl)\n",
    "        tr_loss = 0.0\n",
    "        for step, batch in enumerate(epoch_iterator_train):\n",
    "            model.train()\n",
    "            (img_ids, imgs, labels) = batch\n",
    "            images, targets = imgs[0].to(device), labels.to(device)\n",
    "            #images, targets = batch[\"image\"].to(device), batch[\"target\"].to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            targets = targets  # .view(-1, 1)\n",
    "            loss = criterion(outputs.squeeze(1), targets.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            epoch_iterator_train.set_postfix(\n",
    "                batch_loss=(loss.item()), loss=(tr_loss / (step + 1))\n",
    "            )\n",
    "\n",
    "        train_writer.add_scalar('loss', (tr_loss/(step+1)), counter+1)\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            preds = []\n",
    "            true_labels = []\n",
    "            case_ids = []\n",
    "            epoch_iterator_val = tqdm(validation_dl)\n",
    "            for step, batch in enumerate(epoch_iterator_val):\n",
    "                model.eval()\n",
    "                (img_ids, imgs, labels) = batch\n",
    "                images, targets = imgs[0].to(device), labels.to(device)\n",
    "                #images, targets = batch[\"image\"].to(device), batch[\"target\"].to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                targets = targets  # .view(-1, 1)\n",
    "                loss = criterion(outputs.squeeze(1), targets.float())\n",
    "                val_loss += loss.item()\n",
    "                epoch_iterator_val.set_postfix(\n",
    "                    batch_loss=(loss.item()), loss=(val_loss / (step + 1))\n",
    "                )\n",
    "                preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "                true_labels.append(targets.cpu().numpy())\n",
    "                #case_ids.append(batch[\"case_id\"])\n",
    "                if img_ids[0][0][0].isnumeric():\n",
    "                    img_ids_fixed = [img_id[:5] for img_id in img_ids[0]]\n",
    "                else:\n",
    "                    img_ids_fixed = [img_id[:-4] for img_id in img_ids[0]]\n",
    "                case_ids.append(img_ids_fixed)\n",
    "        preds = np.vstack(preds).T[0].tolist()\n",
    "        true_labels = np.hstack(true_labels).tolist()\n",
    "        case_ids = np.hstack(case_ids).tolist()\n",
    "        auc_score = roc_auc_score(true_labels, preds)\n",
    "        auc_score_adj_best = 0\n",
    "        for thresh in np.linspace(0, 1, 50):\n",
    "            auc_score_adj = roc_auc_score(true_labels, list(np.array(preds) > thresh))\n",
    "            if auc_score_adj > auc_score_adj_best:\n",
    "                best_thresh = thresh\n",
    "                auc_score_adj_best = auc_score_adj\n",
    "\n",
    "        print(\n",
    "            f\"EPOCH {counter}/{epochs}: Validation average loss: {val_loss/(step+1)} + AUC SCORE = {auc_score} + AUC SCORE THRESH {best_thresh} = {auc_score_adj_best}\"\n",
    "        )\n",
    "        train_writer.add_scalar('val_loss', val_loss/(step+1), counter+1)\n",
    "        train_writer.add_scalar('val_auc', auc_score, counter+1)\n",
    "        if auc_score > best_auc:\n",
    "            print(\"Saving the model...\")\n",
    "\n",
    "            all_files = os.listdir(\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/\")\n",
    "\n",
    "            for f in all_files:\n",
    "                if f\"{model_name}_{mri_type}_fold{fold_number}\" in f:\n",
    "                    os.remove(f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/{f}\")\n",
    "\n",
    "            best_auc = auc_score\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/3d-{model_name}_{mri_type}_fold{fold_number}_{round(best_auc,3)}.pth\",\n",
    "            )\n",
    "\n",
    "    print(best_auc)\n",
    "\n",
    "def train_folded_models(fold, mri_type, model_name, batch_size, epochs):\n",
    "    #data = pd.read_csv(\"train.csv\")\n",
    "    #train_df = data[data.fold != fold].reset_index(drop=False)\n",
    "    #val_df = data[data.fold == fold].reset_index(drop=False)\n",
    "    \n",
    "    print(f\"train_{mri_type}_{fold}\")\n",
    "    #train_dataset = BrainRSNADataset(data=train_df, mri_type=args.type, ds_type=f\"train_{args.type}_{args.fold}\")\n",
    "\n",
    "    #valid_dataset = BrainRSNADataset(data=val_df, mri_type=args.type, ds_type=f\"val_{args.type}_{args.fold}\")\n",
    "\n",
    "    packs = generate_datasets([mri_type])\n",
    "    \n",
    "    loader_packs = {}\n",
    "    for t, pack in packs.items():\n",
    "        print(\"Type: \"+t)\n",
    "        m_dataset_merged, m_dataset_merged_no_tr, m_splits = get_merged_dataset(pack['m_dataset_0'], pack['m_dataset_1'], fold)\n",
    "        n_dataset_merged, n_dataset_merged_no_tr, n_splits = get_merged_dataset(pack['n_dataset_0'], pack['n_dataset_1'], fold)\n",
    "        fn_dataset_merged, fn_dataset_merged_no_tr, fn_splits = get_merged_dataset(pack['fn_dataset_0'], pack['fn_dataset_1'], fold)\n",
    "        print(\"SPLITS:\")\n",
    "        print(\"- folds:\")\n",
    "        print(len(m_splits))\n",
    "        print(\"- splits per fold:\")\n",
    "        print(len(m_splits[0]))\n",
    "        #print(len(n_splits))\n",
    "        i = 0\n",
    "        for split in m_splits:\n",
    "            m_dataloader = get_all_split_loaders(m_dataset_merged, m_dataset_merged_no_tr, [split], batch_size)\n",
    "            m_dataloaders = list(m_dataloader[0])\n",
    "            print(f\"(M) Train validation splitted: {len(split[0])} {len(split[1])}\")\n",
    "            print(m_dataloaders)\n",
    "            train_dl = m_dataloaders[0]\n",
    "            validation_dl = m_dataloaders[1]\n",
    "            train_model(train_dl, validation_dl, i, mri_type, model_name+\"_m\", epochs)\n",
    "            \"\"\"\n",
    "            device = torch.device(\"cuda\")\n",
    "            model = monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1)\n",
    "            model.to(device)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "            scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.5, last_epoch=-1, verbose=True)\n",
    "            trainer = Trainer(\n",
    "                model, \n",
    "                device, \n",
    "                optimizer, \n",
    "                criterion,\n",
    "                scheduler,\n",
    "                1\n",
    "            )\n",
    "\n",
    "            history = trainer.fit(\n",
    "                device,\n",
    "                epochs, \n",
    "                train_dl,\n",
    "                validation_dl,\n",
    "                model_name+\"_m\", \n",
    "                15\n",
    "            )\n",
    "\n",
    "            trainer.train_writer.flush()\n",
    "            \"\"\"\n",
    "            i += 1\n",
    "            \n",
    "        i = 0\n",
    "        for split in n_splits:\n",
    "            n_dataloader = get_all_split_loaders(n_dataset_merged, n_dataset_merged_no_tr, [split], batch_size)\n",
    "            n_dataloaders = list(n_dataloader[0])\n",
    "            print(f\"(M) Train validation splitted: {len(split[0])} {len(split[1])}\")\n",
    "            train_dl = n_dataloaders[0]\n",
    "            validation_dl = n_dataloaders[1]\n",
    "            train_model(train_dl, validation_dl, i, mri_type, model_name+\"_n\", epochs)\n",
    "            i += 1\n",
    "            \n",
    "        i = 0\n",
    "        for split in fn_splits:\n",
    "            fn_dataloader = get_all_split_loaders(fn_dataset_merged, fn_dataset_merged_no_tr, [split], batch_size)\n",
    "            fn_dataloaders = list(fn_dataloader[0])\n",
    "            print(f\"(FN) Train validation splitted: {len(split[0])} {len(split[1])}\")\n",
    "            train_dl = fn_dataloaders[0]\n",
    "            validation_dl = fn_dataloaders[1]\n",
    "            train_model(train_dl, validation_dl, i, mri_type, model_name+\"_fn\", epochs)\n",
    "            i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14356929"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for file in os.listdir(no_tumor_dir_path+\"/KLF/0\"):\n",
    "    fixed_file = file[:-7]+\"T1wCE.mat\"\n",
    "    shutil.copy(dir_path+\"/T1wCE/0/\"+fixed_file, no_tumor_dir_path+\"/T1wCE/0/\"+fixed_file)\n",
    "    \n",
    "for file in os.listdir(tumor_only_dir_path+\"/KLF/0\"):\n",
    "    fixed_file = file[:-7]+\"T1wCE.mat\"\n",
    "    shutil.copy(dir_path+\"/T1wCE/0/\"+fixed_file, tumor_only_dir_path+\"/T1wCE/0/\"+fixed_file)\n",
    "    \n",
    "for file in os.listdir(tumor_only_dir_path+\"/KLF/1\"):\n",
    "    fixed_file = file[:-7]+\"T1wCE.mat\"\n",
    "    shutil.copy(dir_path+\"/T1wCE/1/\"+fixed_file, tumor_only_dir_path+\"/T1wCE/1/\"+fixed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_T1wCE_2\n",
      "Type: T1wCE\n",
      "Type: T1wCE\n",
      "Length of concatenated dataset: 606\n",
      "Length of concatenated dataset: 606\n",
      "[(array([  4,   6,   7,   9,  11,  12,  13,  16,  17,  18,  20,  21,  22,\n",
      "        23,  24,  27,  32,  37,  39,  40,  42,  43,  46,  48,  51,  52,\n",
      "        53,  56,  57,  59,  61,  64,  65,  66,  67,  68,  69,  70,  71,\n",
      "        72,  74,  76,  78,  79,  80,  81,  82,  85,  87,  88,  90,  91,\n",
      "        93,  94,  96,  98, 100, 103, 105, 107, 108, 114, 115, 117, 120,\n",
      "       124, 125, 126, 128, 129, 130, 131, 132, 136, 137, 138, 140, 141,\n",
      "       144, 149, 151, 152, 153, 154, 158, 159, 160, 161, 163, 165, 167,\n",
      "       169, 173, 176, 177, 178, 182, 185, 186, 187, 189, 190, 191, 194,\n",
      "       197, 200, 207, 210, 212, 215, 216, 217, 218, 219, 220, 221, 228,\n",
      "       232, 234, 236, 238, 239, 240, 244, 245, 248, 250, 251, 254, 256,\n",
      "       257, 261, 262, 263, 264, 268, 269, 270, 271, 273, 275, 276, 281,\n",
      "       285, 286, 289, 291, 294, 296, 297, 301, 303, 305, 306, 307, 311,\n",
      "       313, 315, 316, 317, 321, 323, 326, 327, 330, 331, 332, 333, 334,\n",
      "       338, 339, 344, 345, 348, 350, 351, 352, 355, 356, 360, 361, 365,\n",
      "       368, 370, 371, 372, 376, 380, 381, 382, 386, 387, 388, 389, 392,\n",
      "       393, 394, 395, 399, 403, 404, 406, 416, 421, 423, 424, 425, 426,\n",
      "       427, 428, 429, 430, 431, 432, 434, 435, 436, 437, 439, 440, 441,\n",
      "       442, 444, 446, 448, 450, 452, 454, 457, 458, 459, 460, 461, 462,\n",
      "       465, 466, 467, 468, 471, 472, 473, 475, 476, 479, 485, 488, 489,\n",
      "       490, 492, 493, 495, 496, 498, 501, 502, 503, 505, 506, 507, 509,\n",
      "       513, 514, 516, 520, 524, 526, 527, 528, 531, 532, 535, 536, 538,\n",
      "       539, 541, 543, 544, 548, 552, 556, 557, 560, 565, 567, 568, 570,\n",
      "       574, 577, 578, 579, 585, 586, 587, 588, 589, 590, 592, 594, 596,\n",
      "       598, 600, 602, 604]), array([  0,   1,   2,   3,   5,   8,  10,  14,  15,  19,  25,  26,  28,\n",
      "        29,  30,  31,  33,  34,  35,  36,  38,  41,  44,  45,  47,  49,\n",
      "        50,  54,  55,  58,  60,  62,  63,  73,  75,  77,  83,  84,  86,\n",
      "        89,  92,  95,  97,  99, 101, 102, 104, 106, 109, 110, 111, 112,\n",
      "       113, 116, 118, 119, 121, 122, 123, 127, 133, 134, 135, 139, 142,\n",
      "       143, 145, 146, 147, 148, 150, 155, 156, 157, 162, 164, 166, 168,\n",
      "       170, 171, 172, 174, 175, 179, 180, 181, 183, 184, 188, 192, 193,\n",
      "       195, 196, 198, 199, 201, 202, 203, 204, 205, 206, 208, 209, 211,\n",
      "       213, 214, 222, 223, 224, 225, 226, 227, 229, 230, 231, 233, 235,\n",
      "       237, 241, 242, 243, 246, 247, 249, 252, 253, 255, 258, 259, 260,\n",
      "       265, 266, 267, 272, 274, 277, 278, 279, 280, 282, 283, 284, 287,\n",
      "       288, 290, 292, 293, 295, 298, 299, 300, 302, 304, 308, 309, 310,\n",
      "       312, 314, 318, 319, 320, 322, 324, 325, 328, 329, 335, 336, 337,\n",
      "       340, 341, 342, 343, 346, 347, 349, 353, 354, 357, 358, 359, 362,\n",
      "       363, 364, 366, 367, 369, 373, 374, 375, 377, 378, 379, 383, 384,\n",
      "       385, 390, 391, 396, 397, 398, 400, 401, 402, 405, 407, 408, 409,\n",
      "       410, 411, 412, 413, 414, 415, 417, 418, 419, 420, 422, 433, 438,\n",
      "       443, 445, 447, 449, 451, 453, 455, 456, 463, 464, 469, 470, 474,\n",
      "       477, 478, 480, 481, 482, 483, 484, 486, 487, 491, 494, 497, 499,\n",
      "       500, 504, 508, 510, 511, 512, 515, 517, 518, 519, 521, 522, 523,\n",
      "       525, 529, 530, 533, 534, 537, 540, 542, 545, 546, 547, 549, 550,\n",
      "       551, 553, 554, 555, 558, 559, 561, 562, 563, 564, 566, 569, 571,\n",
      "       572, 573, 575, 576, 580, 581, 582, 583, 584, 591, 593, 595, 597,\n",
      "       599, 601, 603, 605])), (array([  0,   1,   2,   3,   5,   8,  10,  14,  15,  19,  25,  26,  28,\n",
      "        29,  30,  31,  33,  34,  35,  36,  38,  41,  44,  45,  47,  49,\n",
      "        50,  54,  55,  58,  60,  62,  63,  73,  75,  77,  83,  84,  86,\n",
      "        89,  92,  95,  97,  99, 101, 102, 104, 106, 109, 110, 111, 112,\n",
      "       113, 116, 118, 119, 121, 122, 123, 127, 133, 134, 135, 139, 142,\n",
      "       143, 145, 146, 147, 148, 150, 155, 156, 157, 162, 164, 166, 168,\n",
      "       170, 171, 172, 174, 175, 179, 180, 181, 183, 184, 188, 192, 193,\n",
      "       195, 196, 198, 199, 201, 202, 203, 204, 205, 206, 208, 209, 211,\n",
      "       213, 214, 222, 223, 224, 225, 226, 227, 229, 230, 231, 233, 235,\n",
      "       237, 241, 242, 243, 246, 247, 249, 252, 253, 255, 258, 259, 260,\n",
      "       265, 266, 267, 272, 274, 277, 278, 279, 280, 282, 283, 284, 287,\n",
      "       288, 290, 292, 293, 295, 298, 299, 300, 302, 304, 308, 309, 310,\n",
      "       312, 314, 318, 319, 320, 322, 324, 325, 328, 329, 335, 336, 337,\n",
      "       340, 341, 342, 343, 346, 347, 349, 353, 354, 357, 358, 359, 362,\n",
      "       363, 364, 366, 367, 369, 373, 374, 375, 377, 378, 379, 383, 384,\n",
      "       385, 390, 391, 396, 397, 398, 400, 401, 402, 405, 407, 408, 409,\n",
      "       410, 411, 412, 413, 414, 415, 417, 418, 419, 420, 422, 433, 438,\n",
      "       443, 445, 447, 449, 451, 453, 455, 456, 463, 464, 469, 470, 474,\n",
      "       477, 478, 480, 481, 482, 483, 484, 486, 487, 491, 494, 497, 499,\n",
      "       500, 504, 508, 510, 511, 512, 515, 517, 518, 519, 521, 522, 523,\n",
      "       525, 529, 530, 533, 534, 537, 540, 542, 545, 546, 547, 549, 550,\n",
      "       551, 553, 554, 555, 558, 559, 561, 562, 563, 564, 566, 569, 571,\n",
      "       572, 573, 575, 576, 580, 581, 582, 583, 584, 591, 593, 595, 597,\n",
      "       599, 601, 603, 605]), array([  4,   6,   7,   9,  11,  12,  13,  16,  17,  18,  20,  21,  22,\n",
      "        23,  24,  27,  32,  37,  39,  40,  42,  43,  46,  48,  51,  52,\n",
      "        53,  56,  57,  59,  61,  64,  65,  66,  67,  68,  69,  70,  71,\n",
      "        72,  74,  76,  78,  79,  80,  81,  82,  85,  87,  88,  90,  91,\n",
      "        93,  94,  96,  98, 100, 103, 105, 107, 108, 114, 115, 117, 120,\n",
      "       124, 125, 126, 128, 129, 130, 131, 132, 136, 137, 138, 140, 141,\n",
      "       144, 149, 151, 152, 153, 154, 158, 159, 160, 161, 163, 165, 167,\n",
      "       169, 173, 176, 177, 178, 182, 185, 186, 187, 189, 190, 191, 194,\n",
      "       197, 200, 207, 210, 212, 215, 216, 217, 218, 219, 220, 221, 228,\n",
      "       232, 234, 236, 238, 239, 240, 244, 245, 248, 250, 251, 254, 256,\n",
      "       257, 261, 262, 263, 264, 268, 269, 270, 271, 273, 275, 276, 281,\n",
      "       285, 286, 289, 291, 294, 296, 297, 301, 303, 305, 306, 307, 311,\n",
      "       313, 315, 316, 317, 321, 323, 326, 327, 330, 331, 332, 333, 334,\n",
      "       338, 339, 344, 345, 348, 350, 351, 352, 355, 356, 360, 361, 365,\n",
      "       368, 370, 371, 372, 376, 380, 381, 382, 386, 387, 388, 389, 392,\n",
      "       393, 394, 395, 399, 403, 404, 406, 416, 421, 423, 424, 425, 426,\n",
      "       427, 428, 429, 430, 431, 432, 434, 435, 436, 437, 439, 440, 441,\n",
      "       442, 444, 446, 448, 450, 452, 454, 457, 458, 459, 460, 461, 462,\n",
      "       465, 466, 467, 468, 471, 472, 473, 475, 476, 479, 485, 488, 489,\n",
      "       490, 492, 493, 495, 496, 498, 501, 502, 503, 505, 506, 507, 509,\n",
      "       513, 514, 516, 520, 524, 526, 527, 528, 531, 532, 535, 536, 538,\n",
      "       539, 541, 543, 544, 548, 552, 556, 557, 560, 565, 567, 568, 570,\n",
      "       574, 577, 578, 579, 585, 586, 587, 588, 589, 590, 592, 594, 596,\n",
      "       598, 600, 602, 604]))]\n",
      "Length of concatenated dataset: 340\n",
      "Length of concatenated dataset: 340\n",
      "[(array([  0,   1,   2,   6,   7,   8,  10,  11,  12,  13,  16,  17,  18,\n",
      "        19,  21,  22,  23,  25,  27,  31,  32,  33,  35,  36,  38,  39,\n",
      "        41,  45,  47,  49,  50,  54,  56,  61,  62,  63,  64,  70,  71,\n",
      "        76,  77,  79,  80,  81,  82,  83,  84,  86,  87,  90,  91,  95,\n",
      "        96,  97, 103, 105, 106, 111, 114, 115, 118, 120, 122, 123, 125,\n",
      "       126, 128, 130, 133, 134, 136, 142, 144, 146, 147, 148, 155, 156,\n",
      "       159, 161, 163, 164, 166, 167, 169, 170, 171, 172, 173, 175, 177,\n",
      "       180, 181, 182, 183, 184, 185, 187, 192, 193, 194, 196, 197, 198,\n",
      "       199, 200, 201, 205, 206, 208, 210, 214, 216, 217, 218, 221, 222,\n",
      "       226, 228, 231, 234, 237, 238, 241, 244, 246, 252, 253, 254, 255,\n",
      "       257, 260, 263, 264, 268, 270, 272, 274, 275, 276, 277, 280, 281,\n",
      "       283, 286, 288, 290, 291, 292, 295, 297, 298, 300, 303, 306, 309,\n",
      "       310, 311, 312, 313, 317, 321, 322, 323, 324, 327, 329, 330, 336,\n",
      "       338]), array([  3,   4,   5,   9,  14,  15,  20,  24,  26,  28,  29,  30,  34,\n",
      "        37,  40,  42,  43,  44,  46,  48,  51,  52,  53,  55,  57,  58,\n",
      "        59,  60,  65,  66,  67,  68,  69,  72,  73,  74,  75,  78,  85,\n",
      "        88,  89,  92,  93,  94,  98,  99, 100, 101, 102, 104, 107, 108,\n",
      "       109, 110, 112, 113, 116, 117, 119, 121, 124, 127, 129, 131, 132,\n",
      "       135, 137, 138, 139, 140, 141, 143, 145, 149, 150, 151, 152, 153,\n",
      "       154, 157, 158, 160, 162, 165, 168, 174, 176, 178, 179, 186, 188,\n",
      "       189, 190, 191, 195, 202, 203, 204, 207, 209, 211, 212, 213, 215,\n",
      "       219, 220, 223, 224, 225, 227, 229, 230, 232, 233, 235, 236, 239,\n",
      "       240, 242, 243, 245, 247, 248, 249, 250, 251, 256, 258, 259, 261,\n",
      "       262, 265, 266, 267, 269, 271, 273, 278, 279, 282, 284, 285, 287,\n",
      "       289, 293, 294, 296, 299, 301, 302, 304, 305, 307, 308, 314, 315,\n",
      "       316, 318, 319, 320, 325, 326, 328, 331, 332, 333, 334, 335, 337,\n",
      "       339])), (array([  3,   4,   5,   9,  14,  15,  20,  24,  26,  28,  29,  30,  34,\n",
      "        37,  40,  42,  43,  44,  46,  48,  51,  52,  53,  55,  57,  58,\n",
      "        59,  60,  65,  66,  67,  68,  69,  72,  73,  74,  75,  78,  85,\n",
      "        88,  89,  92,  93,  94,  98,  99, 100, 101, 102, 104, 107, 108,\n",
      "       109, 110, 112, 113, 116, 117, 119, 121, 124, 127, 129, 131, 132,\n",
      "       135, 137, 138, 139, 140, 141, 143, 145, 149, 150, 151, 152, 153,\n",
      "       154, 157, 158, 160, 162, 165, 168, 174, 176, 178, 179, 186, 188,\n",
      "       189, 190, 191, 195, 202, 203, 204, 207, 209, 211, 212, 213, 215,\n",
      "       219, 220, 223, 224, 225, 227, 229, 230, 232, 233, 235, 236, 239,\n",
      "       240, 242, 243, 245, 247, 248, 249, 250, 251, 256, 258, 259, 261,\n",
      "       262, 265, 266, 267, 269, 271, 273, 278, 279, 282, 284, 285, 287,\n",
      "       289, 293, 294, 296, 299, 301, 302, 304, 305, 307, 308, 314, 315,\n",
      "       316, 318, 319, 320, 325, 326, 328, 331, 332, 333, 334, 335, 337,\n",
      "       339]), array([  0,   1,   2,   6,   7,   8,  10,  11,  12,  13,  16,  17,  18,\n",
      "        19,  21,  22,  23,  25,  27,  31,  32,  33,  35,  36,  38,  39,\n",
      "        41,  45,  47,  49,  50,  54,  56,  61,  62,  63,  64,  70,  71,\n",
      "        76,  77,  79,  80,  81,  82,  83,  84,  86,  87,  90,  91,  95,\n",
      "        96,  97, 103, 105, 106, 111, 114, 115, 118, 120, 122, 123, 125,\n",
      "       126, 128, 130, 133, 134, 136, 142, 144, 146, 147, 148, 155, 156,\n",
      "       159, 161, 163, 164, 166, 167, 169, 170, 171, 172, 173, 175, 177,\n",
      "       180, 181, 182, 183, 184, 185, 187, 192, 193, 194, 196, 197, 198,\n",
      "       199, 200, 201, 205, 206, 208, 210, 214, 216, 217, 218, 221, 222,\n",
      "       226, 228, 231, 234, 237, 238, 241, 244, 246, 252, 253, 254, 255,\n",
      "       257, 260, 263, 264, 268, 270, 272, 274, 275, 276, 277, 280, 281,\n",
      "       283, 286, 288, 290, 291, 292, 295, 297, 298, 300, 303, 306, 309,\n",
      "       310, 311, 312, 313, 317, 321, 322, 323, 324, 327, 329, 330, 336,\n",
      "       338]))]\n",
      "SPLITS:\n",
      "- folds:\n",
      "2\n",
      "- splits per fold:\n",
      "2\n",
      "(M) Train validation splitted: 303 303\n",
      "[<torch.utils.data.dataloader.DataLoader object at 0x7ffb0659d190>, <torch.utils.data.dataloader.DataLoader object at 0x7ffb544e3100>]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/303 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 216.00 MiB (GPU 0; 7.80 GiB total capacity; 5.25 GiB already allocated; 97.38 MiB free; 5.43 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9556/480821663.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_folded_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"T1wCE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"resnet10\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_9556/1128738627.py\u001b[0m in \u001b[0;36mtrain_folded_models\u001b[0;34m(fold, mri_type, model_name, batch_size, epochs)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mtrain_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_dataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mvalidation_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_dataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmri_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_m\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \"\"\"\n\u001b[1;32m    262\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9556/1128738627.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_dl, validation_dl, fold_number, mri_type, model_name, epochs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 216.00 MiB (GPU 0; 7.80 GiB total capacity; 5.25 GiB already allocated; 97.38 MiB free; 5.43 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "fold = 5\n",
    "mri_type = \"T1wCE\"\n",
    "batch_size = 4\n",
    "epochs = 15\n",
    "train_folded_models(fold, mri_type, \"resnet10\", batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
