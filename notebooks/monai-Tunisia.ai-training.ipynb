{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../rsnaresnet10/working/create_folds.py --n_folds 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_T1wCE_0\n",
      "Loading the best images indexes for all the cases...\n",
      "Loading the best images indexes for all the cases...\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-28 23:07:22.170950: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [03:47<00:00,  1.94s/it, batch_loss=0.506, loss=0.714]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:41<00:00,  1.39s/it, batch_loss=0.137, loss=0.701]\n",
      "EPOCH 0/15: Validation average loss: 0.7012121265133222 + AUC SCORE = 0.5387096774193548 + AUC SCORE THRESH 0.6938775510204082 = 0.5472140762463343\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [09:47<00:00,  5.02s/it, batch_loss=0.705, loss=0.709]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:46<00:00,  1.57s/it, batch_loss=0.558, loss=0.692]\n",
      "EPOCH 1/15: Validation average loss: 0.6924694299697876 + AUC SCORE = 0.49149560117302055 + AUC SCORE THRESH 0.5102040816326531 = 0.5304985337243402\n",
      "100%|███████████| 117/117 [10:55<00:00,  5.60s/it, batch_loss=0.692, loss=0.696]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:52<00:00,  1.76s/it, batch_loss=0.738, loss=0.689]\n",
      "EPOCH 2/15: Validation average loss: 0.6894651691118876 + AUC SCORE = 0.5390029325513197 + AUC SCORE THRESH 0.5306122448979591 = 0.5558651026392962\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [10:58<00:00,  5.63s/it, batch_loss=0.619, loss=0.693]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.97s/it, batch_loss=0.189, loss=0.738]\n",
      "EPOCH 3/15: Validation average loss: 0.7383265644311905 + AUC SCORE = 0.5167155425219941 + AUC SCORE THRESH 0.42857142857142855 = 0.5582111436950148\n",
      "100%|███████████| 117/117 [11:19<00:00,  5.80s/it, batch_loss=0.596, loss=0.693]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.79s/it, batch_loss=0.961, loss=0.699]\n",
      "EPOCH 4/15: Validation average loss: 0.6985847502946854 + AUC SCORE = 0.5384164222873901 + AUC SCORE THRESH 0.5306122448979591 = 0.5577712609970674\n",
      "100%|███████████| 117/117 [11:15<00:00,  5.78s/it, batch_loss=0.623, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|███████████████| 30/30 [00:58<00:00,  1.95s/it, batch_loss=1.4, loss=0.744]\n",
      "EPOCH 5/15: Validation average loss: 0.7437388370434443 + AUC SCORE = 0.5428152492668622 + AUC SCORE THRESH 0.6326530612244897 = 0.5759530791788856\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:16<00:00,  5.78s/it, batch_loss=0.568, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:54<00:00,  1.81s/it, batch_loss=1.23, loss=0.767]\n",
      "EPOCH 6/15: Validation average loss: 0.766578687230746 + AUC SCORE = 0.5126099706744868 + AUC SCORE THRESH 0.673469387755102 = 0.5639296187683285\n",
      "100%|███████████| 117/117 [11:03<00:00,  5.67s/it, batch_loss=0.766, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|████████████████| 30/30 [01:01<00:00,  2.05s/it, batch_loss=0.68, loss=0.7]\n",
      "EPOCH 7/15: Validation average loss: 0.6997993469238282 + AUC SCORE = 0.5249266862170088 + AUC SCORE THRESH 0.5714285714285714 = 0.5501466275659824\n",
      "100%|███████████| 117/117 [11:11<00:00,  5.74s/it, batch_loss=0.686, loss=0.682]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.94s/it, batch_loss=0.915, loss=0.765]\n",
      "EPOCH 8/15: Validation average loss: 0.7648158838351568 + AUC SCORE = 0.46920821114369504 + AUC SCORE THRESH 0.673469387755102 = 0.5335777126099707\n",
      "100%|████████████| 117/117 [11:10<00:00,  5.73s/it, batch_loss=0.61, loss=0.675]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.95s/it, batch_loss=0.605, loss=0.796]\n",
      "EPOCH 9/15: Validation average loss: 0.7956684321165085 + AUC SCORE = 0.5457478005865103 + AUC SCORE THRESH 0.5102040816326531 = 0.5784457478005864\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:18<00:00,  5.80s/it, batch_loss=0.645, loss=0.679]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|███████████████| 30/30 [00:54<00:00,  1.82s/it, batch_loss=0.611, loss=0.7]\n",
      "EPOCH 10/15: Validation average loss: 0.6997048377990722 + AUC SCORE = 0.506158357771261 + AUC SCORE THRESH 0.5306122448979591 = 0.5416422287390029\n",
      "100%|███████████| 117/117 [11:29<00:00,  5.89s/it, batch_loss=0.658, loss=0.669]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.95s/it, batch_loss=0.617, loss=0.701]\n",
      "EPOCH 11/15: Validation average loss: 0.7005097776651382 + AUC SCORE = 0.5099706744868034 + AUC SCORE THRESH 0.5102040816326531 = 0.5587976539589443\n",
      "100%|████████████| 117/117 [11:27<00:00,  5.87s/it, batch_loss=0.825, loss=0.67]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.705, loss=0.726]\n",
      "EPOCH 12/15: Validation average loss: 0.7262069682280222 + AUC SCORE = 0.4501466275659824 + AUC SCORE THRESH 0.7142857142857142 = 0.52316715542522\n",
      "100%|███████████| 117/117 [11:34<00:00,  5.93s/it, batch_loss=0.668, loss=0.662]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.376, loss=0.709]\n",
      "EPOCH 13/15: Validation average loss: 0.7085824747880299 + AUC SCORE = 0.4436950146627566 + AUC SCORE THRESH 0.36734693877551017 = 0.5303519061583578\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.547, loss=0.647]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:59<00:00,  1.99s/it, batch_loss=0.999, loss=0.724]\n",
      "EPOCH 14/15: Validation average loss: 0.7243539830048878 + AUC SCORE = 0.4838709677419355 + AUC SCORE THRESH 0.4897959183673469 = 0.5375366568914957\n",
      "0.5457478005865103\n",
      "train_T1wCE_1\n",
      "Loading the best images indexes for all the cases...\n",
      "Loading the best images indexes for all the cases...\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 02:01:30.486845: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|████████████| 117/117 [11:25<00:00,  5.86s/it, batch_loss=0.835, loss=0.74]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.524, loss=0.692]\n",
      "EPOCH 0/15: Validation average loss: 0.6922847022612889 + AUC SCORE = 0.5859237536656892 + AUC SCORE THRESH 0.6530612244897959 = 0.5913489736070381\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:29<00:00,  5.89s/it, batch_loss=0.763, loss=0.705]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:59<00:00,  1.97s/it, batch_loss=1.07, loss=0.768]\n",
      "EPOCH 1/15: Validation average loss: 0.7676209251085917 + AUC SCORE = 0.5782991202346042 + AUC SCORE THRESH 0.3877551020408163 = 0.6013196480938416\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.725, loss=0.694]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.79s/it, batch_loss=0.699, loss=0.693]\n",
      "EPOCH 2/15: Validation average loss: 0.6932193716367085 + AUC SCORE = 0.547800586510264 + AUC SCORE THRESH 0.5714285714285714 = 0.6155425219941348\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.778, loss=0.695]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.92s/it, batch_loss=0.899, loss=0.706]\n",
      "EPOCH 3/15: Validation average loss: 0.7055632929007213 + AUC SCORE = 0.5363636363636364 + AUC SCORE THRESH 0.5306122448979591 = 0.5590909090909091\n",
      "100%|███████████| 117/117 [11:34<00:00,  5.94s/it, batch_loss=0.712, loss=0.686]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:59<00:00,  1.97s/it, batch_loss=0.974, loss=0.711]\n",
      "EPOCH 4/15: Validation average loss: 0.7113186558087666 + AUC SCORE = 0.5129032258064516 + AUC SCORE THRESH 0.4897959183673469 = 0.5439882697947215\n",
      "100%|████████████| 117/117 [11:33<00:00,  5.93s/it, batch_loss=0.695, loss=0.69]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.98, loss=0.714]\n",
      "EPOCH 5/15: Validation average loss: 0.7143624901771546 + AUC SCORE = 0.48856304985337246 + AUC SCORE THRESH 0.4693877551020408 = 0.5598240469208211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████| 117/117 [11:33<00:00,  5.93s/it, batch_loss=0.606, loss=0.685]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|███████████████| 30/30 [01:00<00:00,  2.02s/it, batch_loss=0.738, loss=0.7]\n",
      "EPOCH 6/15: Validation average loss: 0.7001098175843556 + AUC SCORE = 0.5683284457478006 + AUC SCORE THRESH 0.5102040816326531 = 0.569941348973607\n",
      "100%|███████████| 117/117 [11:19<00:00,  5.81s/it, batch_loss=0.719, loss=0.682]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [01:04<00:00,  2.16s/it, batch_loss=1.13, loss=0.723]\n",
      "EPOCH 7/15: Validation average loss: 0.7226691484451294 + AUC SCORE = 0.5624633431085043 + AUC SCORE THRESH 0.4081632653061224 = 0.5649560117302054\n",
      "100%|████████████| 117/117 [11:25<00:00,  5.86s/it, batch_loss=0.59, loss=0.681]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.03s/it, batch_loss=0.661, loss=0.709]\n",
      "EPOCH 8/15: Validation average loss: 0.7088729550441106 + AUC SCORE = 0.48651026392961877 + AUC SCORE THRESH 0.5102040816326531 = 0.5587976539589443\n",
      "100%|███████████| 117/117 [11:24<00:00,  5.85s/it, batch_loss=0.727, loss=0.675]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.92s/it, batch_loss=0.832, loss=0.713]\n",
      "EPOCH 9/15: Validation average loss: 0.7130532304445902 + AUC SCORE = 0.4988269794721407 + AUC SCORE THRESH 0.5510204081632653 = 0.5611436950146628\n",
      "100%|████████████| 117/117 [11:37<00:00,  5.96s/it, batch_loss=0.547, loss=0.65]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|██████████████| 30/30 [00:52<00:00,  1.76s/it, batch_loss=0.48, loss=0.722]\n",
      "EPOCH 10/15: Validation average loss: 0.7216970870892206 + AUC SCORE = 0.4683284457478005 + AUC SCORE THRESH 0.36734693877551017 = 0.5181818181818182\n",
      "100%|████████████| 117/117 [11:34<00:00,  5.93s/it, batch_loss=0.839, loss=0.64]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:56<00:00,  1.89s/it, batch_loss=0.826, loss=0.752]\n",
      "EPOCH 11/15: Validation average loss: 0.7520661314328512 + AUC SCORE = 0.4516129032258065 + AUC SCORE THRESH 0.26530612244897955 = 0.5101173020527859\n",
      "100%|███████████| 117/117 [11:31<00:00,  5.91s/it, batch_loss=0.539, loss=0.621]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:55<00:00,  1.85s/it, batch_loss=0.374, loss=0.737]\n",
      "EPOCH 12/15: Validation average loss: 0.7371406267086665 + AUC SCORE = 0.4718475073313783 + AUC SCORE THRESH 0.44897959183673464 = 0.5385630498533724\n",
      "100%|███████████| 117/117 [11:32<00:00,  5.92s/it, batch_loss=0.486, loss=0.598]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.01s/it, batch_loss=0.675, loss=0.778]\n",
      "EPOCH 13/15: Validation average loss: 0.7776127388079961 + AUC SCORE = 0.48621700879765395 + AUC SCORE THRESH 0.7346938775510203 = 0.5381231671554252\n",
      "100%|████████████| 117/117 [11:25<00:00,  5.86s/it, batch_loss=0.34, loss=0.569]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.03s/it, batch_loss=0.644, loss=0.888]\n",
      "EPOCH 14/15: Validation average loss: 0.8879576275746027 + AUC SCORE = 0.4967741935483871 + AUC SCORE THRESH 0.8775510204081632 = 0.5260997067448681\n",
      "0.5859237536656892\n",
      "train_T1wCE_2\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 468/468 [01:09<00:00,  6.74it/s]\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 117/117 [00:15<00:00,  7.36it/s]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 05:10:09.547425: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [07:09<00:00,  3.67s/it, batch_loss=0.624, loss=0.723]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|███████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.559, loss=0.9]\n",
      "EPOCH 0/15: Validation average loss: 0.9003540525833765 + AUC SCORE = 0.5172716627634661 + AUC SCORE THRESH 0.5102040816326531 = 0.5522540983606558\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:29<00:00,  5.89s/it, batch_loss=0.555, loss=0.703]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.73s/it, batch_loss=0.882, loss=0.743]\n",
      "EPOCH 1/15: Validation average loss: 0.7425178209940593 + AUC SCORE = 0.5529859484777517 + AUC SCORE THRESH 0.5918367346938775 = 0.5651346604215457\n",
      "Saving the model...\n",
      "100%|████████████| 117/117 [11:23<00:00,  5.84s/it, batch_loss=0.891, loss=0.69]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:56<00:00,  1.88s/it, batch_loss=0.55, loss=0.802]\n",
      "EPOCH 2/15: Validation average loss: 0.8022603332996369 + AUC SCORE = 0.5283957845433256 + AUC SCORE THRESH 0.4897959183673469 = 0.5440573770491803\n",
      "100%|███████████| 117/117 [11:22<00:00,  5.84s/it, batch_loss=0.712, loss=0.693]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.93s/it, batch_loss=0.711, loss=0.729]\n",
      "EPOCH 3/15: Validation average loss: 0.7292274077733357 + AUC SCORE = 0.4997072599531616 + AUC SCORE THRESH 0.5102040816326531 = 0.5642564402810304\n",
      "100%|███████████| 117/117 [11:17<00:00,  5.79s/it, batch_loss=0.765, loss=0.692]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:55<00:00,  1.85s/it, batch_loss=0.725, loss=0.809]\n",
      "EPOCH 4/15: Validation average loss: 0.8094078809022903 + AUC SCORE = 0.5117096018735362 + AUC SCORE THRESH 0.5714285714285714 = 0.5418618266978923\n",
      "100%|███████████| 117/117 [11:27<00:00,  5.88s/it, batch_loss=0.748, loss=0.691]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [01:02<00:00,  2.09s/it, batch_loss=0.607, loss=0.694]\n",
      "EPOCH 5/15: Validation average loss: 0.6943311750888824 + AUC SCORE = 0.527224824355972 + AUC SCORE THRESH 0.5714285714285714 = 0.5715749414519906\n",
      "100%|███████████| 117/117 [11:05<00:00,  5.69s/it, batch_loss=0.697, loss=0.689]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.97s/it, batch_loss=0.577, loss=0.713]\n",
      "EPOCH 6/15: Validation average loss: 0.7127797623475393 + AUC SCORE = 0.5456674473067915 + AUC SCORE THRESH 0.4693877551020408 = 0.5636709601873536\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.656, loss=0.685]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:55<00:00,  1.86s/it, batch_loss=0.48, loss=0.724]\n",
      "EPOCH 7/15: Validation average loss: 0.7241149435440699 + AUC SCORE = 0.5204918032786885 + AUC SCORE THRESH 0.5102040816326531 = 0.5447892271662764\n",
      "100%|████████████| 117/117 [11:06<00:00,  5.70s/it, batch_loss=0.604, loss=0.68]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:50<00:00,  1.69s/it, batch_loss=0.79, loss=0.736]\n",
      "EPOCH 8/15: Validation average loss: 0.7357085029284159 + AUC SCORE = 0.5333723653395784 + AUC SCORE THRESH 0.5714285714285714 = 0.5509367681498829\n",
      "100%|███████████| 117/117 [11:05<00:00,  5.69s/it, batch_loss=0.789, loss=0.681]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:52<00:00,  1.77s/it, batch_loss=0.692, loss=0.707]\n",
      "EPOCH 9/15: Validation average loss: 0.7074600338935852 + AUC SCORE = 0.514344262295082 + AUC SCORE THRESH 0.5510204081632653 = 0.5620608899297423\n",
      "100%|███████████| 117/117 [10:58<00:00,  5.62s/it, batch_loss=0.675, loss=0.679]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:48<00:00,  1.62s/it, batch_loss=0.578, loss=0.697]\n",
      "EPOCH 10/15: Validation average loss: 0.6972469369570414 + AUC SCORE = 0.5196135831381733 + AUC SCORE THRESH 0.5714285714285714 = 0.5493266978922716\n",
      "100%|███████████| 117/117 [10:51<00:00,  5.57s/it, batch_loss=0.791, loss=0.675]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.566, loss=0.702]\n",
      "EPOCH 11/15: Validation average loss: 0.7024828513463338 + AUC SCORE = 0.5067330210772834 + AUC SCORE THRESH 0.5510204081632653 = 0.5403981264637002\n",
      "100%|████████████| 117/117 [10:47<00:00,  5.54s/it, batch_loss=0.834, loss=0.67]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 30/30 [00:48<00:00,  1.62s/it, batch_loss=0.762, loss=0.715]\n",
      "EPOCH 12/15: Validation average loss: 0.7148974816004435 + AUC SCORE = 0.5257611241217799 + AUC SCORE THRESH 0.5510204081632653 = 0.5613290398126464\n",
      "100%|███████████| 117/117 [10:27<00:00,  5.36s/it, batch_loss=0.698, loss=0.676]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:50<00:00,  1.68s/it, batch_loss=0.625, loss=0.724]\n",
      "EPOCH 13/15: Validation average loss: 0.7237817148367564 + AUC SCORE = 0.5117096018735363 + AUC SCORE THRESH 0.6122448979591836 = 0.5529859484777517\n",
      "100%|███████████| 117/117 [10:48<00:00,  5.54s/it, batch_loss=0.662, loss=0.668]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.698, loss=0.713]\n",
      "EPOCH 14/15: Validation average loss: 0.7131009519100189 + AUC SCORE = 0.5102459016393442 + AUC SCORE THRESH 0.673469387755102 = 0.537324355971897\n",
      "0.5529859484777517\n",
      "train_T1wCE_3\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 468/468 [01:07<00:00,  6.98it/s]\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 117/117 [00:17<00:00,  6.54it/s]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 08:07:34.083197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [08:15<00:00,  4.23s/it, batch_loss=0.615, loss=0.719]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.597, loss=0.687]\n",
      "EPOCH 0/15: Validation average loss: 0.6874020646015803 + AUC SCORE = 0.4944379391100703 + AUC SCORE THRESH 0.3877551020408163 = 0.5661592505854801\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [10:52<00:00,  5.57s/it, batch_loss=0.743, loss=0.705]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:50<00:00,  1.68s/it, batch_loss=1.13, loss=0.682]\n",
      "EPOCH 1/15: Validation average loss: 0.681970696647962 + AUC SCORE = 0.6548594847775177 + AUC SCORE THRESH 0.42857142857142855 = 0.6627634660421545\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [10:43<00:00,  5.50s/it, batch_loss=0.675, loss=0.702]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.65s/it, batch_loss=0.741, loss=0.683]\n",
      "EPOCH 2/15: Validation average loss: 0.6826387484868367 + AUC SCORE = 0.603337236533958 + AUC SCORE THRESH 0.44897959183673464 = 0.6412470725995316\n",
      "100%|███████████| 117/117 [10:43<00:00,  5.50s/it, batch_loss=0.788, loss=0.696]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:54<00:00,  1.80s/it, batch_loss=1.02, loss=0.708]\n",
      "EPOCH 3/15: Validation average loss: 0.7079744189977646 + AUC SCORE = 0.6009953161592506 + AUC SCORE THRESH 0.42857142857142855 = 0.6001170960187353\n",
      "100%|███████████| 117/117 [10:31<00:00,  5.40s/it, batch_loss=0.822, loss=0.694]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.761, loss=0.681]\n",
      "EPOCH 4/15: Validation average loss: 0.6810800532499949 + AUC SCORE = 0.601288056206089 + AUC SCORE THRESH 0.4897959183673469 = 0.5913348946135831\n",
      "100%|███████████| 117/117 [10:28<00:00,  5.37s/it, batch_loss=0.679, loss=0.687]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:49<00:00,  1.64s/it, batch_loss=1.11, loss=0.727]\n",
      "EPOCH 5/15: Validation average loss: 0.7268936266501744 + AUC SCORE = 0.6387587822014053 + AUC SCORE THRESH 0.36734693877551017 = 0.6359777517564402\n",
      "100%|███████████| 117/117 [10:45<00:00,  5.52s/it, batch_loss=0.657, loss=0.692]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.65s/it, batch_loss=0.623, loss=0.677]\n",
      "EPOCH 6/15: Validation average loss: 0.6772445728381474 + AUC SCORE = 0.5872365339578454 + AUC SCORE THRESH 0.5102040816326531 = 0.6203161592505855\n",
      "100%|████████████| 117/117 [10:48<00:00,  5.54s/it, batch_loss=0.636, loss=0.69]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.63s/it, batch_loss=0.591, loss=0.708]\n",
      "EPOCH 7/15: Validation average loss: 0.7076821188131969 + AUC SCORE = 0.5117096018735363 + AUC SCORE THRESH 0.5306122448979591 = 0.545228337236534\n",
      "100%|███████████| 117/117 [10:59<00:00,  5.64s/it, batch_loss=0.713, loss=0.688]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:54<00:00,  1.80s/it, batch_loss=0.682, loss=0.696]\n",
      "EPOCH 8/15: Validation average loss: 0.6964038878679275 + AUC SCORE = 0.5433255269320842 + AUC SCORE THRESH 0.4897959183673469 = 0.5690866510538641\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.695, loss=0.686]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.947, loss=0.743]\n",
      "EPOCH 9/15: Validation average loss: 0.7430156379938125 + AUC SCORE = 0.4651639344262295 + AUC SCORE THRESH 0.3469387755102041 = 0.5579625292740047\n",
      "100%|███████████| 117/117 [11:09<00:00,  5.73s/it, batch_loss=0.644, loss=0.669]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.66s/it, batch_loss=0.842, loss=0.726]\n",
      "EPOCH 10/15: Validation average loss: 0.7262662470340728 + AUC SCORE = 0.4475995316159251 + AUC SCORE THRESH 0.673469387755102 = 0.5163934426229508\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.743, loss=0.661]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:59<00:00,  1.97s/it, batch_loss=0.984, loss=0.767]\n",
      "EPOCH 11/15: Validation average loss: 0.7670036474863688 + AUC SCORE = 0.4142271662763466 + AUC SCORE THRESH 0.7755102040816326 = 0.5163934426229508\n",
      "100%|████████████| 117/117 [11:02<00:00,  5.66s/it, batch_loss=0.615, loss=0.66]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:55<00:00,  1.86s/it, batch_loss=0.638, loss=0.756]\n",
      "EPOCH 12/15: Validation average loss: 0.7560017724831899 + AUC SCORE = 0.4461358313817331 + AUC SCORE THRESH 0.5102040816326531 = 0.5117096018735363\n",
      "100%|███████████| 117/117 [11:09<00:00,  5.72s/it, batch_loss=0.768, loss=0.645]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.77s/it, batch_loss=0.748, loss=0.762]\n",
      "EPOCH 13/15: Validation average loss: 0.7621376474698385 + AUC SCORE = 0.474824355971897 + AUC SCORE THRESH 0.3877551020408163 = 0.5281030444964872\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.71s/it, batch_loss=0.608, loss=0.638]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.66s/it, batch_loss=0.651, loss=0.778]\n",
      "EPOCH 14/15: Validation average loss: 0.7779558042685191 + AUC SCORE = 0.39900468384074944 + AUC SCORE THRESH 0.0 = 0.5\n",
      "0.6548594847775177\n",
      "train_T1wCE_4\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 468/468 [01:07<00:00,  6.93it/s]\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 117/117 [00:17<00:00,  6.78it/s]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 11:02:55.481912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [07:37<00:00,  3.91s/it, batch_loss=0.681, loss=0.729]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.236, loss=0.69]\n",
      "EPOCH 0/15: Validation average loss: 0.6898635506629944 + AUC SCORE = 0.5685011709601874 + AUC SCORE THRESH 0.5306122448979591 = 0.5979215456674473\n",
      "Saving the model...\n",
      "100%|█████████████| 117/117 [11:02<00:00,  5.66s/it, batch_loss=0.769, loss=0.7]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.778, loss=0.694]\n",
      "EPOCH 1/15: Validation average loss: 0.6942250847816467 + AUC SCORE = 0.5377634660421545 + AUC SCORE THRESH 0.5918367346938775 = 0.5343969555035128\n",
      "100%|███████████| 117/117 [11:04<00:00,  5.68s/it, batch_loss=0.709, loss=0.703]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 30/30 [00:52<00:00,  1.76s/it, batch_loss=0.853, loss=0.713]\n",
      "EPOCH 2/15: Validation average loss: 0.7134011109670003 + AUC SCORE = 0.5362997658079625 + AUC SCORE THRESH 0.5918367346938775 = 0.5645491803278688\n",
      "100%|███████████| 117/117 [11:06<00:00,  5.70s/it, batch_loss=0.744, loss=0.699]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:50<00:00,  1.69s/it, batch_loss=0.375, loss=0.704]\n",
      "EPOCH 3/15: Validation average loss: 0.7035461147626241 + AUC SCORE = 0.5620608899297425 + AUC SCORE THRESH 0.44897959183673464 = 0.5769906323185011\n",
      "100%|███████████| 117/117 [11:05<00:00,  5.69s/it, batch_loss=0.766, loss=0.685]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:50<00:00,  1.69s/it, batch_loss=0.388, loss=0.697]\n",
      "EPOCH 4/15: Validation average loss: 0.6969916254281998 + AUC SCORE = 0.539519906323185 + AUC SCORE THRESH 0.5918367346938775 = 0.5560597189695549\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.462, loss=0.689]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.66s/it, batch_loss=0.229, loss=0.721]\n",
      "EPOCH 5/15: Validation average loss: 0.721374407907327 + AUC SCORE = 0.5544496487119438 + AUC SCORE THRESH 0.5510204081632653 = 0.5665983606557377\n",
      "100%|███████████| 117/117 [11:14<00:00,  5.76s/it, batch_loss=0.525, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.02s/it, batch_loss=0.629, loss=0.721]\n",
      "EPOCH 6/15: Validation average loss: 0.7210925231377284 + AUC SCORE = 0.5559133489461358 + AUC SCORE THRESH 0.6122448979591836 = 0.571135831381733\n",
      "100%|███████████| 117/117 [11:18<00:00,  5.80s/it, batch_loss=0.805, loss=0.688]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.73s/it, batch_loss=0.461, loss=0.694]\n",
      "EPOCH 7/15: Validation average loss: 0.6943967928489049 + AUC SCORE = 0.5415690866510539 + AUC SCORE THRESH 0.5714285714285714 = 0.5739168618266979\n",
      "100%|███████████| 117/117 [11:11<00:00,  5.74s/it, batch_loss=0.509, loss=0.673]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:52<00:00,  1.75s/it, batch_loss=0.779, loss=0.71]\n",
      "EPOCH 8/15: Validation average loss: 0.7098765790462493 + AUC SCORE = 0.5128805620608898 + AUC SCORE THRESH 0.6122448979591836 = 0.5352751756440282\n",
      "100%|████████████| 117/117 [11:30<00:00,  5.90s/it, batch_loss=0.864, loss=0.68]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.78s/it, batch_loss=0.783, loss=0.723]\n",
      "EPOCH 9/15: Validation average loss: 0.7228919426600139 + AUC SCORE = 0.5272248243559718 + AUC SCORE THRESH 0.5510204081632653 = 0.5584016393442623\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.595, loss=0.665]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|██████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.74, loss=0.742]\n",
      "EPOCH 10/15: Validation average loss: 0.7418981492519379 + AUC SCORE = 0.498536299765808 + AUC SCORE THRESH 0.5918367346938775 = 0.5383489461358314\n",
      "100%|███████████| 117/117 [11:34<00:00,  5.93s/it, batch_loss=0.704, loss=0.657]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.03s/it, batch_loss=0.374, loss=0.738]\n",
      "EPOCH 11/15: Validation average loss: 0.7378725240627925 + AUC SCORE = 0.4795081967213115 + AUC SCORE THRESH 0.5306122448979591 = 0.5449355971896955\n",
      "100%|███████████| 117/117 [11:30<00:00,  5.90s/it, batch_loss=0.548, loss=0.652]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:01<00:00,  2.04s/it, batch_loss=0.774, loss=0.786]\n",
      "EPOCH 12/15: Validation average loss: 0.7856268147627513 + AUC SCORE = 0.42798594847775173 + AUC SCORE THRESH 0.836734693877551 = 0.5081967213114754\n",
      "100%|███████████| 117/117 [11:26<00:00,  5.87s/it, batch_loss=0.569, loss=0.651]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|██████████████| 30/30 [01:00<00:00,  2.02s/it, batch_loss=1.16, loss=0.806]\n",
      "EPOCH 13/15: Validation average loss: 0.8058923304080963 + AUC SCORE = 0.44057377049180335 + AUC SCORE THRESH 0.5306122448979591 = 0.5251756440281031\n",
      "100%|███████████| 117/117 [11:37<00:00,  5.96s/it, batch_loss=0.712, loss=0.631]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.796, loss=0.943]\n",
      "EPOCH 14/15: Validation average loss: 0.9430062651634217 + AUC SCORE = 0.4142271662763466 + AUC SCORE THRESH 0.18367346938775508 = 0.5177107728337236\n",
      "0.5685011709601874\n"
     ]
    }
   ],
   "source": [
    "!python3 ../rsnaresnet10/working/train.py --fold 0 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 1 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 2 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 3 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 4 --type T1wCE --model_name resnet10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../rsnaresnet10/working/validation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.dataset_utils import *\n",
    "from utils.classifier_utils import *\n",
    "\n",
    "import os\n",
    "\n",
    "import monai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format='%(asctime)s - %(message)s', datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "#import config\n",
    "#from dataset import BrainRSNADataset\n",
    "\n",
    "dir_path = \"../../RSNA-BTC-Datasets/train_mat\"\n",
    "test_dir_path = \"../../RSNA-BTC-Datasets/test_mat\"\n",
    "tumor_only_dir_path = \"../../RSNA-BTC-Datasets/ec_train_mat\"\n",
    "tumor_only_test_dir_path = \"../../RSNA-BTC-Datasets/ec_test_mat\"\n",
    "no_tumor_dir_path = \"../../RSNA-BTC-Datasets/no_tumor_train_mat\"\n",
    "#ext_test_1_dir_path = \"../../RSNA-BTC-Datasets/brats18_mat\"\n",
    "#ext_test_0_dir_path = \"../../RSNA-BTC-Datasets/OpenNeuroDS000221_ss_mat\"\n",
    "new_dir_path = \"../../RSNA-BTC-Datasets/UPENN-GBM_mat\"\n",
    "\n",
    "def generate_datasets(types):\n",
    "    data_packs = {}\n",
    "    ext = \"mat\"\n",
    "    transform = None\n",
    "    dims = 3\n",
    "    sel_slices = None\n",
    "    for t in types:\n",
    "        print(\"Type: \"+t)\n",
    "        # Competition Train + Val + Test\n",
    "        m_dataset_0 = Dataset(dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        logging.info(\"m0 Train/Val datasets size: {}\".format(len(m_dataset_0)))\n",
    "\n",
    "        m_dataset_1 = Dataset(dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "        \n",
    "        logging.info(\"m1 Train/Val datasets size: {}\".format(len(m_dataset_1)))\n",
    "\n",
    "        # External Train + Val + Test\n",
    "        #t_dataset_0 = Dataset(ext_test_0_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        #logging.info(\"Train/Val datasets size: {}\".format(len(t_dataset_0)))\n",
    "\n",
    "        #t_dataset_1 = Dataset(ext_test_1_dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        #logging.info(\"Train/Val datasets size: {}\".format(len(t_dataset_1)))\n",
    "\n",
    "        # UPENN Train + Val + Test\n",
    "        n_dataset_0 = Dataset(new_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        logging.info(\"n0 Train/Val datasets size: {}\".format(len(n_dataset_0)))\n",
    "\n",
    "        n_dataset_1 = Dataset(new_dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "        \n",
    "        logging.info(\"n1 Train/Val datasets size: {}\".format(len(n_dataset_1)))\n",
    "        \n",
    "        if t == \"KLF\" or t == \"T1wCE\":\n",
    "            # Competition (Tumor Only) Train + Val + Test\n",
    "            f_dataset_0 = Dataset(tumor_only_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "            logging.info(\"f0 Train/Val datasets size: {}\".format(len(f_dataset_0)))\n",
    "\n",
    "            f_dataset_1 = Dataset(tumor_only_dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "            logging.info(\"f1 Train/Val datasets size: {}\".format(len(f_dataset_1)))\n",
    "            \n",
    "            # Competition (No Tumor) Train + Val + Test\n",
    "            h_dataset_0 = Dataset(no_tumor_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "            logging.info(\"h0 Train/Val datasets size: {}\".format(len(h_dataset_0)))\n",
    "            \n",
    "            # Competition (Tumor Only) + UPENN Train + Val + Test\n",
    "            fn_dataset_0 = Dataset().concat_datasets(f_dataset_0, n_dataset_0)\n",
    "            \n",
    "            logging.info(\"fn0 Train/Val datasets size: {}\".format(len(fn_dataset_0)))\n",
    "            \n",
    "            fn_dataset_1 = Dataset().concat_datasets(f_dataset_1, n_dataset_1)\n",
    "            \n",
    "            logging.info(\"fn1 Train/Val datasets size: {}\".format(len(fn_dataset_1)))\n",
    "        \n",
    "        if t == \"KLF\" or t == \"T1wCE\":\n",
    "            data_packs[t] = {\n",
    "                \"m_dataset_0\": m_dataset_0,\n",
    "                \"m_dataset_1\": m_dataset_1,\n",
    "                \"f_dataset_0\": f_dataset_0,\n",
    "                \"f_dataset_1\": f_dataset_1,\n",
    "                \"h_dataset_0\": h_dataset_0,\n",
    "                #\"t_dataset_0\": t_dataset_0,\n",
    "                #\"t_dataset_1\": t_dataset_1,\n",
    "                \"n_dataset_0\": n_dataset_0,\n",
    "                \"n_dataset_1\": n_dataset_1,\n",
    "                \"fn_dataset_0\": fn_dataset_0,\n",
    "                \"fn_dataset_1\": fn_dataset_1\n",
    "            }\n",
    "        else:\n",
    "            data_packs[t] = {\n",
    "                \"m_dataset_0\": m_dataset_0,\n",
    "                \"m_dataset_1\": m_dataset_1,\n",
    "                #\"t_dataset_0\": t_dataset_0,\n",
    "                #\"t_dataset_1\": t_dataset_1,\n",
    "                \"n_dataset_0\": n_dataset_0,\n",
    "                \"n_dataset_1\": n_dataset_1\n",
    "            }\n",
    "    return data_packs\n",
    "\n",
    "def get_merged_dataset(dataset_0, dataset_1, k=1):\n",
    "    dataset_merged = Dataset().concat_datasets(dataset_0, dataset_1)\n",
    "    dataset_merged_no_tr = Dataset().concat_datasets(dataset_0, dataset_1, import_transform=False)\n",
    "\n",
    "    val_total_ratio = 0.2\n",
    "    is_k_fold = (k > 1)\n",
    "    splits = dataset_utils.get_splits(dataset_0, dataset_1, val_total_ratio, is_k_fold, 0.1, k)\n",
    "    print(splits)\n",
    "    return dataset_merged, dataset_merged_no_tr, splits\n",
    "\n",
    "def get_loaders(packs, batch_size):\n",
    "    loader_packs = {}\n",
    "    for t, pack in packs.items():\n",
    "        print(\"Type: \"+t)\n",
    "        m_dataset_merged, m_dataset_merged_no_tr, m_splits = get_merged_dataset(pack['m_dataset_0'], pack['m_dataset_1'])\n",
    "        n_dataset_merged, n_dataset_merged_no_tr, n_splits = get_merged_dataset(pack['n_dataset_0'], pack['n_dataset_1'])\n",
    "        #t_dataset_merged, t_dataset_merged_no_tr, t_splits = get_merged_dataset(pack['t_dataset_0'], pack['t_dataset_1'])\n",
    "        if t == \"KLF\" or t == \"T1wCE\":\n",
    "            f_dataset_merged, f_dataset_merged_no_tr, f_splits = get_merged_dataset(pack['f_dataset_0'], pack['f_dataset_1'])\n",
    "            h_dataset_merged, h_dataset_merged_no_tr, h_splits = get_merged_dataset(pack['h_dataset_0'], None)\n",
    "            fn_dataset_merged, fn_dataset_merged_no_tr, fn_splits = get_merged_dataset(pack['fn_dataset_0'], pack['fn_dataset_1'])\n",
    "        \n",
    "        m_dataloader = get_all_split_loaders(m_dataset_merged, m_dataset_merged_no_tr, m_splits, batch_size)\n",
    "        m_dataloaders = list(m_dataloader[0])\n",
    "        logging.info(\"(M) Train validation test splitted: {} {} {}\".format(len(m_splits[0][0]),len(m_splits[0][1]),len(m_splits[0][2])))\n",
    "\n",
    "        #t_dataloader = get_all_split_loaders(t_dataset_merged, t_dataset_merged_no_tr, t_splits, info[\"batch_size\"])\n",
    "        #t_dataloaders = list(t_dataloader[0])\n",
    "        #logging.info(\"(T) Train validation test splitted: {} {} {}\".format(len(t_splits[0][0]),len(t_splits[0][1]),len(t_splits[0][2])))\n",
    "\n",
    "        n_dataloader = get_all_split_loaders(n_dataset_merged, n_dataset_merged_no_tr, n_splits, batch_size)\n",
    "        n_dataloaders = list(n_dataloader[0])\n",
    "        logging.info(\"(N) Train validation test splitted: {} {} {}\".format(len(n_splits[0][0]),len(n_splits[0][1]),len(n_splits[0][2])))\n",
    "        \n",
    "        if t == \"KLF\" or t == \"T1wCE\":\n",
    "            f_dataloader = get_all_split_loaders(f_dataset_merged, f_dataset_merged_no_tr, f_splits, batch_size)\n",
    "            f_dataloaders = list(f_dataloader[0])\n",
    "            logging.info(\"(F) Train validation test splitted: {} {} {}\".format(len(f_splits[0][0]),len(f_splits[0][1]),len(f_splits[0][2])))\n",
    "            \n",
    "            h_dataloader = get_all_split_loaders(h_dataset_merged, h_dataset_merged_no_tr, h_splits, batch_size)\n",
    "            h_dataloaders = list(h_dataloader[0])\n",
    "            logging.info(\"(H) Train validation test splitted: {} {} {}\".format(len(h_splits[0][0]),len(h_splits[0][1]),len(h_splits[0][2])))\n",
    "\n",
    "            fn_dataloader = get_all_split_loaders(fn_dataset_merged, fn_dataset_merged_no_tr, fn_splits, batch_size)\n",
    "            fn_dataloaders = list(fn_dataloader[0])\n",
    "            logging.info(\"(FN) Train validation test splitted: {} {} {}\".format(len(fn_splits[0][0]),len(fn_splits[0][1]),len(fn_splits[0][2])))\n",
    "        \n",
    "        if t == \"KLF\" or t == \"T1wCE\":\n",
    "            loader_packs[t] = {\n",
    "                \"m_dataloaders\": m_dataloaders,\n",
    "                \"f_dataloaders\": f_dataloaders,\n",
    "                \"h_dataloaders\": h_dataloaders,\n",
    "                \"n_dataloaders\": n_dataloaders,\n",
    "                #\"t_dataloaders\": t_dataloaders,\n",
    "                \"fn_dataloaders\": fn_dataloaders\n",
    "            }\n",
    "        else:\n",
    "            loader_packs[t] = {\n",
    "                \"m_dataloaders\": m_dataloaders,\n",
    "                \"n_dataloaders\": n_dataloaders,\n",
    "                #\"t_dataloaders\": t_dataloaders\n",
    "            }\n",
    "        \n",
    "    return loader_packs\n",
    "\n",
    "import importlib\n",
    "from utils import dataset_utils\n",
    "importlib.reload(dataset_utils)\n",
    "\n",
    "def train_model(train_dl, validation_dl, fold_number, mri_type, model_name, epochs):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.5, last_epoch=-1, verbose=True)\n",
    "\n",
    "    model.zero_grad()\n",
    "    model.to(device)\n",
    "    best_loss = 9999\n",
    "    best_auc = 0\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    train_writer = SummaryWriter()\n",
    "    for counter in range(epochs):\n",
    "\n",
    "        epoch_iterator_train = tqdm(train_dl)\n",
    "        tr_loss = 0.0\n",
    "        for step, batch in enumerate(epoch_iterator_train):\n",
    "            model.train()\n",
    "            (img_ids, imgs, labels) = batch\n",
    "            images, targets = imgs[0].to(device), labels.to(device)\n",
    "            #images, targets = batch[\"image\"].to(device), batch[\"target\"].to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            targets = targets  # .view(-1, 1)\n",
    "            loss = criterion(outputs.squeeze(1), targets.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            epoch_iterator_train.set_postfix(\n",
    "                batch_loss=(loss.item()), loss=(tr_loss / (step + 1))\n",
    "            )\n",
    "\n",
    "        train_writer.add_scalar('loss', (tr_loss/(step+1)), counter+1)\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            preds = []\n",
    "            true_labels = []\n",
    "            case_ids = []\n",
    "            epoch_iterator_val = tqdm(validation_dl)\n",
    "            for step, batch in enumerate(epoch_iterator_val):\n",
    "                model.eval()\n",
    "                (img_ids, imgs, labels) = batch\n",
    "                images, targets = imgs[0].to(device), labels.to(device)\n",
    "                #images, targets = batch[\"image\"].to(device), batch[\"target\"].to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                targets = targets  # .view(-1, 1)\n",
    "                loss = criterion(outputs.squeeze(1), targets.float())\n",
    "                val_loss += loss.item()\n",
    "                epoch_iterator_val.set_postfix(\n",
    "                    batch_loss=(loss.item()), loss=(val_loss / (step + 1))\n",
    "                )\n",
    "                preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "                true_labels.append(targets.cpu().numpy())\n",
    "                #case_ids.append(batch[\"case_id\"])\n",
    "                if img_ids[0][0][0].isnumeric():\n",
    "                    img_ids_fixed = [img_id[:5] for img_id in img_ids[0]]\n",
    "                else:\n",
    "                    img_ids_fixed = [img_id[:-4] for img_id in img_ids[0]]\n",
    "                case_ids.append(img_ids_fixed)\n",
    "        preds = np.vstack(preds).T[0].tolist()\n",
    "        true_labels = np.hstack(true_labels).tolist()\n",
    "        case_ids = np.hstack(case_ids).tolist()\n",
    "        auc_score = roc_auc_score(true_labels, preds)\n",
    "        auc_score_adj_best = 0\n",
    "        for thresh in np.linspace(0, 1, 50):\n",
    "            auc_score_adj = roc_auc_score(true_labels, list(np.array(preds) > thresh))\n",
    "            if auc_score_adj > auc_score_adj_best:\n",
    "                best_thresh = thresh\n",
    "                auc_score_adj_best = auc_score_adj\n",
    "\n",
    "        print(\n",
    "            f\"EPOCH {counter+1}/{epochs}: Validation average loss: {val_loss/(step+1)} + AUC SCORE = {auc_score} + AUC SCORE THRESH {best_thresh} = {auc_score_adj_best}\"\n",
    "        )\n",
    "        train_writer.add_scalar('val_loss', val_loss/(step+1), counter+1)\n",
    "        train_writer.add_scalar('val_auc', auc_score, counter+1)\n",
    "        if auc_score > best_auc:\n",
    "            print(\"Saving the model...\")\n",
    "            date_time = datetime.now()\n",
    "            date_str = date_time.strftime(\"%b%d_%H-%M-%S\")\n",
    "    \n",
    "            #modelname = model.__class__.__name__\n",
    "        \n",
    "            model_fullname = f\"{model_name}_{date_str}\"\n",
    "\n",
    "            if not os.path.exists(\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/\"):\n",
    "                os.mkdir(\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/\")\n",
    "            if not os.path.exists(f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/{model_fullname}\"):\n",
    "                os.mkdir(f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/{model_fullname}\")\n",
    "            all_files = os.listdir(f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/{model_fullname}\")\n",
    "\n",
    "            for f in all_files:\n",
    "                if f\"{model_name}_{mri_type}_fold{fold_number}\" in f:\n",
    "                    os.remove(f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/{model_fullname}/{f}\")\n",
    "\n",
    "            best_auc = auc_score\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/{model_fullname}/3d-{model_name}_{mri_type}_fold{fold_number}_{round(best_auc,3)}.pth\",\n",
    "            )\n",
    "\n",
    "    print(best_auc)\n",
    "\n",
    "def train_folded_models(fold, mri_type, model_name, batch_size, epochs, train_origins):\n",
    "    #data = pd.read_csv(\"train.csv\")\n",
    "    #train_df = data[data.fold != fold].reset_index(drop=False)\n",
    "    #val_df = data[data.fold == fold].reset_index(drop=False)\n",
    "    \n",
    "    print(f\"train_{mri_type}_{fold}\")\n",
    "    #train_dataset = BrainRSNADataset(data=train_df, mri_type=args.type, ds_type=f\"train_{args.type}_{args.fold}\")\n",
    "\n",
    "    #valid_dataset = BrainRSNADataset(data=val_df, mri_type=args.type, ds_type=f\"val_{args.type}_{args.fold}\")\n",
    "\n",
    "    ##packs = generate_datasets([mri_type])\n",
    "    \n",
    "    loader_packs = {}\n",
    "    for t, pack in packs.items():\n",
    "        print(\"Type: \"+t)\n",
    "        m_dataset_merged, m_dataset_merged_no_tr, m_splits = get_merged_dataset(pack['m_dataset_0'], pack['m_dataset_1'], fold)\n",
    "        n_dataset_merged, n_dataset_merged_no_tr, n_splits = get_merged_dataset(pack['n_dataset_0'], pack['n_dataset_1'], fold)\n",
    "        fn_dataset_merged, fn_dataset_merged_no_tr, fn_splits = get_merged_dataset(pack['fn_dataset_0'], pack['fn_dataset_1'], fold)\n",
    "        f_dataset_merged, f_dataset_merged_no_tr, f_splits = get_merged_dataset(pack['f_dataset_0'], pack['f_dataset_1'], fold)\n",
    "        print(\"SPLITS:\")\n",
    "        print(\"- folds:\")\n",
    "        print(len(m_splits))\n",
    "        print(\"- splits per fold:\")\n",
    "        print(len(m_splits[0]))\n",
    "        #print(len(n_splits))\n",
    "        for to in train_origins:\n",
    "            if to == \"m\":\n",
    "                i = 0\n",
    "                for split in m_splits:\n",
    "                    m_dataloader = get_all_split_loaders(m_dataset_merged, m_dataset_merged_no_tr, [split], batch_size)\n",
    "                    m_dataloaders = list(m_dataloader[0])\n",
    "                    print(f\"(M) Train validation splitted: {len(split[0])} {len(split[1])}\")\n",
    "                    print(m_dataloaders)\n",
    "                    train_dl = m_dataloaders[0]\n",
    "                    validation_dl = m_dataloaders[1]\n",
    "                    train_model(train_dl, validation_dl, i, mri_type, model_name+\"_m\", epochs)\n",
    "                    \"\"\"\n",
    "                    device = torch.device(\"cuda\")\n",
    "                    model = monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1)\n",
    "                    model.to(device)\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "                    criterion = nn.BCEWithLogitsLoss()\n",
    "                    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.5, last_epoch=-1, verbose=True)\n",
    "                    trainer = Trainer(\n",
    "                        model, \n",
    "                        device, \n",
    "                        optimizer, \n",
    "                        criterion,\n",
    "                        scheduler,\n",
    "                        1\n",
    "                    )\n",
    "\n",
    "                    history = trainer.fit(\n",
    "                        device,\n",
    "                        epochs, \n",
    "                        train_dl,\n",
    "                        validation_dl,\n",
    "                        model_name+\"_m\", \n",
    "                        15\n",
    "                    )\n",
    "\n",
    "                    trainer.train_writer.flush()\n",
    "                    \"\"\"\n",
    "                    i += 1\n",
    "\n",
    "            elif to == \"n\":\n",
    "                i = 0\n",
    "                for split in n_splits:\n",
    "                    n_dataloader = get_all_split_loaders(n_dataset_merged, n_dataset_merged_no_tr, [split], batch_size)\n",
    "                    n_dataloaders = list(n_dataloader[0])\n",
    "                    print(f\"(N) Train validation splitted: {len(split[0])} {len(split[1])}\")\n",
    "                    train_dl = n_dataloaders[0]\n",
    "                    validation_dl = n_dataloaders[1]\n",
    "                    train_model(train_dl, validation_dl, i, mri_type, model_name+\"_n\", epochs)\n",
    "                    i += 1\n",
    "            elif to == \"fn\":\n",
    "                i = 0\n",
    "                for split in fn_splits:\n",
    "                    print(f\"Fold n.{i} started\")\n",
    "                    fn_dataloader = get_all_split_loaders(fn_dataset_merged, fn_dataset_merged_no_tr, [split], batch_size)\n",
    "                    fn_dataloaders = list(fn_dataloader[0])\n",
    "                    print(f\"(FN) Train validation splitted: {len(split[0])} {len(split[1])}\")\n",
    "                    train_dl = fn_dataloaders[0]\n",
    "                    validation_dl = fn_dataloaders[1]\n",
    "                    train_model(train_dl, validation_dl, i, mri_type, model_name+\"_fn\", epochs)\n",
    "                    i += 1\n",
    "            elif to == \"f\":\n",
    "                i = 0\n",
    "                for split in f_splits:\n",
    "                    f_dataloader = get_all_split_loaders(f_dataset_merged, f_dataset_merged_no_tr, [split], batch_size)\n",
    "                    f_dataloaders = list(f_dataloader[0])\n",
    "                    print(f\"(F) Train validation splitted: {len(split[0])} {len(split[1])}\")\n",
    "                    train_dl = f_dataloaders[0]\n",
    "                    validation_dl = f_dataloaders[1]\n",
    "                    train_model(train_dl, validation_dl, i, mri_type, model_name+\"_f\", epochs)\n",
    "                    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14356929"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce RTX 3090\n",
      "1.12.1\n",
      "11.3\n",
      "tensor([-1.2654], device='cuda:0')\n",
      "2022-08-09 19:35:23 - Printing one: 1\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\"\"\"\n",
    "for file in os.listdir(no_tumor_dir_path+\"/KLF/0\"):\n",
    "    fixed_file = file[:-7]+\"T1wCE.mat\"\n",
    "    shutil.copy(dir_path+\"/T1wCE/0/\"+fixed_file, no_tumor_dir_path+\"/T1wCE/0/\"+fixed_file)\n",
    "    \n",
    "for file in os.listdir(tumor_only_dir_path+\"/KLF/0\"):\n",
    "    fixed_file = file[:-7]+\"T1wCE.mat\"\n",
    "    shutil.copy(dir_path+\"/T1wCE/0/\"+fixed_file, tumor_only_dir_path+\"/T1wCE/0/\"+fixed_file)\n",
    "    \n",
    "for file in os.listdir(tumor_only_dir_path+\"/KLF/1\"):\n",
    "    fixed_file = file[:-7]+\"T1wCE.mat\"\n",
    "    shutil.copy(dir_path+\"/T1wCE/1/\"+fixed_file, tumor_only_dir_path+\"/T1wCE/1/\"+fixed_file)\n",
    "\"\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "x = torch.randn(1).cuda()\n",
    "print(x)\n",
    "logging.info(\"Printing one: {}\".format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: T1wCE\n",
      "2022-08-09 19:35:24 - m0 Train/Val datasets size: 270\n",
      "2022-08-09 19:35:24 - m1 Train/Val datasets size: 303\n",
      "2022-08-09 19:35:24 - n0 Train/Val datasets size: 170\n",
      "2022-08-09 19:35:24 - n1 Train/Val datasets size: 121\n",
      "2022-08-09 19:35:24 - f0 Train/Val datasets size: 129\n",
      "2022-08-09 19:35:24 - f1 Train/Val datasets size: 273\n",
      "2022-08-09 19:35:24 - h0 Train/Val datasets size: 141\n",
      "Length of concatenated dataset: 340\n",
      "2022-08-09 19:35:24 - fn0 Train/Val datasets size: 340\n",
      "Length of concatenated dataset: 546\n",
      "2022-08-09 19:35:24 - fn1 Train/Val datasets size: 546\n",
      "Type: T1wCE\n",
      "Length of concatenated dataset: 606\n",
      "Length of concatenated dataset: 606\n",
      "Train Idx:\n",
      "[238, 137, 106, 284, 44, 139, 247, 288, 156, 297, 252, 54, 234, 18, 205, 254, 182, 56, 71, 144, 249, 209, 290, 219, 158, 176, 33, 83, 136, 210, 118, 60, 159, 282, 110, 21, 29, 150, 16, 75, 109, 179, 283, 4, 96, 229, 61, 67, 295, 266, 171, 281, 40, 189, 13, 107, 200, 3, 161, 125, 24, 30, 77, 279, 190, 19, 257, 235, 268, 80, 51, 2, 239, 104, 262, 86, 10, 224, 58, 41, 14, 155, 50, 215, 237, 123, 220, 62, 191, 230, 130, 213, 187, 43, 114, 138, 199, 222, 149, 112, 298, 98, 221, 93, 208, 162, 36, 178, 113, 0, 94, 294, 95, 299, 263, 256, 69, 49, 48, 85, 300, 141, 207, 23, 250, 148, 143, 78, 180, 100, 204, 131, 269, 301, 196, 6, 68, 203, 84, 170, 121, 140, 258, 276, 142, 259, 91, 82, 285, 11, 119, 102, 35, 57, 169, 231, 65, 1, 120, 267, 186, 42, 105, 132, 79, 17, 271, 38, 53, 260, 128, 28, 183, 163, 151, 244, 202, 31, 32, 127, 185, 280, 273, 147, 278, 177, 99, 197, 243, 115, 265, 72, 25, 165, 289, 174, 291, 39, 193, 88, 70, 87, 292, 242, 277, 211, 9, 195, 251, 192, 117, 47, 172, 516, 380, 549, 365, 554, 536, 489, 433, 486, 369, 338, 320, 465, 589, 448, 528, 499, 348, 353, 360, 556, 547, 531, 544, 335, 381, 449, 436, 399, 517, 401, 505, 471, 392, 543, 561, 550, 435, 349, 500, 410, 473, 303, 542, 374, 579, 405, 370, 411, 525, 387, 584, 557, 428, 539, 412, 329, 484, 602, 545, 490, 437, 372, 402, 527, 521, 342, 496, 493, 432, 551, 443, 434, 564, 416, 321, 379, 495, 552, 414, 479, 312, 492, 462, 599, 346, 394, 407, 441, 478, 415, 371, 339, 513, 368, 345, 429, 306, 420, 451, 596, 580, 574, 431, 485, 440, 600, 310, 389, 482, 422, 569, 418, 464, 332, 458, 563, 488, 404, 400, 323, 456, 357, 333, 583, 352, 403, 565, 594, 454, 417, 359, 447, 363, 497, 535, 515, 502, 601, 309, 562, 311, 520, 382, 576, 511, 577, 546, 568, 470, 341, 373, 424, 582, 347, 603, 597, 480, 361, 466, 427, 457, 383, 362, 595, 351, 356, 461, 354, 575, 522, 377, 307, 442, 510, 590, 559, 308, 444, 364, 438, 386, 530, 325, 573, 523, 506, 423, 384, 316, 587, 375, 450, 463, 390, 541, 605, 439, 498, 494, 419, 327, 397, 467, 409, 319, 366, 408, 512, 331, 504, 477, 396]\n",
      "Val Idx:\n",
      "[225, 152, 228, 201, 52, 245, 175, 168, 223, 217, 111, 135, 218, 12, 15, 66, 97, 90, 198, 103, 22, 212, 226, 264, 133, 216, 275, 270, 154, 55, 194, 255, 134, 8, 157, 241, 240, 81, 214, 167, 5, 59, 92, 274, 34, 145, 116, 188, 246, 7, 45, 129, 122, 63, 124, 227, 146, 302, 26, 108, 560, 472, 367, 518, 487, 343, 514, 459, 588, 426, 524, 355, 538, 566, 395, 474, 425, 468, 558, 324, 567, 326, 591, 328, 592, 571, 337, 322, 314, 391, 421, 586, 453, 455, 508, 570, 491, 406, 501, 388, 378, 534, 452, 598, 385, 578, 315, 336, 581, 555, 413, 507, 334, 445, 529, 330, 340, 317, 604, 481]\n",
      "Test Idx:\n",
      "[89, 74, 153, 64, 296, 287, 286, 236, 126, 73, 20, 46, 160, 232, 181, 27, 173, 261, 37, 101, 166, 233, 184, 164, 206, 248, 253, 293, 76, 272, 305, 585, 304, 475, 476, 533, 548, 553, 344, 318, 393, 483, 532, 509, 540, 313, 430, 350, 526, 572, 460, 446, 398, 469, 537, 593, 358, 376, 519, 503]\n",
      "[([238, 137, 106, 284, 44, 139, 247, 288, 156, 297, 252, 54, 234, 18, 205, 254, 182, 56, 71, 144, 249, 209, 290, 219, 158, 176, 33, 83, 136, 210, 118, 60, 159, 282, 110, 21, 29, 150, 16, 75, 109, 179, 283, 4, 96, 229, 61, 67, 295, 266, 171, 281, 40, 189, 13, 107, 200, 3, 161, 125, 24, 30, 77, 279, 190, 19, 257, 235, 268, 80, 51, 2, 239, 104, 262, 86, 10, 224, 58, 41, 14, 155, 50, 215, 237, 123, 220, 62, 191, 230, 130, 213, 187, 43, 114, 138, 199, 222, 149, 112, 298, 98, 221, 93, 208, 162, 36, 178, 113, 0, 94, 294, 95, 299, 263, 256, 69, 49, 48, 85, 300, 141, 207, 23, 250, 148, 143, 78, 180, 100, 204, 131, 269, 301, 196, 6, 68, 203, 84, 170, 121, 140, 258, 276, 142, 259, 91, 82, 285, 11, 119, 102, 35, 57, 169, 231, 65, 1, 120, 267, 186, 42, 105, 132, 79, 17, 271, 38, 53, 260, 128, 28, 183, 163, 151, 244, 202, 31, 32, 127, 185, 280, 273, 147, 278, 177, 99, 197, 243, 115, 265, 72, 25, 165, 289, 174, 291, 39, 193, 88, 70, 87, 292, 242, 277, 211, 9, 195, 251, 192, 117, 47, 172, 516, 380, 549, 365, 554, 536, 489, 433, 486, 369, 338, 320, 465, 589, 448, 528, 499, 348, 353, 360, 556, 547, 531, 544, 335, 381, 449, 436, 399, 517, 401, 505, 471, 392, 543, 561, 550, 435, 349, 500, 410, 473, 303, 542, 374, 579, 405, 370, 411, 525, 387, 584, 557, 428, 539, 412, 329, 484, 602, 545, 490, 437, 372, 402, 527, 521, 342, 496, 493, 432, 551, 443, 434, 564, 416, 321, 379, 495, 552, 414, 479, 312, 492, 462, 599, 346, 394, 407, 441, 478, 415, 371, 339, 513, 368, 345, 429, 306, 420, 451, 596, 580, 574, 431, 485, 440, 600, 310, 389, 482, 422, 569, 418, 464, 332, 458, 563, 488, 404, 400, 323, 456, 357, 333, 583, 352, 403, 565, 594, 454, 417, 359, 447, 363, 497, 535, 515, 502, 601, 309, 562, 311, 520, 382, 576, 511, 577, 546, 568, 470, 341, 373, 424, 582, 347, 603, 597, 480, 361, 466, 427, 457, 383, 362, 595, 351, 356, 461, 354, 575, 522, 377, 307, 442, 510, 590, 559, 308, 444, 364, 438, 386, 530, 325, 573, 523, 506, 423, 384, 316, 587, 375, 450, 463, 390, 541, 605, 439, 498, 494, 419, 327, 397, 467, 409, 319, 366, 408, 512, 331, 504, 477, 396], [225, 152, 228, 201, 52, 245, 175, 168, 223, 217, 111, 135, 218, 12, 15, 66, 97, 90, 198, 103, 22, 212, 226, 264, 133, 216, 275, 270, 154, 55, 194, 255, 134, 8, 157, 241, 240, 81, 214, 167, 5, 59, 92, 274, 34, 145, 116, 188, 246, 7, 45, 129, 122, 63, 124, 227, 146, 302, 26, 108, 560, 472, 367, 518, 487, 343, 514, 459, 588, 426, 524, 355, 538, 566, 395, 474, 425, 468, 558, 324, 567, 326, 591, 328, 592, 571, 337, 322, 314, 391, 421, 586, 453, 455, 508, 570, 491, 406, 501, 388, 378, 534, 452, 598, 385, 578, 315, 336, 581, 555, 413, 507, 334, 445, 529, 330, 340, 317, 604, 481], [89, 74, 153, 64, 296, 287, 286, 236, 126, 73, 20, 46, 160, 232, 181, 27, 173, 261, 37, 101, 166, 233, 184, 164, 206, 248, 253, 293, 76, 272, 305, 585, 304, 475, 476, 533, 548, 553, 344, 318, 393, 483, 532, 509, 540, 313, 430, 350, 526, 572, 460, 446, 398, 469, 537, 593, 358, 376, 519, 503])]\n",
      "Length of concatenated dataset: 546\n",
      "Length of concatenated dataset: 546\n",
      "Train Idx:\n",
      "[33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441]\n",
      "Val Idx:\n",
      "[218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529]\n",
      "Test Idx:\n",
      "[201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358]\n",
      "[([33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441], [218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529], [201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358])]\n",
      "Length of concatenated dataset: 546\n",
      "Length of concatenated dataset: 546\n",
      "Train Idx:\n",
      "[33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441]\n",
      "Val Idx:\n",
      "[218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529]\n",
      "Test Idx:\n",
      "[201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358]\n",
      "[([33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441], [218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529], [201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358])]\n",
      "Length of concatenated dataset: 141\n",
      "Length of concatenated dataset: 141\n",
      "Train Idx:\n",
      "[112, 78, 132, 68, 93, 85, 48, 135, 13, 92, 95, 73, 119, 15, 116, 40, 62, 128, 138, 3, 52, 63, 113, 6, 139, 12, 86, 104, 109, 127, 11, 94, 110, 41, 101, 1, 97, 130, 42, 4, 114, 17, 38, 5, 53, 134, 89, 0, 34, 28, 55, 75, 35, 23, 74, 31, 102, 57, 120, 65, 32, 129, 14, 106, 19, 29, 49, 126, 99, 82, 64, 140, 79, 69, 118, 80, 115, 20, 136, 72, 77, 25, 37, 81, 131, 46, 133, 39, 58, 88, 70, 87, 36, 21, 9, 103, 67, 117, 47]\n",
      "Val Idx:\n",
      "[45, 60, 7, 51, 66, 27, 71, 54, 123, 8, 76, 16, 125, 122, 124, 98, 105, 83, 33, 56, 91, 22, 137, 24, 2, 111, 26, 121]\n",
      "Test Idx:\n",
      "[18, 10, 96, 43, 100, 108, 50, 84, 61, 107, 90, 59, 44, 30]\n",
      "[([112, 78, 132, 68, 93, 85, 48, 135, 13, 92, 95, 73, 119, 15, 116, 40, 62, 128, 138, 3, 52, 63, 113, 6, 139, 12, 86, 104, 109, 127, 11, 94, 110, 41, 101, 1, 97, 130, 42, 4, 114, 17, 38, 5, 53, 134, 89, 0, 34, 28, 55, 75, 35, 23, 74, 31, 102, 57, 120, 65, 32, 129, 14, 106, 19, 29, 49, 126, 99, 82, 64, 140, 79, 69, 118, 80, 115, 20, 136, 72, 77, 25, 37, 81, 131, 46, 133, 39, 58, 88, 70, 87, 36, 21, 9, 103, 67, 117, 47], [45, 60, 7, 51, 66, 27, 71, 54, 123, 8, 76, 16, 125, 122, 124, 98, 105, 83, 33, 56, 91, 22, 137, 24, 2, 111, 26, 121], [18, 10, 96, 43, 100, 108, 50, 84, 61, 107, 90, 59, 44, 30])]\n",
      "Length of concatenated dataset: 1092\n",
      "Length of concatenated dataset: 1092\n",
      "Train Idx:\n",
      "[386, 463, 206, 38, 188, 361, 339, 272, 289, 437, 462, 124, 154, 526, 59, 252, 466, 491, 541, 235, 211, 420, 55, 171, 233, 205, 158, 385, 34, 367, 18, 506, 247, 529, 52, 74, 26, 173, 92, 167, 4, 435, 181, 246, 443, 5, 141, 301, 200, 135, 263, 122, 22, 68, 210, 20, 306, 336, 14, 170, 374, 281, 271, 220, 537, 64, 520, 250, 120, 81, 421, 500, 240, 308, 534, 528, 160, 536, 238, 497, 484, 392, 478, 465, 51, 195, 191, 116, 342, 395, 164, 106, 372, 63, 511, 284, 519, 445, 316, 93, 366, 332, 198, 145, 150, 39, 495, 439, 253, 344, 464, 2, 221, 514, 146, 241, 538, 114, 391, 176, 168, 515, 346, 513, 136, 424, 254, 476, 299, 457, 432, 255, 232, 133, 33, 88, 290, 44, 61, 199, 505, 525, 544, 340, 218, 302, 297, 73, 295, 35, 467, 29, 427, 446, 412, 309, 523, 217, 27, 469, 347, 156, 493, 409, 138, 212, 104, 414, 410, 416, 215, 521, 189, 214, 501, 204, 234, 259, 67, 24, 216, 300, 223, 129, 111, 166, 498, 470, 40, 274, 422, 79, 403, 468, 327, 13, 287, 326, 489, 251, 228, 415, 161, 83, 117, 25, 110, 149, 152, 16, 402, 331, 109, 417, 139, 237, 260, 352, 527, 317, 323, 477, 248, 389, 479, 19, 328, 296, 447, 269, 363, 226, 458, 3, 413, 125, 280, 286, 77, 184, 371, 461, 535, 275, 294, 517, 182, 32, 80, 307, 258, 11, 360, 440, 86, 266, 36, 193, 58, 41, 270, 411, 50, 209, 474, 473, 496, 123, 222, 419, 62, 449, 377, 130, 187, 23, 444, 43, 370, 394, 0, 383, 201, 405, 368, 522, 98, 387, 349, 304, 418, 292, 178, 369, 256, 94, 197, 95, 531, 163, 169, 69, 305, 48, 341, 373, 397, 207, 279, 509, 227, 148, 143, 334, 180, 356, 460, 131, 127, 47, 452, 262, 324, 203, 84, 426, 121, 539, 516, 530, 398, 384, 91, 82, 430, 267, 119, 358, 291, 57, 425, 487, 321, 257, 376, 31, 442, 42, 105, 388, 335, 273, 488, 53, 518, 128, 28, 183, 459, 510, 151, 244, 265, 288, 423, 147, 177, 99, 448, 431, 115, 72, 174, 87, 486, 314, 396, 472, 70, 277, 9, 359, 192, 1064, 1012, 998, 663, 1010, 712, 953, 551, 937, 791, 548, 866, 748, 628, 786, 790, 821, 572, 1052, 1049, 1007, 976, 685, 1070, 568, 693, 964, 982, 589, 799, 1041, 587, 794, 680, 635, 842, 737, 657, 851, 988, 898, 746, 569, 611, 1072, 1027, 930, 562, 672, 829, 640, 575, 800, 766, 967, 1063, 734, 854, 715, 844, 606, 760, 907, 947, 1087, 652, 694, 550, 793, 576, 843, 714, 816, 911, 1037, 879, 675, 1055, 987, 1019, 755, 642, 554, 653, 565, 647, 863, 874, 939, 1051, 658, 951, 968, 965, 709, 600, 940, 557, 660, 868, 1078, 833, 1089, 881, 553, 774, 1025, 776, 870, 736, 1033, 691, 855, 801, 1057, 1068, 960, 690, 607, 974, 798, 753, 761, 1043, 626, 952, 1003, 841, 1004, 700, 807, 999, 629, 838, 696, 639, 869, 991, 956, 641, 659, 605, 583, 689, 704, 586, 969, 941, 886, 759, 897, 782, 638, 932, 559, 958, 1077, 695, 972, 1036, 608, 625, 845, 739, 1001, 727, 1013, 989, 555, 996, 980, 1006, 853, 1085, 877, 950, 808, 552, 812, 803, 584, 697, 579, 1005, 817, 686, 1029, 740, 1061, 674, 1075, 1071, 957, 1031, 596, 708, 901, 1090, 914, 1032, 546, 856, 1038, 757, 718, 741, 977, 1008, 830, 669, 780, 585, 820, 1066, 702, 768, 822, 756, 890, 852, 763, 645, 835, 924, 713, 771, 650, 995, 556, 651, 614, 636, 1067, 919, 926, 1028, 779, 910, 918, 804, 811, 648, 850, 726, 889, 574, 588, 754, 566, 921, 1076, 630, 1044, 1073, 831, 1045, 617, 595, 725, 1069, 973, 662, 839, 622, 594, 1015, 809, 806, 692, 619, 992, 878, 610, 656, 598, 909, 1083, 955, 670, 633, 661, 1074, 834, 920, 848, 664, 558, 703, 883, 963, 673, 592, 781, 983, 681, 787, 899, 948, 707, 1056, 985, 723, 604, 710, 970, 871, 677, 698, 896, 993, 1023, 563, 934, 732, 743, 884, 752, 1080, 933, 891, 1021, 859, 788, 1079, 997, 716, 733, 593, 679, 847, 745, 618, 864, 624, 984, 620, 892, 942, 744, 935, 931, 929, 711, 665, 1040, 699, 946, 1016, 775, 975, 567, 827, 938, 796, 789, 783, 581, 1053, 1088, 875, 655, 925, 717, 784, 549, 836, 994, 867, 666, 701, 684, 671, 1002, 612, 720, 1054, 724, 767, 961, 646, 792, 765, 880]\n",
      "Val Idx:\n",
      "[85, 436, 96, 186, 134, 37, 450, 90, 502, 179, 140, 429, 66, 325, 285, 330, 196, 393, 137, 298, 407, 337, 503, 278, 230, 320, 175, 338, 162, 142, 451, 311, 261, 485, 113, 225, 242, 243, 15, 155, 380, 283, 17, 303, 475, 355, 353, 45, 532, 365, 456, 185, 406, 504, 512, 345, 438, 249, 433, 540, 224, 348, 108, 89, 401, 46, 102, 239, 21, 107, 315, 208, 103, 71, 75, 313, 78, 378, 357, 441, 379, 322, 310, 190, 236, 480, 219, 318, 381, 351, 157, 159, 276, 481, 492, 153, 268, 350, 1, 172, 12, 132, 390, 453, 434, 483, 245, 76, 229, 959, 1030, 887, 922, 876, 573, 917, 905, 865, 1039, 1062, 1058, 1020, 893, 1014, 772, 560, 903, 582, 637, 885, 1017, 826, 916, 1048, 615, 810, 928, 966, 1060, 616, 778, 872, 923, 764, 900, 936, 979, 1050, 735, 1091, 861, 832, 1035, 577, 873, 912, 578, 777, 986, 795, 621, 762, 785, 590, 602, 944, 742, 705, 631, 906, 580, 888, 846, 1082, 682, 773, 815, 1011, 1047, 915, 1046, 849, 1022, 688, 913, 721, 981, 954, 599, 564, 547, 758, 609, 769, 840, 818, 978, 728, 882, 654, 908, 747, 837, 927, 722, 824, 814, 862, 603, 632, 797, 1084, 949, 945, 613, 683, 601, 667]\n",
      "Test Idx:\n",
      "[312, 118, 400, 543, 202, 165, 508, 454, 264, 524, 455, 329, 375, 10, 482, 112, 282, 343, 293, 542, 65, 404, 126, 490, 545, 231, 213, 408, 194, 7, 507, 499, 494, 533, 471, 101, 97, 382, 54, 30, 364, 49, 100, 428, 362, 319, 399, 56, 144, 60, 6, 8, 354, 333, 823, 1024, 749, 813, 649, 1081, 1065, 1042, 561, 802, 904, 719, 770, 1000, 1026, 962, 805, 751, 943, 597, 729, 706, 902, 857, 591, 1018, 731, 571, 894, 738, 643, 1009, 750, 860, 895, 668, 1059, 644, 627, 687, 730, 623, 828, 990, 676, 858, 570, 678, 819, 971, 825, 634, 1086, 1034]\n",
      "[([386, 463, 206, 38, 188, 361, 339, 272, 289, 437, 462, 124, 154, 526, 59, 252, 466, 491, 541, 235, 211, 420, 55, 171, 233, 205, 158, 385, 34, 367, 18, 506, 247, 529, 52, 74, 26, 173, 92, 167, 4, 435, 181, 246, 443, 5, 141, 301, 200, 135, 263, 122, 22, 68, 210, 20, 306, 336, 14, 170, 374, 281, 271, 220, 537, 64, 520, 250, 120, 81, 421, 500, 240, 308, 534, 528, 160, 536, 238, 497, 484, 392, 478, 465, 51, 195, 191, 116, 342, 395, 164, 106, 372, 63, 511, 284, 519, 445, 316, 93, 366, 332, 198, 145, 150, 39, 495, 439, 253, 344, 464, 2, 221, 514, 146, 241, 538, 114, 391, 176, 168, 515, 346, 513, 136, 424, 254, 476, 299, 457, 432, 255, 232, 133, 33, 88, 290, 44, 61, 199, 505, 525, 544, 340, 218, 302, 297, 73, 295, 35, 467, 29, 427, 446, 412, 309, 523, 217, 27, 469, 347, 156, 493, 409, 138, 212, 104, 414, 410, 416, 215, 521, 189, 214, 501, 204, 234, 259, 67, 24, 216, 300, 223, 129, 111, 166, 498, 470, 40, 274, 422, 79, 403, 468, 327, 13, 287, 326, 489, 251, 228, 415, 161, 83, 117, 25, 110, 149, 152, 16, 402, 331, 109, 417, 139, 237, 260, 352, 527, 317, 323, 477, 248, 389, 479, 19, 328, 296, 447, 269, 363, 226, 458, 3, 413, 125, 280, 286, 77, 184, 371, 461, 535, 275, 294, 517, 182, 32, 80, 307, 258, 11, 360, 440, 86, 266, 36, 193, 58, 41, 270, 411, 50, 209, 474, 473, 496, 123, 222, 419, 62, 449, 377, 130, 187, 23, 444, 43, 370, 394, 0, 383, 201, 405, 368, 522, 98, 387, 349, 304, 418, 292, 178, 369, 256, 94, 197, 95, 531, 163, 169, 69, 305, 48, 341, 373, 397, 207, 279, 509, 227, 148, 143, 334, 180, 356, 460, 131, 127, 47, 452, 262, 324, 203, 84, 426, 121, 539, 516, 530, 398, 384, 91, 82, 430, 267, 119, 358, 291, 57, 425, 487, 321, 257, 376, 31, 442, 42, 105, 388, 335, 273, 488, 53, 518, 128, 28, 183, 459, 510, 151, 244, 265, 288, 423, 147, 177, 99, 448, 431, 115, 72, 174, 87, 486, 314, 396, 472, 70, 277, 9, 359, 192, 1064, 1012, 998, 663, 1010, 712, 953, 551, 937, 791, 548, 866, 748, 628, 786, 790, 821, 572, 1052, 1049, 1007, 976, 685, 1070, 568, 693, 964, 982, 589, 799, 1041, 587, 794, 680, 635, 842, 737, 657, 851, 988, 898, 746, 569, 611, 1072, 1027, 930, 562, 672, 829, 640, 575, 800, 766, 967, 1063, 734, 854, 715, 844, 606, 760, 907, 947, 1087, 652, 694, 550, 793, 576, 843, 714, 816, 911, 1037, 879, 675, 1055, 987, 1019, 755, 642, 554, 653, 565, 647, 863, 874, 939, 1051, 658, 951, 968, 965, 709, 600, 940, 557, 660, 868, 1078, 833, 1089, 881, 553, 774, 1025, 776, 870, 736, 1033, 691, 855, 801, 1057, 1068, 960, 690, 607, 974, 798, 753, 761, 1043, 626, 952, 1003, 841, 1004, 700, 807, 999, 629, 838, 696, 639, 869, 991, 956, 641, 659, 605, 583, 689, 704, 586, 969, 941, 886, 759, 897, 782, 638, 932, 559, 958, 1077, 695, 972, 1036, 608, 625, 845, 739, 1001, 727, 1013, 989, 555, 996, 980, 1006, 853, 1085, 877, 950, 808, 552, 812, 803, 584, 697, 579, 1005, 817, 686, 1029, 740, 1061, 674, 1075, 1071, 957, 1031, 596, 708, 901, 1090, 914, 1032, 546, 856, 1038, 757, 718, 741, 977, 1008, 830, 669, 780, 585, 820, 1066, 702, 768, 822, 756, 890, 852, 763, 645, 835, 924, 713, 771, 650, 995, 556, 651, 614, 636, 1067, 919, 926, 1028, 779, 910, 918, 804, 811, 648, 850, 726, 889, 574, 588, 754, 566, 921, 1076, 630, 1044, 1073, 831, 1045, 617, 595, 725, 1069, 973, 662, 839, 622, 594, 1015, 809, 806, 692, 619, 992, 878, 610, 656, 598, 909, 1083, 955, 670, 633, 661, 1074, 834, 920, 848, 664, 558, 703, 883, 963, 673, 592, 781, 983, 681, 787, 899, 948, 707, 1056, 985, 723, 604, 710, 970, 871, 677, 698, 896, 993, 1023, 563, 934, 732, 743, 884, 752, 1080, 933, 891, 1021, 859, 788, 1079, 997, 716, 733, 593, 679, 847, 745, 618, 864, 624, 984, 620, 892, 942, 744, 935, 931, 929, 711, 665, 1040, 699, 946, 1016, 775, 975, 567, 827, 938, 796, 789, 783, 581, 1053, 1088, 875, 655, 925, 717, 784, 549, 836, 994, 867, 666, 701, 684, 671, 1002, 612, 720, 1054, 724, 767, 961, 646, 792, 765, 880], [85, 436, 96, 186, 134, 37, 450, 90, 502, 179, 140, 429, 66, 325, 285, 330, 196, 393, 137, 298, 407, 337, 503, 278, 230, 320, 175, 338, 162, 142, 451, 311, 261, 485, 113, 225, 242, 243, 15, 155, 380, 283, 17, 303, 475, 355, 353, 45, 532, 365, 456, 185, 406, 504, 512, 345, 438, 249, 433, 540, 224, 348, 108, 89, 401, 46, 102, 239, 21, 107, 315, 208, 103, 71, 75, 313, 78, 378, 357, 441, 379, 322, 310, 190, 236, 480, 219, 318, 381, 351, 157, 159, 276, 481, 492, 153, 268, 350, 1, 172, 12, 132, 390, 453, 434, 483, 245, 76, 229, 959, 1030, 887, 922, 876, 573, 917, 905, 865, 1039, 1062, 1058, 1020, 893, 1014, 772, 560, 903, 582, 637, 885, 1017, 826, 916, 1048, 615, 810, 928, 966, 1060, 616, 778, 872, 923, 764, 900, 936, 979, 1050, 735, 1091, 861, 832, 1035, 577, 873, 912, 578, 777, 986, 795, 621, 762, 785, 590, 602, 944, 742, 705, 631, 906, 580, 888, 846, 1082, 682, 773, 815, 1011, 1047, 915, 1046, 849, 1022, 688, 913, 721, 981, 954, 599, 564, 547, 758, 609, 769, 840, 818, 978, 728, 882, 654, 908, 747, 837, 927, 722, 824, 814, 862, 603, 632, 797, 1084, 949, 945, 613, 683, 601, 667], [312, 118, 400, 543, 202, 165, 508, 454, 264, 524, 455, 329, 375, 10, 482, 112, 282, 343, 293, 542, 65, 404, 126, 490, 545, 231, 213, 408, 194, 7, 507, 499, 494, 533, 471, 101, 97, 382, 54, 30, 364, 49, 100, 428, 362, 319, 399, 56, 144, 60, 6, 8, 354, 333, 823, 1024, 749, 813, 649, 1081, 1065, 1042, 561, 802, 904, 719, 770, 1000, 1026, 962, 805, 751, 943, 597, 729, 706, 902, 857, 591, 1018, 731, 571, 894, 738, 643, 1009, 750, 860, 895, 668, 1059, 644, 627, 687, 730, 623, 828, 990, 676, 858, 570, 678, 819, 971, 825, 634, 1086, 1034])]\n",
      "2022-08-09 19:35:24 - (M) Train validation test splitted: 426 120 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-09 19:35:24 - (N) Train validation test splitted: 384 108 54\n",
      "2022-08-09 19:35:24 - (F) Train validation test splitted: 384 108 54\n",
      "2022-08-09 19:35:24 - (H) Train validation test splitted: 99 28 14\n",
      "2022-08-09 19:35:24 - (FN) Train validation test splitted: 766 218 108\n"
     ]
    }
   ],
   "source": [
    "fold = 1 #5\n",
    "mri_type = \"T1wCE\"\n",
    "batch_size = 1\n",
    "epochs = 15\n",
    "train_origins = [\"f\"]#[\"m\",\"n\",\"fn\",\"f\"]\n",
    "packs = generate_datasets([mri_type])\n",
    "loader_packs = get_loaders(packs, batch_size)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "#print(loader_packs['KLF']['m_dataloaders'])\n",
    "\n",
    "m_dataloader = loader_packs[mri_type]['m_dataloaders']#m_dataloaders[0]\n",
    "# Competition Train\n",
    "m_train_loader = m_dataloader[0]\n",
    "# Competition Val\n",
    "m_val_loader = m_dataloader[1]\n",
    "# Competition Test\n",
    "m_test_loader = m_dataloader[2]\n",
    "\n",
    "#t_dataloader = loader_packs[selected_type]['t_dataloaders']#t_dataloaders[0]\n",
    "# External Train\n",
    "#t_train_loader = t_dataloader[0]\n",
    "# External Val\n",
    "#t_val_loader = t_dataloader[1]\n",
    "# External Test\n",
    "#t_test_loader = t_dataloader[2]\n",
    "\n",
    "n_dataloader = loader_packs[mri_type]['n_dataloaders']#n_dataloaders[0]\n",
    "# UPENN Train\n",
    "n_train_loader = n_dataloader[0]\n",
    "# UPENN Val\n",
    "n_val_loader = n_dataloader[1]\n",
    "# UPENN Test\n",
    "n_test_loader = n_dataloader[2]\n",
    "\n",
    "#if selected_type == \"KLF\":\n",
    "f_dataloader = loader_packs[mri_type]['f_dataloaders']#f_dataloaders[0]\n",
    "# Competition (Tumor Only) Train\n",
    "f_train_loader = f_dataloader[0]\n",
    "# Competition (Tumor Only) Val\n",
    "f_val_loader = f_dataloader[1]\n",
    "# Competition (Tumor Only) Test\n",
    "f_test_loader = f_dataloader[2]\n",
    "\n",
    "h_dataloader = loader_packs[mri_type]['h_dataloaders']#h_dataloaders[0]\n",
    "# Competition (No Tumor) Train\n",
    "h_train_loader = h_dataloader[0]\n",
    "# Competition (No Tumor) Val\n",
    "h_val_loader = h_dataloader[1]\n",
    "# Competition (No Tumor) Test\n",
    "h_test_loader = h_dataloader[2]\n",
    "    \n",
    "fn_dataloader = loader_packs[mri_type]['fn_dataloaders']#fn_dataloaders[0]\n",
    "# Competition (Tumor Only) + UPENN Train\n",
    "fn_train_loader = fn_dataloader[0]\n",
    "# Competition (Tumor Only) + UPENN Val\n",
    "fn_val_loader = fn_dataloader[1]\n",
    "# Competition (Tumor Only) + UPENN Test\n",
    "fn_test_loader = fn_dataloader[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_T1wCE_1\n",
      "Type: T1wCE\n",
      "Length of concatenated dataset: 606\n",
      "Length of concatenated dataset: 606\n",
      "Train Idx:\n",
      "[238, 137, 106, 284, 44, 139, 247, 288, 156, 297, 252, 54, 234, 18, 205, 254, 182, 56, 71, 144, 249, 209, 290, 219, 158, 176, 33, 83, 136, 210, 118, 60, 159, 282, 110, 21, 29, 150, 16, 75, 109, 179, 283, 4, 96, 229, 61, 67, 295, 266, 171, 281, 40, 189, 13, 107, 200, 3, 161, 125, 24, 30, 77, 279, 190, 19, 257, 235, 268, 80, 51, 2, 239, 104, 262, 86, 10, 224, 58, 41, 14, 155, 50, 215, 237, 123, 220, 62, 191, 230, 130, 213, 187, 43, 114, 138, 199, 222, 149, 112, 298, 98, 221, 93, 208, 162, 36, 178, 113, 0, 94, 294, 95, 299, 263, 256, 69, 49, 48, 85, 300, 141, 207, 23, 250, 148, 143, 78, 180, 100, 204, 131, 269, 301, 196, 6, 68, 203, 84, 170, 121, 140, 258, 276, 142, 259, 91, 82, 285, 11, 119, 102, 35, 57, 169, 231, 65, 1, 120, 267, 186, 42, 105, 132, 79, 17, 271, 38, 53, 260, 128, 28, 183, 163, 151, 244, 202, 31, 32, 127, 185, 280, 273, 147, 278, 177, 99, 197, 243, 115, 265, 72, 25, 165, 289, 174, 291, 39, 193, 88, 70, 87, 292, 242, 277, 211, 9, 195, 251, 192, 117, 47, 172, 516, 380, 549, 365, 554, 536, 489, 433, 486, 369, 338, 320, 465, 589, 448, 528, 499, 348, 353, 360, 556, 547, 531, 544, 335, 381, 449, 436, 399, 517, 401, 505, 471, 392, 543, 561, 550, 435, 349, 500, 410, 473, 303, 542, 374, 579, 405, 370, 411, 525, 387, 584, 557, 428, 539, 412, 329, 484, 602, 545, 490, 437, 372, 402, 527, 521, 342, 496, 493, 432, 551, 443, 434, 564, 416, 321, 379, 495, 552, 414, 479, 312, 492, 462, 599, 346, 394, 407, 441, 478, 415, 371, 339, 513, 368, 345, 429, 306, 420, 451, 596, 580, 574, 431, 485, 440, 600, 310, 389, 482, 422, 569, 418, 464, 332, 458, 563, 488, 404, 400, 323, 456, 357, 333, 583, 352, 403, 565, 594, 454, 417, 359, 447, 363, 497, 535, 515, 502, 601, 309, 562, 311, 520, 382, 576, 511, 577, 546, 568, 470, 341, 373, 424, 582, 347, 603, 597, 480, 361, 466, 427, 457, 383, 362, 595, 351, 356, 461, 354, 575, 522, 377, 307, 442, 510, 590, 559, 308, 444, 364, 438, 386, 530, 325, 573, 523, 506, 423, 384, 316, 587, 375, 450, 463, 390, 541, 605, 439, 498, 494, 419, 327, 397, 467, 409, 319, 366, 408, 512, 331, 504, 477, 396]\n",
      "Val Idx:\n",
      "[225, 152, 228, 201, 52, 245, 175, 168, 223, 217, 111, 135, 218, 12, 15, 66, 97, 90, 198, 103, 22, 212, 226, 264, 133, 216, 275, 270, 154, 55, 194, 255, 134, 8, 157, 241, 240, 81, 214, 167, 5, 59, 92, 274, 34, 145, 116, 188, 246, 7, 45, 129, 122, 63, 124, 227, 146, 302, 26, 108, 560, 472, 367, 518, 487, 343, 514, 459, 588, 426, 524, 355, 538, 566, 395, 474, 425, 468, 558, 324, 567, 326, 591, 328, 592, 571, 337, 322, 314, 391, 421, 586, 453, 455, 508, 570, 491, 406, 501, 388, 378, 534, 452, 598, 385, 578, 315, 336, 581, 555, 413, 507, 334, 445, 529, 330, 340, 317, 604, 481]\n",
      "Test Idx:\n",
      "[89, 74, 153, 64, 296, 287, 286, 236, 126, 73, 20, 46, 160, 232, 181, 27, 173, 261, 37, 101, 166, 233, 184, 164, 206, 248, 253, 293, 76, 272, 305, 585, 304, 475, 476, 533, 548, 553, 344, 318, 393, 483, 532, 509, 540, 313, 430, 350, 526, 572, 460, 446, 398, 469, 537, 593, 358, 376, 519, 503]\n",
      "[([238, 137, 106, 284, 44, 139, 247, 288, 156, 297, 252, 54, 234, 18, 205, 254, 182, 56, 71, 144, 249, 209, 290, 219, 158, 176, 33, 83, 136, 210, 118, 60, 159, 282, 110, 21, 29, 150, 16, 75, 109, 179, 283, 4, 96, 229, 61, 67, 295, 266, 171, 281, 40, 189, 13, 107, 200, 3, 161, 125, 24, 30, 77, 279, 190, 19, 257, 235, 268, 80, 51, 2, 239, 104, 262, 86, 10, 224, 58, 41, 14, 155, 50, 215, 237, 123, 220, 62, 191, 230, 130, 213, 187, 43, 114, 138, 199, 222, 149, 112, 298, 98, 221, 93, 208, 162, 36, 178, 113, 0, 94, 294, 95, 299, 263, 256, 69, 49, 48, 85, 300, 141, 207, 23, 250, 148, 143, 78, 180, 100, 204, 131, 269, 301, 196, 6, 68, 203, 84, 170, 121, 140, 258, 276, 142, 259, 91, 82, 285, 11, 119, 102, 35, 57, 169, 231, 65, 1, 120, 267, 186, 42, 105, 132, 79, 17, 271, 38, 53, 260, 128, 28, 183, 163, 151, 244, 202, 31, 32, 127, 185, 280, 273, 147, 278, 177, 99, 197, 243, 115, 265, 72, 25, 165, 289, 174, 291, 39, 193, 88, 70, 87, 292, 242, 277, 211, 9, 195, 251, 192, 117, 47, 172, 516, 380, 549, 365, 554, 536, 489, 433, 486, 369, 338, 320, 465, 589, 448, 528, 499, 348, 353, 360, 556, 547, 531, 544, 335, 381, 449, 436, 399, 517, 401, 505, 471, 392, 543, 561, 550, 435, 349, 500, 410, 473, 303, 542, 374, 579, 405, 370, 411, 525, 387, 584, 557, 428, 539, 412, 329, 484, 602, 545, 490, 437, 372, 402, 527, 521, 342, 496, 493, 432, 551, 443, 434, 564, 416, 321, 379, 495, 552, 414, 479, 312, 492, 462, 599, 346, 394, 407, 441, 478, 415, 371, 339, 513, 368, 345, 429, 306, 420, 451, 596, 580, 574, 431, 485, 440, 600, 310, 389, 482, 422, 569, 418, 464, 332, 458, 563, 488, 404, 400, 323, 456, 357, 333, 583, 352, 403, 565, 594, 454, 417, 359, 447, 363, 497, 535, 515, 502, 601, 309, 562, 311, 520, 382, 576, 511, 577, 546, 568, 470, 341, 373, 424, 582, 347, 603, 597, 480, 361, 466, 427, 457, 383, 362, 595, 351, 356, 461, 354, 575, 522, 377, 307, 442, 510, 590, 559, 308, 444, 364, 438, 386, 530, 325, 573, 523, 506, 423, 384, 316, 587, 375, 450, 463, 390, 541, 605, 439, 498, 494, 419, 327, 397, 467, 409, 319, 366, 408, 512, 331, 504, 477, 396], [225, 152, 228, 201, 52, 245, 175, 168, 223, 217, 111, 135, 218, 12, 15, 66, 97, 90, 198, 103, 22, 212, 226, 264, 133, 216, 275, 270, 154, 55, 194, 255, 134, 8, 157, 241, 240, 81, 214, 167, 5, 59, 92, 274, 34, 145, 116, 188, 246, 7, 45, 129, 122, 63, 124, 227, 146, 302, 26, 108, 560, 472, 367, 518, 487, 343, 514, 459, 588, 426, 524, 355, 538, 566, 395, 474, 425, 468, 558, 324, 567, 326, 591, 328, 592, 571, 337, 322, 314, 391, 421, 586, 453, 455, 508, 570, 491, 406, 501, 388, 378, 534, 452, 598, 385, 578, 315, 336, 581, 555, 413, 507, 334, 445, 529, 330, 340, 317, 604, 481], [89, 74, 153, 64, 296, 287, 286, 236, 126, 73, 20, 46, 160, 232, 181, 27, 173, 261, 37, 101, 166, 233, 184, 164, 206, 248, 253, 293, 76, 272, 305, 585, 304, 475, 476, 533, 548, 553, 344, 318, 393, 483, 532, 509, 540, 313, 430, 350, 526, 572, 460, 446, 398, 469, 537, 593, 358, 376, 519, 503])]\n",
      "Length of concatenated dataset: 546\n",
      "Length of concatenated dataset: 546\n",
      "Train Idx:\n",
      "[33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441]\n",
      "Val Idx:\n",
      "[218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529]\n",
      "Test Idx:\n",
      "[201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358]\n",
      "[([33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441], [218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529], [201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358])]\n",
      "Length of concatenated dataset: 1092\n",
      "Length of concatenated dataset: 1092\n",
      "Train Idx:\n",
      "[386, 463, 206, 38, 188, 361, 339, 272, 289, 437, 462, 124, 154, 526, 59, 252, 466, 491, 541, 235, 211, 420, 55, 171, 233, 205, 158, 385, 34, 367, 18, 506, 247, 529, 52, 74, 26, 173, 92, 167, 4, 435, 181, 246, 443, 5, 141, 301, 200, 135, 263, 122, 22, 68, 210, 20, 306, 336, 14, 170, 374, 281, 271, 220, 537, 64, 520, 250, 120, 81, 421, 500, 240, 308, 534, 528, 160, 536, 238, 497, 484, 392, 478, 465, 51, 195, 191, 116, 342, 395, 164, 106, 372, 63, 511, 284, 519, 445, 316, 93, 366, 332, 198, 145, 150, 39, 495, 439, 253, 344, 464, 2, 221, 514, 146, 241, 538, 114, 391, 176, 168, 515, 346, 513, 136, 424, 254, 476, 299, 457, 432, 255, 232, 133, 33, 88, 290, 44, 61, 199, 505, 525, 544, 340, 218, 302, 297, 73, 295, 35, 467, 29, 427, 446, 412, 309, 523, 217, 27, 469, 347, 156, 493, 409, 138, 212, 104, 414, 410, 416, 215, 521, 189, 214, 501, 204, 234, 259, 67, 24, 216, 300, 223, 129, 111, 166, 498, 470, 40, 274, 422, 79, 403, 468, 327, 13, 287, 326, 489, 251, 228, 415, 161, 83, 117, 25, 110, 149, 152, 16, 402, 331, 109, 417, 139, 237, 260, 352, 527, 317, 323, 477, 248, 389, 479, 19, 328, 296, 447, 269, 363, 226, 458, 3, 413, 125, 280, 286, 77, 184, 371, 461, 535, 275, 294, 517, 182, 32, 80, 307, 258, 11, 360, 440, 86, 266, 36, 193, 58, 41, 270, 411, 50, 209, 474, 473, 496, 123, 222, 419, 62, 449, 377, 130, 187, 23, 444, 43, 370, 394, 0, 383, 201, 405, 368, 522, 98, 387, 349, 304, 418, 292, 178, 369, 256, 94, 197, 95, 531, 163, 169, 69, 305, 48, 341, 373, 397, 207, 279, 509, 227, 148, 143, 334, 180, 356, 460, 131, 127, 47, 452, 262, 324, 203, 84, 426, 121, 539, 516, 530, 398, 384, 91, 82, 430, 267, 119, 358, 291, 57, 425, 487, 321, 257, 376, 31, 442, 42, 105, 388, 335, 273, 488, 53, 518, 128, 28, 183, 459, 510, 151, 244, 265, 288, 423, 147, 177, 99, 448, 431, 115, 72, 174, 87, 486, 314, 396, 472, 70, 277, 9, 359, 192, 1064, 1012, 998, 663, 1010, 712, 953, 551, 937, 791, 548, 866, 748, 628, 786, 790, 821, 572, 1052, 1049, 1007, 976, 685, 1070, 568, 693, 964, 982, 589, 799, 1041, 587, 794, 680, 635, 842, 737, 657, 851, 988, 898, 746, 569, 611, 1072, 1027, 930, 562, 672, 829, 640, 575, 800, 766, 967, 1063, 734, 854, 715, 844, 606, 760, 907, 947, 1087, 652, 694, 550, 793, 576, 843, 714, 816, 911, 1037, 879, 675, 1055, 987, 1019, 755, 642, 554, 653, 565, 647, 863, 874, 939, 1051, 658, 951, 968, 965, 709, 600, 940, 557, 660, 868, 1078, 833, 1089, 881, 553, 774, 1025, 776, 870, 736, 1033, 691, 855, 801, 1057, 1068, 960, 690, 607, 974, 798, 753, 761, 1043, 626, 952, 1003, 841, 1004, 700, 807, 999, 629, 838, 696, 639, 869, 991, 956, 641, 659, 605, 583, 689, 704, 586, 969, 941, 886, 759, 897, 782, 638, 932, 559, 958, 1077, 695, 972, 1036, 608, 625, 845, 739, 1001, 727, 1013, 989, 555, 996, 980, 1006, 853, 1085, 877, 950, 808, 552, 812, 803, 584, 697, 579, 1005, 817, 686, 1029, 740, 1061, 674, 1075, 1071, 957, 1031, 596, 708, 901, 1090, 914, 1032, 546, 856, 1038, 757, 718, 741, 977, 1008, 830, 669, 780, 585, 820, 1066, 702, 768, 822, 756, 890, 852, 763, 645, 835, 924, 713, 771, 650, 995, 556, 651, 614, 636, 1067, 919, 926, 1028, 779, 910, 918, 804, 811, 648, 850, 726, 889, 574, 588, 754, 566, 921, 1076, 630, 1044, 1073, 831, 1045, 617, 595, 725, 1069, 973, 662, 839, 622, 594, 1015, 809, 806, 692, 619, 992, 878, 610, 656, 598, 909, 1083, 955, 670, 633, 661, 1074, 834, 920, 848, 664, 558, 703, 883, 963, 673, 592, 781, 983, 681, 787, 899, 948, 707, 1056, 985, 723, 604, 710, 970, 871, 677, 698, 896, 993, 1023, 563, 934, 732, 743, 884, 752, 1080, 933, 891, 1021, 859, 788, 1079, 997, 716, 733, 593, 679, 847, 745, 618, 864, 624, 984, 620, 892, 942, 744, 935, 931, 929, 711, 665, 1040, 699, 946, 1016, 775, 975, 567, 827, 938, 796, 789, 783, 581, 1053, 1088, 875, 655, 925, 717, 784, 549, 836, 994, 867, 666, 701, 684, 671, 1002, 612, 720, 1054, 724, 767, 961, 646, 792, 765, 880]\n",
      "Val Idx:\n",
      "[85, 436, 96, 186, 134, 37, 450, 90, 502, 179, 140, 429, 66, 325, 285, 330, 196, 393, 137, 298, 407, 337, 503, 278, 230, 320, 175, 338, 162, 142, 451, 311, 261, 485, 113, 225, 242, 243, 15, 155, 380, 283, 17, 303, 475, 355, 353, 45, 532, 365, 456, 185, 406, 504, 512, 345, 438, 249, 433, 540, 224, 348, 108, 89, 401, 46, 102, 239, 21, 107, 315, 208, 103, 71, 75, 313, 78, 378, 357, 441, 379, 322, 310, 190, 236, 480, 219, 318, 381, 351, 157, 159, 276, 481, 492, 153, 268, 350, 1, 172, 12, 132, 390, 453, 434, 483, 245, 76, 229, 959, 1030, 887, 922, 876, 573, 917, 905, 865, 1039, 1062, 1058, 1020, 893, 1014, 772, 560, 903, 582, 637, 885, 1017, 826, 916, 1048, 615, 810, 928, 966, 1060, 616, 778, 872, 923, 764, 900, 936, 979, 1050, 735, 1091, 861, 832, 1035, 577, 873, 912, 578, 777, 986, 795, 621, 762, 785, 590, 602, 944, 742, 705, 631, 906, 580, 888, 846, 1082, 682, 773, 815, 1011, 1047, 915, 1046, 849, 1022, 688, 913, 721, 981, 954, 599, 564, 547, 758, 609, 769, 840, 818, 978, 728, 882, 654, 908, 747, 837, 927, 722, 824, 814, 862, 603, 632, 797, 1084, 949, 945, 613, 683, 601, 667]\n",
      "Test Idx:\n",
      "[312, 118, 400, 543, 202, 165, 508, 454, 264, 524, 455, 329, 375, 10, 482, 112, 282, 343, 293, 542, 65, 404, 126, 490, 545, 231, 213, 408, 194, 7, 507, 499, 494, 533, 471, 101, 97, 382, 54, 30, 364, 49, 100, 428, 362, 319, 399, 56, 144, 60, 6, 8, 354, 333, 823, 1024, 749, 813, 649, 1081, 1065, 1042, 561, 802, 904, 719, 770, 1000, 1026, 962, 805, 751, 943, 597, 729, 706, 902, 857, 591, 1018, 731, 571, 894, 738, 643, 1009, 750, 860, 895, 668, 1059, 644, 627, 687, 730, 623, 828, 990, 676, 858, 570, 678, 819, 971, 825, 634, 1086, 1034]\n",
      "[([386, 463, 206, 38, 188, 361, 339, 272, 289, 437, 462, 124, 154, 526, 59, 252, 466, 491, 541, 235, 211, 420, 55, 171, 233, 205, 158, 385, 34, 367, 18, 506, 247, 529, 52, 74, 26, 173, 92, 167, 4, 435, 181, 246, 443, 5, 141, 301, 200, 135, 263, 122, 22, 68, 210, 20, 306, 336, 14, 170, 374, 281, 271, 220, 537, 64, 520, 250, 120, 81, 421, 500, 240, 308, 534, 528, 160, 536, 238, 497, 484, 392, 478, 465, 51, 195, 191, 116, 342, 395, 164, 106, 372, 63, 511, 284, 519, 445, 316, 93, 366, 332, 198, 145, 150, 39, 495, 439, 253, 344, 464, 2, 221, 514, 146, 241, 538, 114, 391, 176, 168, 515, 346, 513, 136, 424, 254, 476, 299, 457, 432, 255, 232, 133, 33, 88, 290, 44, 61, 199, 505, 525, 544, 340, 218, 302, 297, 73, 295, 35, 467, 29, 427, 446, 412, 309, 523, 217, 27, 469, 347, 156, 493, 409, 138, 212, 104, 414, 410, 416, 215, 521, 189, 214, 501, 204, 234, 259, 67, 24, 216, 300, 223, 129, 111, 166, 498, 470, 40, 274, 422, 79, 403, 468, 327, 13, 287, 326, 489, 251, 228, 415, 161, 83, 117, 25, 110, 149, 152, 16, 402, 331, 109, 417, 139, 237, 260, 352, 527, 317, 323, 477, 248, 389, 479, 19, 328, 296, 447, 269, 363, 226, 458, 3, 413, 125, 280, 286, 77, 184, 371, 461, 535, 275, 294, 517, 182, 32, 80, 307, 258, 11, 360, 440, 86, 266, 36, 193, 58, 41, 270, 411, 50, 209, 474, 473, 496, 123, 222, 419, 62, 449, 377, 130, 187, 23, 444, 43, 370, 394, 0, 383, 201, 405, 368, 522, 98, 387, 349, 304, 418, 292, 178, 369, 256, 94, 197, 95, 531, 163, 169, 69, 305, 48, 341, 373, 397, 207, 279, 509, 227, 148, 143, 334, 180, 356, 460, 131, 127, 47, 452, 262, 324, 203, 84, 426, 121, 539, 516, 530, 398, 384, 91, 82, 430, 267, 119, 358, 291, 57, 425, 487, 321, 257, 376, 31, 442, 42, 105, 388, 335, 273, 488, 53, 518, 128, 28, 183, 459, 510, 151, 244, 265, 288, 423, 147, 177, 99, 448, 431, 115, 72, 174, 87, 486, 314, 396, 472, 70, 277, 9, 359, 192, 1064, 1012, 998, 663, 1010, 712, 953, 551, 937, 791, 548, 866, 748, 628, 786, 790, 821, 572, 1052, 1049, 1007, 976, 685, 1070, 568, 693, 964, 982, 589, 799, 1041, 587, 794, 680, 635, 842, 737, 657, 851, 988, 898, 746, 569, 611, 1072, 1027, 930, 562, 672, 829, 640, 575, 800, 766, 967, 1063, 734, 854, 715, 844, 606, 760, 907, 947, 1087, 652, 694, 550, 793, 576, 843, 714, 816, 911, 1037, 879, 675, 1055, 987, 1019, 755, 642, 554, 653, 565, 647, 863, 874, 939, 1051, 658, 951, 968, 965, 709, 600, 940, 557, 660, 868, 1078, 833, 1089, 881, 553, 774, 1025, 776, 870, 736, 1033, 691, 855, 801, 1057, 1068, 960, 690, 607, 974, 798, 753, 761, 1043, 626, 952, 1003, 841, 1004, 700, 807, 999, 629, 838, 696, 639, 869, 991, 956, 641, 659, 605, 583, 689, 704, 586, 969, 941, 886, 759, 897, 782, 638, 932, 559, 958, 1077, 695, 972, 1036, 608, 625, 845, 739, 1001, 727, 1013, 989, 555, 996, 980, 1006, 853, 1085, 877, 950, 808, 552, 812, 803, 584, 697, 579, 1005, 817, 686, 1029, 740, 1061, 674, 1075, 1071, 957, 1031, 596, 708, 901, 1090, 914, 1032, 546, 856, 1038, 757, 718, 741, 977, 1008, 830, 669, 780, 585, 820, 1066, 702, 768, 822, 756, 890, 852, 763, 645, 835, 924, 713, 771, 650, 995, 556, 651, 614, 636, 1067, 919, 926, 1028, 779, 910, 918, 804, 811, 648, 850, 726, 889, 574, 588, 754, 566, 921, 1076, 630, 1044, 1073, 831, 1045, 617, 595, 725, 1069, 973, 662, 839, 622, 594, 1015, 809, 806, 692, 619, 992, 878, 610, 656, 598, 909, 1083, 955, 670, 633, 661, 1074, 834, 920, 848, 664, 558, 703, 883, 963, 673, 592, 781, 983, 681, 787, 899, 948, 707, 1056, 985, 723, 604, 710, 970, 871, 677, 698, 896, 993, 1023, 563, 934, 732, 743, 884, 752, 1080, 933, 891, 1021, 859, 788, 1079, 997, 716, 733, 593, 679, 847, 745, 618, 864, 624, 984, 620, 892, 942, 744, 935, 931, 929, 711, 665, 1040, 699, 946, 1016, 775, 975, 567, 827, 938, 796, 789, 783, 581, 1053, 1088, 875, 655, 925, 717, 784, 549, 836, 994, 867, 666, 701, 684, 671, 1002, 612, 720, 1054, 724, 767, 961, 646, 792, 765, 880], [85, 436, 96, 186, 134, 37, 450, 90, 502, 179, 140, 429, 66, 325, 285, 330, 196, 393, 137, 298, 407, 337, 503, 278, 230, 320, 175, 338, 162, 142, 451, 311, 261, 485, 113, 225, 242, 243, 15, 155, 380, 283, 17, 303, 475, 355, 353, 45, 532, 365, 456, 185, 406, 504, 512, 345, 438, 249, 433, 540, 224, 348, 108, 89, 401, 46, 102, 239, 21, 107, 315, 208, 103, 71, 75, 313, 78, 378, 357, 441, 379, 322, 310, 190, 236, 480, 219, 318, 381, 351, 157, 159, 276, 481, 492, 153, 268, 350, 1, 172, 12, 132, 390, 453, 434, 483, 245, 76, 229, 959, 1030, 887, 922, 876, 573, 917, 905, 865, 1039, 1062, 1058, 1020, 893, 1014, 772, 560, 903, 582, 637, 885, 1017, 826, 916, 1048, 615, 810, 928, 966, 1060, 616, 778, 872, 923, 764, 900, 936, 979, 1050, 735, 1091, 861, 832, 1035, 577, 873, 912, 578, 777, 986, 795, 621, 762, 785, 590, 602, 944, 742, 705, 631, 906, 580, 888, 846, 1082, 682, 773, 815, 1011, 1047, 915, 1046, 849, 1022, 688, 913, 721, 981, 954, 599, 564, 547, 758, 609, 769, 840, 818, 978, 728, 882, 654, 908, 747, 837, 927, 722, 824, 814, 862, 603, 632, 797, 1084, 949, 945, 613, 683, 601, 667], [312, 118, 400, 543, 202, 165, 508, 454, 264, 524, 455, 329, 375, 10, 482, 112, 282, 343, 293, 542, 65, 404, 126, 490, 545, 231, 213, 408, 194, 7, 507, 499, 494, 533, 471, 101, 97, 382, 54, 30, 364, 49, 100, 428, 362, 319, 399, 56, 144, 60, 6, 8, 354, 333, 823, 1024, 749, 813, 649, 1081, 1065, 1042, 561, 802, 904, 719, 770, 1000, 1026, 962, 805, 751, 943, 597, 729, 706, 902, 857, 591, 1018, 731, 571, 894, 738, 643, 1009, 750, 860, 895, 668, 1059, 644, 627, 687, 730, 623, 828, 990, 676, 858, 570, 678, 819, 971, 825, 634, 1086, 1034])]\n",
      "Length of concatenated dataset: 546\n",
      "Length of concatenated dataset: 546\n",
      "Train Idx:\n",
      "[33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441]\n",
      "Val Idx:\n",
      "[218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529]\n",
      "Test Idx:\n",
      "[201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358]\n",
      "[([33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441], [218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529], [201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358])]\n",
      "SPLITS:\n",
      "- folds:\n",
      "1\n",
      "- splits per fold:\n",
      "3\n",
      "(F) Train validation splitted: 384 108\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.469, loss=0.713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 108/108 [00:08<00:00, 12.38it/s, batch_loss=0.46, loss=0.703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/15: Validation average loss: 0.7033604642859211 + AUC SCORE = 0.5171467764060356 + AUC SCORE THRESH 0.6122448979591836 = 0.5740740740740741\n",
      "Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:28<00:00,  4.34it/s, batch_loss=0.554, loss=0.709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.40it/s, batch_loss=0.688, loss=0.725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2/15: Validation average loss: 0.7250772489717713 + AUC SCORE = 0.5006858710562414 + AUC SCORE THRESH 0.7755102040816326 = 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:28<00:00,  4.33it/s, batch_loss=0.873, loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.32it/s, batch_loss=0.845, loss=0.715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3/15: Validation average loss: 0.7149383021449601 + AUC SCORE = 0.5006858710562414 + AUC SCORE THRESH 0.6938775510204082 = 0.5740740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 384/384 [01:28<00:00,  4.32it/s, batch_loss=0.53, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.28it/s, batch_loss=0.851, loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4/15: Validation average loss: 0.6989641236486258 + AUC SCORE = 0.46810699588477367 + AUC SCORE THRESH 0.5714285714285714 = 0.5277777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.593, loss=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 108/108 [00:08<00:00, 12.31it/s, batch_loss=0.692, loss=0.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5/15: Validation average loss: 0.6997826565746907 + AUC SCORE = 0.4619341563786008 + AUC SCORE THRESH 0.6122448979591836 = 0.5740740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.634, loss=0.671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.31it/s, batch_loss=0.629, loss=0.716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6/15: Validation average loss: 0.715678444063222 + AUC SCORE = 0.448559670781893 + AUC SCORE THRESH 0.5306122448979591 = 0.5462962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.651, loss=0.665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.32it/s, batch_loss=0.584, loss=0.782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 7/15: Validation average loss: 0.7819199589667497 + AUC SCORE = 0.44890260631001366 + AUC SCORE THRESH 0.32653061224489793 = 0.5092592592592593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.917, loss=0.657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 108/108 [00:08<00:00, 12.32it/s, batch_loss=3.38, loss=0.968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 8/15: Validation average loss: 0.9679068962663964 + AUC SCORE = 0.5216049382716049 + AUC SCORE THRESH 0.9183673469387754 = 0.5740740740740741\n",
      "Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.765, loss=0.702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 108/108 [00:08<00:00, 12.27it/s, batch_loss=0.767, loss=0.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 9/15: Validation average loss: 0.8396988351898337 + AUC SCORE = 0.49965706447187924 + AUC SCORE THRESH 0.8571428571428571 = 0.5740740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.793, loss=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.30it/s, batch_loss=0.878, loss=0.951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 10/15: Validation average loss: 0.9513975078071881 + AUC SCORE = 0.48079561042524005 + AUC SCORE THRESH 0.9387755102040816 = 0.5833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.504, loss=0.686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.29it/s, batch_loss=0.824, loss=0.869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 11/15: Validation average loss: 0.8690216263273248 + AUC SCORE = 0.4783950617283951 + AUC SCORE THRESH 0.8979591836734693 = 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.789, loss=0.668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.28it/s, batch_loss=0.849, loss=0.714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 12/15: Validation average loss: 0.7139648172866415 + AUC SCORE = 0.48731138545953356 + AUC SCORE THRESH 0.6122448979591836 = 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=1.06, loss=0.649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:08<00:00, 12.29it/s, batch_loss=0.00338, loss=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 13/15: Validation average loss: 0.9499226041220094 + AUC SCORE = 0.4591906721536351 + AUC SCORE THRESH 0.9387755102040816 = 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.515, loss=0.636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.28it/s, batch_loss=0.778, loss=0.848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 14/15: Validation average loss: 0.8481016096020876 + AUC SCORE = 0.46570644718792864 + AUC SCORE THRESH 0.8571428571428571 = 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.344, loss=0.622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.25it/s, batch_loss=0.416, loss=0.917]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 15/15: Validation average loss: 0.9166451604278 + AUC SCORE = 0.4646776406035665 + AUC SCORE THRESH 0.9183673469387754 = 0.5740740740740741\n",
      "0.5216049382716049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_folded_models(fold, mri_type, \"resnet10\", batch_size, epochs, train_origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y, y_pred, y_prob, name):\n",
    "    auc = roc_auc_score(y, y_prob)\n",
    "    acc = [1 if yy == out else 0 for (yy,out) in zip(y,y_pred)].count(1)/len(y_pred)\n",
    "    total_0_count = y.count(0)\n",
    "    total_1_count = y.count(1)\n",
    "    total_1_pred_count = list(y_pred).count(1)\n",
    "    true_0 = [1 if yy == out and yy == 0 else 0 for (yy,out) in zip(y,y_pred)].count(1)\n",
    "    true_1 = [1 if yy == out and yy == 1 else 0 for (yy,out) in zip(y,y_pred)].count(1)\n",
    "    spec = true_0/total_0_count\n",
    "    sens = true_1/total_1_count\n",
    "    if total_1_pred_count != 0:\n",
    "        prec = true_1/total_1_pred_count\n",
    "    else:\n",
    "        prec = 0\n",
    "    print(f\"Prediction AUC: {auc:.4f}\")\n",
    "    print(f\"Prediction Accuracy: {acc:.4f}\")\n",
    "    print(f\"Prediction Specificity: {spec:.4f}\")\n",
    "    print(f\"Prediction Sensitivity: {sens:.4f}\")\n",
    "    print(f\"Prediction Precision: {prec:.4f}\")\n",
    "    return pd.DataFrame({\"model\": [name], \"AUC\": [auc], \"acc\": [acc], \"spec\": [spec], \"sens\": [sens], \"prec\": [prec]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(filepath, test_dl):\n",
    "    modelname = os.path.basename(filepath)\n",
    "    model = monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/{filepath}\"))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred = [] #y_pred\n",
    "        preds = [] #y_prob\n",
    "        true_labels = [] #y\n",
    "        case_ids = []\n",
    "        epoch_iterator_test = tqdm(test_dl)\n",
    "        for step, batch in enumerate(epoch_iterator_test):\n",
    "            model.eval()\n",
    "            (img_ids, imgs, labels) = batch\n",
    "            images, targets = imgs[0].to(device), labels.to(device)\n",
    "            #images, targets = batch[\"image\"].to(device), batch[\"target\"].to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            targets = targets  # .view(-1, 1)\n",
    "\n",
    "            preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "            true_labels.append(targets.cpu().numpy())\n",
    "            predicted = (outputs>0.5).int()\n",
    "            predicted = torch.reshape(predicted, (-1,))\n",
    "\n",
    "            y_pred.extend(predicted.tolist())\n",
    "            #case_ids.append(batch[\"case_id\"])\n",
    "            if img_ids[0][0][0].isnumeric():\n",
    "                img_ids_fixed = [img_id[:5] for img_id in img_ids[0]]\n",
    "            else:\n",
    "                img_ids_fixed = [img_id[:-4] for img_id in img_ids[0]]\n",
    "            case_ids.append(img_ids_fixed)\n",
    "    preds = np.vstack(preds).T[0].tolist()\n",
    "    true_labels = np.hstack(true_labels).tolist()\n",
    "    case_ids = np.hstack(case_ids).tolist()\n",
    "    auc_score = roc_auc_score(true_labels, preds)\n",
    "    preddf = get_metrics(true_labels, y_pred, preds, modelname)\n",
    "    return preddf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [00:04<00:00, 12.46it/s]\n",
      "/tmp/ipykernel_2843398/4121842239.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.3856\n",
      "Prediction Accuracy: 0.4333\n",
      "Prediction Specificity: 0.7000\n",
      "Prediction Sensitivity: 0.1667\n",
      "Prediction Precision: 0.3571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [00:04<00:00, 12.52it/s]\n",
      "/tmp/ipykernel_2843398/4121842239.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.5444\n",
      "Prediction Accuracy: 0.5000\n",
      "Prediction Specificity: 1.0000\n",
      "Prediction Sensitivity: 0.0000\n",
      "Prediction Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [00:04<00:00, 12.40it/s]\n",
      "/tmp/ipykernel_2843398/4121842239.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.6856\n",
      "Prediction Accuracy: 0.5000\n",
      "Prediction Specificity: 1.0000\n",
      "Prediction Sensitivity: 0.0000\n",
      "Prediction Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [00:04<00:00, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.3156\n",
      "Prediction Accuracy: 0.3667\n",
      "Prediction Specificity: 0.0000\n",
      "Prediction Sensitivity: 0.7333\n",
      "Prediction Precision: 0.4231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_2843398/4121842239.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    \"resnet10_m_Aug09_17-26-02/3d-resnet10_m_T1wCE_fold0_0.49.pth\", #m\n",
    "    \"resnet10_n_Aug09_17-52-43/3d-resnet10_n_T1wCE_fold0_0.518.pth\", #n\n",
    "    \"resnet10_fn_Aug09_18-39-12/3d-resnet10_fn_T1wCE_fold0_0.577.pth\", #f\n",
    "    \"resnet10_f_Aug09_19-48-33/3d-resnet10_f_T1wCE_fold0_0.522.pth\" #fn\n",
    "]\n",
    "metrics = pd.DataFrame({\"model\": [], \"AUC\": [], \"acc\": [], \"spec\": [], \"sens\": [], \"prec\": []})\n",
    "for filepath in paths:\n",
    "    test_loader = m_test_loader\n",
    "    preddf = test_model(filepath, test_loader)\n",
    "    metrics = metrics.append(preddf, ignore_index=True)\n",
    "    \n",
    "metrics.to_csv(f\"tunisiaai_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 54/54 [00:04<00:00, 12.32it/s]\n",
      "/tmp/ipykernel_2843398/1426414694.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.6269\n",
      "Prediction Accuracy: 0.5741\n",
      "Prediction Specificity: 1.0000\n",
      "Prediction Sensitivity: 0.1481\n",
      "Prediction Precision: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 54/54 [00:04<00:00, 12.42it/s]\n",
      "/tmp/ipykernel_2843398/1426414694.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.2853\n",
      "Prediction Accuracy: 0.5000\n",
      "Prediction Specificity: 1.0000\n",
      "Prediction Sensitivity: 0.0000\n",
      "Prediction Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 54/54 [00:04<00:00, 12.36it/s]\n",
      "/tmp/ipykernel_2843398/1426414694.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.3923\n",
      "Prediction Accuracy: 0.5000\n",
      "Prediction Specificity: 1.0000\n",
      "Prediction Sensitivity: 0.0000\n",
      "Prediction Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 54/54 [00:04<00:00, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.6283\n",
      "Prediction Accuracy: 0.4815\n",
      "Prediction Specificity: 0.2593\n",
      "Prediction Sensitivity: 0.7037\n",
      "Prediction Precision: 0.4872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_2843398/1426414694.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    \"resnet10_m_Aug09_17-26-02/3d-resnet10_m_T1wCE_fold0_0.49.pth\", #m\n",
    "    \"resnet10_n_Aug09_17-52-43/3d-resnet10_n_T1wCE_fold0_0.518.pth\", #n\n",
    "    \"resnet10_fn_Aug09_18-39-12/3d-resnet10_fn_T1wCE_fold0_0.577.pth\", #f\n",
    "    \"resnet10_f_Aug09_19-48-33/3d-resnet10_f_T1wCE_fold0_0.522.pth\" #fn\n",
    "]\n",
    "metrics = pd.DataFrame({\"model\": [], \"AUC\": [], \"acc\": [], \"spec\": [], \"sens\": [], \"prec\": []})\n",
    "for filepath in paths:\n",
    "    test_loader = n_test_loader\n",
    "    preddf = test_model(filepath, test_loader)\n",
    "    metrics = metrics.append(preddf, ignore_index=True)\n",
    "    \n",
    "metrics.to_csv(f\"tunisiaai_metrics_n.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
