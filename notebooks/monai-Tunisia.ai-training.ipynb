{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../rsnaresnet10/working/create_folds.py --n_folds 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_T1wCE_0\n",
      "Loading the best images indexes for all the cases...\n",
      "Loading the best images indexes for all the cases...\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-28 23:07:22.170950: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [03:47<00:00,  1.94s/it, batch_loss=0.506, loss=0.714]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:41<00:00,  1.39s/it, batch_loss=0.137, loss=0.701]\n",
      "EPOCH 0/15: Validation average loss: 0.7012121265133222 + AUC SCORE = 0.5387096774193548 + AUC SCORE THRESH 0.6938775510204082 = 0.5472140762463343\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [09:47<00:00,  5.02s/it, batch_loss=0.705, loss=0.709]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:46<00:00,  1.57s/it, batch_loss=0.558, loss=0.692]\n",
      "EPOCH 1/15: Validation average loss: 0.6924694299697876 + AUC SCORE = 0.49149560117302055 + AUC SCORE THRESH 0.5102040816326531 = 0.5304985337243402\n",
      "100%|███████████| 117/117 [10:55<00:00,  5.60s/it, batch_loss=0.692, loss=0.696]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:52<00:00,  1.76s/it, batch_loss=0.738, loss=0.689]\n",
      "EPOCH 2/15: Validation average loss: 0.6894651691118876 + AUC SCORE = 0.5390029325513197 + AUC SCORE THRESH 0.5306122448979591 = 0.5558651026392962\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [10:58<00:00,  5.63s/it, batch_loss=0.619, loss=0.693]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.97s/it, batch_loss=0.189, loss=0.738]\n",
      "EPOCH 3/15: Validation average loss: 0.7383265644311905 + AUC SCORE = 0.5167155425219941 + AUC SCORE THRESH 0.42857142857142855 = 0.5582111436950148\n",
      "100%|███████████| 117/117 [11:19<00:00,  5.80s/it, batch_loss=0.596, loss=0.693]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.79s/it, batch_loss=0.961, loss=0.699]\n",
      "EPOCH 4/15: Validation average loss: 0.6985847502946854 + AUC SCORE = 0.5384164222873901 + AUC SCORE THRESH 0.5306122448979591 = 0.5577712609970674\n",
      "100%|███████████| 117/117 [11:15<00:00,  5.78s/it, batch_loss=0.623, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|███████████████| 30/30 [00:58<00:00,  1.95s/it, batch_loss=1.4, loss=0.744]\n",
      "EPOCH 5/15: Validation average loss: 0.7437388370434443 + AUC SCORE = 0.5428152492668622 + AUC SCORE THRESH 0.6326530612244897 = 0.5759530791788856\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:16<00:00,  5.78s/it, batch_loss=0.568, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:54<00:00,  1.81s/it, batch_loss=1.23, loss=0.767]\n",
      "EPOCH 6/15: Validation average loss: 0.766578687230746 + AUC SCORE = 0.5126099706744868 + AUC SCORE THRESH 0.673469387755102 = 0.5639296187683285\n",
      "100%|███████████| 117/117 [11:03<00:00,  5.67s/it, batch_loss=0.766, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|████████████████| 30/30 [01:01<00:00,  2.05s/it, batch_loss=0.68, loss=0.7]\n",
      "EPOCH 7/15: Validation average loss: 0.6997993469238282 + AUC SCORE = 0.5249266862170088 + AUC SCORE THRESH 0.5714285714285714 = 0.5501466275659824\n",
      "100%|███████████| 117/117 [11:11<00:00,  5.74s/it, batch_loss=0.686, loss=0.682]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.94s/it, batch_loss=0.915, loss=0.765]\n",
      "EPOCH 8/15: Validation average loss: 0.7648158838351568 + AUC SCORE = 0.46920821114369504 + AUC SCORE THRESH 0.673469387755102 = 0.5335777126099707\n",
      "100%|████████████| 117/117 [11:10<00:00,  5.73s/it, batch_loss=0.61, loss=0.675]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.95s/it, batch_loss=0.605, loss=0.796]\n",
      "EPOCH 9/15: Validation average loss: 0.7956684321165085 + AUC SCORE = 0.5457478005865103 + AUC SCORE THRESH 0.5102040816326531 = 0.5784457478005864\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:18<00:00,  5.80s/it, batch_loss=0.645, loss=0.679]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|███████████████| 30/30 [00:54<00:00,  1.82s/it, batch_loss=0.611, loss=0.7]\n",
      "EPOCH 10/15: Validation average loss: 0.6997048377990722 + AUC SCORE = 0.506158357771261 + AUC SCORE THRESH 0.5306122448979591 = 0.5416422287390029\n",
      "100%|███████████| 117/117 [11:29<00:00,  5.89s/it, batch_loss=0.658, loss=0.669]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.95s/it, batch_loss=0.617, loss=0.701]\n",
      "EPOCH 11/15: Validation average loss: 0.7005097776651382 + AUC SCORE = 0.5099706744868034 + AUC SCORE THRESH 0.5102040816326531 = 0.5587976539589443\n",
      "100%|████████████| 117/117 [11:27<00:00,  5.87s/it, batch_loss=0.825, loss=0.67]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.705, loss=0.726]\n",
      "EPOCH 12/15: Validation average loss: 0.7262069682280222 + AUC SCORE = 0.4501466275659824 + AUC SCORE THRESH 0.7142857142857142 = 0.52316715542522\n",
      "100%|███████████| 117/117 [11:34<00:00,  5.93s/it, batch_loss=0.668, loss=0.662]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.376, loss=0.709]\n",
      "EPOCH 13/15: Validation average loss: 0.7085824747880299 + AUC SCORE = 0.4436950146627566 + AUC SCORE THRESH 0.36734693877551017 = 0.5303519061583578\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.547, loss=0.647]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:59<00:00,  1.99s/it, batch_loss=0.999, loss=0.724]\n",
      "EPOCH 14/15: Validation average loss: 0.7243539830048878 + AUC SCORE = 0.4838709677419355 + AUC SCORE THRESH 0.4897959183673469 = 0.5375366568914957\n",
      "0.5457478005865103\n",
      "train_T1wCE_1\n",
      "Loading the best images indexes for all the cases...\n",
      "Loading the best images indexes for all the cases...\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 02:01:30.486845: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|████████████| 117/117 [11:25<00:00,  5.86s/it, batch_loss=0.835, loss=0.74]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.524, loss=0.692]\n",
      "EPOCH 0/15: Validation average loss: 0.6922847022612889 + AUC SCORE = 0.5859237536656892 + AUC SCORE THRESH 0.6530612244897959 = 0.5913489736070381\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:29<00:00,  5.89s/it, batch_loss=0.763, loss=0.705]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:59<00:00,  1.97s/it, batch_loss=1.07, loss=0.768]\n",
      "EPOCH 1/15: Validation average loss: 0.7676209251085917 + AUC SCORE = 0.5782991202346042 + AUC SCORE THRESH 0.3877551020408163 = 0.6013196480938416\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.725, loss=0.694]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.79s/it, batch_loss=0.699, loss=0.693]\n",
      "EPOCH 2/15: Validation average loss: 0.6932193716367085 + AUC SCORE = 0.547800586510264 + AUC SCORE THRESH 0.5714285714285714 = 0.6155425219941348\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.778, loss=0.695]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.92s/it, batch_loss=0.899, loss=0.706]\n",
      "EPOCH 3/15: Validation average loss: 0.7055632929007213 + AUC SCORE = 0.5363636363636364 + AUC SCORE THRESH 0.5306122448979591 = 0.5590909090909091\n",
      "100%|███████████| 117/117 [11:34<00:00,  5.94s/it, batch_loss=0.712, loss=0.686]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:59<00:00,  1.97s/it, batch_loss=0.974, loss=0.711]\n",
      "EPOCH 4/15: Validation average loss: 0.7113186558087666 + AUC SCORE = 0.5129032258064516 + AUC SCORE THRESH 0.4897959183673469 = 0.5439882697947215\n",
      "100%|████████████| 117/117 [11:33<00:00,  5.93s/it, batch_loss=0.695, loss=0.69]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.98, loss=0.714]\n",
      "EPOCH 5/15: Validation average loss: 0.7143624901771546 + AUC SCORE = 0.48856304985337246 + AUC SCORE THRESH 0.4693877551020408 = 0.5598240469208211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████| 117/117 [11:33<00:00,  5.93s/it, batch_loss=0.606, loss=0.685]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|███████████████| 30/30 [01:00<00:00,  2.02s/it, batch_loss=0.738, loss=0.7]\n",
      "EPOCH 6/15: Validation average loss: 0.7001098175843556 + AUC SCORE = 0.5683284457478006 + AUC SCORE THRESH 0.5102040816326531 = 0.569941348973607\n",
      "100%|███████████| 117/117 [11:19<00:00,  5.81s/it, batch_loss=0.719, loss=0.682]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [01:04<00:00,  2.16s/it, batch_loss=1.13, loss=0.723]\n",
      "EPOCH 7/15: Validation average loss: 0.7226691484451294 + AUC SCORE = 0.5624633431085043 + AUC SCORE THRESH 0.4081632653061224 = 0.5649560117302054\n",
      "100%|████████████| 117/117 [11:25<00:00,  5.86s/it, batch_loss=0.59, loss=0.681]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.03s/it, batch_loss=0.661, loss=0.709]\n",
      "EPOCH 8/15: Validation average loss: 0.7088729550441106 + AUC SCORE = 0.48651026392961877 + AUC SCORE THRESH 0.5102040816326531 = 0.5587976539589443\n",
      "100%|███████████| 117/117 [11:24<00:00,  5.85s/it, batch_loss=0.727, loss=0.675]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.92s/it, batch_loss=0.832, loss=0.713]\n",
      "EPOCH 9/15: Validation average loss: 0.7130532304445902 + AUC SCORE = 0.4988269794721407 + AUC SCORE THRESH 0.5510204081632653 = 0.5611436950146628\n",
      "100%|████████████| 117/117 [11:37<00:00,  5.96s/it, batch_loss=0.547, loss=0.65]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|██████████████| 30/30 [00:52<00:00,  1.76s/it, batch_loss=0.48, loss=0.722]\n",
      "EPOCH 10/15: Validation average loss: 0.7216970870892206 + AUC SCORE = 0.4683284457478005 + AUC SCORE THRESH 0.36734693877551017 = 0.5181818181818182\n",
      "100%|████████████| 117/117 [11:34<00:00,  5.93s/it, batch_loss=0.839, loss=0.64]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:56<00:00,  1.89s/it, batch_loss=0.826, loss=0.752]\n",
      "EPOCH 11/15: Validation average loss: 0.7520661314328512 + AUC SCORE = 0.4516129032258065 + AUC SCORE THRESH 0.26530612244897955 = 0.5101173020527859\n",
      "100%|███████████| 117/117 [11:31<00:00,  5.91s/it, batch_loss=0.539, loss=0.621]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:55<00:00,  1.85s/it, batch_loss=0.374, loss=0.737]\n",
      "EPOCH 12/15: Validation average loss: 0.7371406267086665 + AUC SCORE = 0.4718475073313783 + AUC SCORE THRESH 0.44897959183673464 = 0.5385630498533724\n",
      "100%|███████████| 117/117 [11:32<00:00,  5.92s/it, batch_loss=0.486, loss=0.598]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.01s/it, batch_loss=0.675, loss=0.778]\n",
      "EPOCH 13/15: Validation average loss: 0.7776127388079961 + AUC SCORE = 0.48621700879765395 + AUC SCORE THRESH 0.7346938775510203 = 0.5381231671554252\n",
      "100%|████████████| 117/117 [11:25<00:00,  5.86s/it, batch_loss=0.34, loss=0.569]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.03s/it, batch_loss=0.644, loss=0.888]\n",
      "EPOCH 14/15: Validation average loss: 0.8879576275746027 + AUC SCORE = 0.4967741935483871 + AUC SCORE THRESH 0.8775510204081632 = 0.5260997067448681\n",
      "0.5859237536656892\n",
      "train_T1wCE_2\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 468/468 [01:09<00:00,  6.74it/s]\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 117/117 [00:15<00:00,  7.36it/s]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 05:10:09.547425: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [07:09<00:00,  3.67s/it, batch_loss=0.624, loss=0.723]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|███████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.559, loss=0.9]\n",
      "EPOCH 0/15: Validation average loss: 0.9003540525833765 + AUC SCORE = 0.5172716627634661 + AUC SCORE THRESH 0.5102040816326531 = 0.5522540983606558\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:29<00:00,  5.89s/it, batch_loss=0.555, loss=0.703]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.73s/it, batch_loss=0.882, loss=0.743]\n",
      "EPOCH 1/15: Validation average loss: 0.7425178209940593 + AUC SCORE = 0.5529859484777517 + AUC SCORE THRESH 0.5918367346938775 = 0.5651346604215457\n",
      "Saving the model...\n",
      "100%|████████████| 117/117 [11:23<00:00,  5.84s/it, batch_loss=0.891, loss=0.69]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:56<00:00,  1.88s/it, batch_loss=0.55, loss=0.802]\n",
      "EPOCH 2/15: Validation average loss: 0.8022603332996369 + AUC SCORE = 0.5283957845433256 + AUC SCORE THRESH 0.4897959183673469 = 0.5440573770491803\n",
      "100%|███████████| 117/117 [11:22<00:00,  5.84s/it, batch_loss=0.712, loss=0.693]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.93s/it, batch_loss=0.711, loss=0.729]\n",
      "EPOCH 3/15: Validation average loss: 0.7292274077733357 + AUC SCORE = 0.4997072599531616 + AUC SCORE THRESH 0.5102040816326531 = 0.5642564402810304\n",
      "100%|███████████| 117/117 [11:17<00:00,  5.79s/it, batch_loss=0.765, loss=0.692]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:55<00:00,  1.85s/it, batch_loss=0.725, loss=0.809]\n",
      "EPOCH 4/15: Validation average loss: 0.8094078809022903 + AUC SCORE = 0.5117096018735362 + AUC SCORE THRESH 0.5714285714285714 = 0.5418618266978923\n",
      "100%|███████████| 117/117 [11:27<00:00,  5.88s/it, batch_loss=0.748, loss=0.691]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [01:02<00:00,  2.09s/it, batch_loss=0.607, loss=0.694]\n",
      "EPOCH 5/15: Validation average loss: 0.6943311750888824 + AUC SCORE = 0.527224824355972 + AUC SCORE THRESH 0.5714285714285714 = 0.5715749414519906\n",
      "100%|███████████| 117/117 [11:05<00:00,  5.69s/it, batch_loss=0.697, loss=0.689]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.97s/it, batch_loss=0.577, loss=0.713]\n",
      "EPOCH 6/15: Validation average loss: 0.7127797623475393 + AUC SCORE = 0.5456674473067915 + AUC SCORE THRESH 0.4693877551020408 = 0.5636709601873536\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.656, loss=0.685]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:55<00:00,  1.86s/it, batch_loss=0.48, loss=0.724]\n",
      "EPOCH 7/15: Validation average loss: 0.7241149435440699 + AUC SCORE = 0.5204918032786885 + AUC SCORE THRESH 0.5102040816326531 = 0.5447892271662764\n",
      "100%|████████████| 117/117 [11:06<00:00,  5.70s/it, batch_loss=0.604, loss=0.68]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:50<00:00,  1.69s/it, batch_loss=0.79, loss=0.736]\n",
      "EPOCH 8/15: Validation average loss: 0.7357085029284159 + AUC SCORE = 0.5333723653395784 + AUC SCORE THRESH 0.5714285714285714 = 0.5509367681498829\n",
      "100%|███████████| 117/117 [11:05<00:00,  5.69s/it, batch_loss=0.789, loss=0.681]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:52<00:00,  1.77s/it, batch_loss=0.692, loss=0.707]\n",
      "EPOCH 9/15: Validation average loss: 0.7074600338935852 + AUC SCORE = 0.514344262295082 + AUC SCORE THRESH 0.5510204081632653 = 0.5620608899297423\n",
      "100%|███████████| 117/117 [10:58<00:00,  5.62s/it, batch_loss=0.675, loss=0.679]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:48<00:00,  1.62s/it, batch_loss=0.578, loss=0.697]\n",
      "EPOCH 10/15: Validation average loss: 0.6972469369570414 + AUC SCORE = 0.5196135831381733 + AUC SCORE THRESH 0.5714285714285714 = 0.5493266978922716\n",
      "100%|███████████| 117/117 [10:51<00:00,  5.57s/it, batch_loss=0.791, loss=0.675]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.566, loss=0.702]\n",
      "EPOCH 11/15: Validation average loss: 0.7024828513463338 + AUC SCORE = 0.5067330210772834 + AUC SCORE THRESH 0.5510204081632653 = 0.5403981264637002\n",
      "100%|████████████| 117/117 [10:47<00:00,  5.54s/it, batch_loss=0.834, loss=0.67]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 30/30 [00:48<00:00,  1.62s/it, batch_loss=0.762, loss=0.715]\n",
      "EPOCH 12/15: Validation average loss: 0.7148974816004435 + AUC SCORE = 0.5257611241217799 + AUC SCORE THRESH 0.5510204081632653 = 0.5613290398126464\n",
      "100%|███████████| 117/117 [10:27<00:00,  5.36s/it, batch_loss=0.698, loss=0.676]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:50<00:00,  1.68s/it, batch_loss=0.625, loss=0.724]\n",
      "EPOCH 13/15: Validation average loss: 0.7237817148367564 + AUC SCORE = 0.5117096018735363 + AUC SCORE THRESH 0.6122448979591836 = 0.5529859484777517\n",
      "100%|███████████| 117/117 [10:48<00:00,  5.54s/it, batch_loss=0.662, loss=0.668]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.698, loss=0.713]\n",
      "EPOCH 14/15: Validation average loss: 0.7131009519100189 + AUC SCORE = 0.5102459016393442 + AUC SCORE THRESH 0.673469387755102 = 0.537324355971897\n",
      "0.5529859484777517\n",
      "train_T1wCE_3\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 468/468 [01:07<00:00,  6.98it/s]\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 117/117 [00:17<00:00,  6.54it/s]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 08:07:34.083197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [08:15<00:00,  4.23s/it, batch_loss=0.615, loss=0.719]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.597, loss=0.687]\n",
      "EPOCH 0/15: Validation average loss: 0.6874020646015803 + AUC SCORE = 0.4944379391100703 + AUC SCORE THRESH 0.3877551020408163 = 0.5661592505854801\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [10:52<00:00,  5.57s/it, batch_loss=0.743, loss=0.705]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:50<00:00,  1.68s/it, batch_loss=1.13, loss=0.682]\n",
      "EPOCH 1/15: Validation average loss: 0.681970696647962 + AUC SCORE = 0.6548594847775177 + AUC SCORE THRESH 0.42857142857142855 = 0.6627634660421545\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [10:43<00:00,  5.50s/it, batch_loss=0.675, loss=0.702]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.65s/it, batch_loss=0.741, loss=0.683]\n",
      "EPOCH 2/15: Validation average loss: 0.6826387484868367 + AUC SCORE = 0.603337236533958 + AUC SCORE THRESH 0.44897959183673464 = 0.6412470725995316\n",
      "100%|███████████| 117/117 [10:43<00:00,  5.50s/it, batch_loss=0.788, loss=0.696]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:54<00:00,  1.80s/it, batch_loss=1.02, loss=0.708]\n",
      "EPOCH 3/15: Validation average loss: 0.7079744189977646 + AUC SCORE = 0.6009953161592506 + AUC SCORE THRESH 0.42857142857142855 = 0.6001170960187353\n",
      "100%|███████████| 117/117 [10:31<00:00,  5.40s/it, batch_loss=0.822, loss=0.694]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.761, loss=0.681]\n",
      "EPOCH 4/15: Validation average loss: 0.6810800532499949 + AUC SCORE = 0.601288056206089 + AUC SCORE THRESH 0.4897959183673469 = 0.5913348946135831\n",
      "100%|███████████| 117/117 [10:28<00:00,  5.37s/it, batch_loss=0.679, loss=0.687]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:49<00:00,  1.64s/it, batch_loss=1.11, loss=0.727]\n",
      "EPOCH 5/15: Validation average loss: 0.7268936266501744 + AUC SCORE = 0.6387587822014053 + AUC SCORE THRESH 0.36734693877551017 = 0.6359777517564402\n",
      "100%|███████████| 117/117 [10:45<00:00,  5.52s/it, batch_loss=0.657, loss=0.692]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.65s/it, batch_loss=0.623, loss=0.677]\n",
      "EPOCH 6/15: Validation average loss: 0.6772445728381474 + AUC SCORE = 0.5872365339578454 + AUC SCORE THRESH 0.5102040816326531 = 0.6203161592505855\n",
      "100%|████████████| 117/117 [10:48<00:00,  5.54s/it, batch_loss=0.636, loss=0.69]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.63s/it, batch_loss=0.591, loss=0.708]\n",
      "EPOCH 7/15: Validation average loss: 0.7076821188131969 + AUC SCORE = 0.5117096018735363 + AUC SCORE THRESH 0.5306122448979591 = 0.545228337236534\n",
      "100%|███████████| 117/117 [10:59<00:00,  5.64s/it, batch_loss=0.713, loss=0.688]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:54<00:00,  1.80s/it, batch_loss=0.682, loss=0.696]\n",
      "EPOCH 8/15: Validation average loss: 0.6964038878679275 + AUC SCORE = 0.5433255269320842 + AUC SCORE THRESH 0.4897959183673469 = 0.5690866510538641\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.695, loss=0.686]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.947, loss=0.743]\n",
      "EPOCH 9/15: Validation average loss: 0.7430156379938125 + AUC SCORE = 0.4651639344262295 + AUC SCORE THRESH 0.3469387755102041 = 0.5579625292740047\n",
      "100%|███████████| 117/117 [11:09<00:00,  5.73s/it, batch_loss=0.644, loss=0.669]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.66s/it, batch_loss=0.842, loss=0.726]\n",
      "EPOCH 10/15: Validation average loss: 0.7262662470340728 + AUC SCORE = 0.4475995316159251 + AUC SCORE THRESH 0.673469387755102 = 0.5163934426229508\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.743, loss=0.661]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:59<00:00,  1.97s/it, batch_loss=0.984, loss=0.767]\n",
      "EPOCH 11/15: Validation average loss: 0.7670036474863688 + AUC SCORE = 0.4142271662763466 + AUC SCORE THRESH 0.7755102040816326 = 0.5163934426229508\n",
      "100%|████████████| 117/117 [11:02<00:00,  5.66s/it, batch_loss=0.615, loss=0.66]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:55<00:00,  1.86s/it, batch_loss=0.638, loss=0.756]\n",
      "EPOCH 12/15: Validation average loss: 0.7560017724831899 + AUC SCORE = 0.4461358313817331 + AUC SCORE THRESH 0.5102040816326531 = 0.5117096018735363\n",
      "100%|███████████| 117/117 [11:09<00:00,  5.72s/it, batch_loss=0.768, loss=0.645]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.77s/it, batch_loss=0.748, loss=0.762]\n",
      "EPOCH 13/15: Validation average loss: 0.7621376474698385 + AUC SCORE = 0.474824355971897 + AUC SCORE THRESH 0.3877551020408163 = 0.5281030444964872\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.71s/it, batch_loss=0.608, loss=0.638]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.66s/it, batch_loss=0.651, loss=0.778]\n",
      "EPOCH 14/15: Validation average loss: 0.7779558042685191 + AUC SCORE = 0.39900468384074944 + AUC SCORE THRESH 0.0 = 0.5\n",
      "0.6548594847775177\n",
      "train_T1wCE_4\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 468/468 [01:07<00:00,  6.93it/s]\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 117/117 [00:17<00:00,  6.78it/s]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 11:02:55.481912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [07:37<00:00,  3.91s/it, batch_loss=0.681, loss=0.729]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.236, loss=0.69]\n",
      "EPOCH 0/15: Validation average loss: 0.6898635506629944 + AUC SCORE = 0.5685011709601874 + AUC SCORE THRESH 0.5306122448979591 = 0.5979215456674473\n",
      "Saving the model...\n",
      "100%|█████████████| 117/117 [11:02<00:00,  5.66s/it, batch_loss=0.769, loss=0.7]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.778, loss=0.694]\n",
      "EPOCH 1/15: Validation average loss: 0.6942250847816467 + AUC SCORE = 0.5377634660421545 + AUC SCORE THRESH 0.5918367346938775 = 0.5343969555035128\n",
      "100%|███████████| 117/117 [11:04<00:00,  5.68s/it, batch_loss=0.709, loss=0.703]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 30/30 [00:52<00:00,  1.76s/it, batch_loss=0.853, loss=0.713]\n",
      "EPOCH 2/15: Validation average loss: 0.7134011109670003 + AUC SCORE = 0.5362997658079625 + AUC SCORE THRESH 0.5918367346938775 = 0.5645491803278688\n",
      "100%|███████████| 117/117 [11:06<00:00,  5.70s/it, batch_loss=0.744, loss=0.699]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:50<00:00,  1.69s/it, batch_loss=0.375, loss=0.704]\n",
      "EPOCH 3/15: Validation average loss: 0.7035461147626241 + AUC SCORE = 0.5620608899297425 + AUC SCORE THRESH 0.44897959183673464 = 0.5769906323185011\n",
      "100%|███████████| 117/117 [11:05<00:00,  5.69s/it, batch_loss=0.766, loss=0.685]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:50<00:00,  1.69s/it, batch_loss=0.388, loss=0.697]\n",
      "EPOCH 4/15: Validation average loss: 0.6969916254281998 + AUC SCORE = 0.539519906323185 + AUC SCORE THRESH 0.5918367346938775 = 0.5560597189695549\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.462, loss=0.689]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.66s/it, batch_loss=0.229, loss=0.721]\n",
      "EPOCH 5/15: Validation average loss: 0.721374407907327 + AUC SCORE = 0.5544496487119438 + AUC SCORE THRESH 0.5510204081632653 = 0.5665983606557377\n",
      "100%|███████████| 117/117 [11:14<00:00,  5.76s/it, batch_loss=0.525, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.02s/it, batch_loss=0.629, loss=0.721]\n",
      "EPOCH 6/15: Validation average loss: 0.7210925231377284 + AUC SCORE = 0.5559133489461358 + AUC SCORE THRESH 0.6122448979591836 = 0.571135831381733\n",
      "100%|███████████| 117/117 [11:18<00:00,  5.80s/it, batch_loss=0.805, loss=0.688]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.73s/it, batch_loss=0.461, loss=0.694]\n",
      "EPOCH 7/15: Validation average loss: 0.6943967928489049 + AUC SCORE = 0.5415690866510539 + AUC SCORE THRESH 0.5714285714285714 = 0.5739168618266979\n",
      "100%|███████████| 117/117 [11:11<00:00,  5.74s/it, batch_loss=0.509, loss=0.673]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:52<00:00,  1.75s/it, batch_loss=0.779, loss=0.71]\n",
      "EPOCH 8/15: Validation average loss: 0.7098765790462493 + AUC SCORE = 0.5128805620608898 + AUC SCORE THRESH 0.6122448979591836 = 0.5352751756440282\n",
      "100%|████████████| 117/117 [11:30<00:00,  5.90s/it, batch_loss=0.864, loss=0.68]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.78s/it, batch_loss=0.783, loss=0.723]\n",
      "EPOCH 9/15: Validation average loss: 0.7228919426600139 + AUC SCORE = 0.5272248243559718 + AUC SCORE THRESH 0.5510204081632653 = 0.5584016393442623\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.595, loss=0.665]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|██████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.74, loss=0.742]\n",
      "EPOCH 10/15: Validation average loss: 0.7418981492519379 + AUC SCORE = 0.498536299765808 + AUC SCORE THRESH 0.5918367346938775 = 0.5383489461358314\n",
      "100%|███████████| 117/117 [11:34<00:00,  5.93s/it, batch_loss=0.704, loss=0.657]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.03s/it, batch_loss=0.374, loss=0.738]\n",
      "EPOCH 11/15: Validation average loss: 0.7378725240627925 + AUC SCORE = 0.4795081967213115 + AUC SCORE THRESH 0.5306122448979591 = 0.5449355971896955\n",
      "100%|███████████| 117/117 [11:30<00:00,  5.90s/it, batch_loss=0.548, loss=0.652]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:01<00:00,  2.04s/it, batch_loss=0.774, loss=0.786]\n",
      "EPOCH 12/15: Validation average loss: 0.7856268147627513 + AUC SCORE = 0.42798594847775173 + AUC SCORE THRESH 0.836734693877551 = 0.5081967213114754\n",
      "100%|███████████| 117/117 [11:26<00:00,  5.87s/it, batch_loss=0.569, loss=0.651]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|██████████████| 30/30 [01:00<00:00,  2.02s/it, batch_loss=1.16, loss=0.806]\n",
      "EPOCH 13/15: Validation average loss: 0.8058923304080963 + AUC SCORE = 0.44057377049180335 + AUC SCORE THRESH 0.5306122448979591 = 0.5251756440281031\n",
      "100%|███████████| 117/117 [11:37<00:00,  5.96s/it, batch_loss=0.712, loss=0.631]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.796, loss=0.943]\n",
      "EPOCH 14/15: Validation average loss: 0.9430062651634217 + AUC SCORE = 0.4142271662763466 + AUC SCORE THRESH 0.18367346938775508 = 0.5177107728337236\n",
      "0.5685011709601874\n"
     ]
    }
   ],
   "source": [
    "!python3 ../rsnaresnet10/working/train.py --fold 0 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 1 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 2 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 3 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 4 --type T1wCE --model_name resnet10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../rsnaresnet10/working/validation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../rsnaresnet10/working/create_splits.py --in_csv_file train_labels.csv --out_csv_file train_f.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../rsnaresnet10/working/create_splits.py --in_csv_file upenn_train_labels.csv --out_csv_file train_n.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_T1wCE\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 413/413 [00:47<00:00,  8.61it/s]\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 114/114 [00:13<00:00,  8.30it/s]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|███████████| 103/103 [00:56<00:00,  1.84it/s, batch_loss=0.696, loss=0.706]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|█████████████| 29/29 [00:07<00:00,  4.11it/s, batch_loss=0.517, loss=0.716]\n",
      "EPOCH 0/100: Validation average loss: 0.7164127189537575 + AUC SCORE = 0.4073959938366718 + AUC SCORE THRESH 0.0 = 0.5\n",
      "Saving the model...\n",
      "100%|███████████| 103/103 [00:54<00:00,  1.87it/s, batch_loss=0.686, loss=0.691]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|██████████████| 29/29 [00:06<00:00,  4.18it/s, batch_loss=0.513, loss=0.72]\n",
      "EPOCH 1/100: Validation average loss: 0.7198914310027813 + AUC SCORE = 0.3821263482280431 + AUC SCORE THRESH 0.0 = 0.5\n",
      "100%|████████████| 103/103 [00:55<00:00,  1.87it/s, batch_loss=0.675, loss=0.68]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|█████████████| 29/29 [00:07<00:00,  4.08it/s, batch_loss=0.507, loss=0.723]\n",
      "EPOCH 2/100: Validation average loss: 0.7234024323266128 + AUC SCORE = 0.4049306625577812 + AUC SCORE THRESH 0.0 = 0.5\n",
      "100%|█████████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.67, loss=0.67]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|█████████████| 29/29 [00:07<00:00,  3.94it/s, batch_loss=0.557, loss=0.727]\n",
      "EPOCH 3/100: Validation average loss: 0.727480294375584 + AUC SCORE = 0.4234206471494607 + AUC SCORE THRESH 0.4693877551020408 = 0.5186440677966102\n",
      "Saving the model...\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.87it/s, batch_loss=0.671, loss=0.658]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|█████████████| 29/29 [00:07<00:00,  4.04it/s, batch_loss=0.697, loss=0.747]\n",
      "EPOCH 4/100: Validation average loss: 0.747475149302647 + AUC SCORE = 0.43297380585516176 + AUC SCORE THRESH 0.3469387755102041 = 0.5072419106317412\n",
      "Saving the model...\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.644, loss=0.645]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|█████████████| 29/29 [00:07<00:00,  4.08it/s, batch_loss=0.924, loss=0.785]\n",
      "EPOCH 5/100: Validation average loss: 0.78463112999653 + AUC SCORE = 0.43235747303543914 + AUC SCORE THRESH 0.0 = 0.5\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.601, loss=0.628]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|██████████████| 29/29 [00:07<00:00,  4.02it/s, batch_loss=1.13, loss=0.859]\n",
      "EPOCH 6/100: Validation average loss: 0.8585939592328565 + AUC SCORE = 0.4144838212634823 + AUC SCORE THRESH 0.0 = 0.5\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.571, loss=0.602]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|██████████████| 29/29 [00:07<00:00,  4.09it/s, batch_loss=1.28, loss=0.929]\n",
      "EPOCH 7/100: Validation average loss: 0.9289548767024073 + AUC SCORE = 0.40061633281972264 + AUC SCORE THRESH 0.0 = 0.5\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.539, loss=0.567]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|███████████████| 29/29 [00:06<00:00,  4.16it/s, batch_loss=1.53, loss=1.03]\n",
      "EPOCH 8/100: Validation average loss: 1.0333317805980813 + AUC SCORE = 0.41078582434514643 + AUC SCORE THRESH 0.0 = 0.5\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.478, loss=0.529]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.07it/s, batch_loss=1.78, loss=1.13]\n",
      "EPOCH 9/100: Validation average loss: 1.1270692240575264 + AUC SCORE = 0.42742681047765796 + AUC SCORE THRESH 0.0 = 0.5\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.404, loss=0.483]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 29/29 [00:07<00:00,  4.02it/s, batch_loss=0.974, loss=0.958]\n",
      "EPOCH 10/100: Validation average loss: 0.958069981172167 + AUC SCORE = 0.36425269645608627 + AUC SCORE THRESH 0.0 = 0.5\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.347, loss=0.443]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.08it/s, batch_loss=1.13, loss=1.02]\n",
      "EPOCH 11/100: Validation average loss: 1.0183016483126015 + AUC SCORE = 0.3864406779661017 + AUC SCORE THRESH 0.0 = 0.5\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.287, loss=0.408]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:06<00:00,  4.19it/s, batch_loss=1.14, loss=1.04]\n",
      "EPOCH 12/100: Validation average loss: 1.0358164885948444 + AUC SCORE = 0.40308166409861323 + AUC SCORE THRESH 0.0 = 0.5\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.242, loss=0.375]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.13it/s, batch_loss=1.08, loss=1.03]\n",
      "EPOCH 13/100: Validation average loss: 1.0295716724519073 + AUC SCORE = 0.4151001540832049 + AUC SCORE THRESH 0.04081632653061224 = 0.5084745762711864\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.207, loss=0.344]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.04it/s, batch_loss=1.08, loss=1.04]\n",
      "EPOCH 14/100: Validation average loss: 1.0411062312537227 + AUC SCORE = 0.4184899845916795 + AUC SCORE THRESH 0.04081632653061224 = 0.5084745762711864\n",
      "100%|████████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.18, loss=0.316]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.05it/s, batch_loss=1.08, loss=1.05]\n",
      "EPOCH 15/100: Validation average loss: 1.0517143571171268 + AUC SCORE = 0.4206471494607088 + AUC SCORE THRESH 0.8775510204081632 = 0.5006163328197226\n",
      "100%|████████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.16, loss=0.291]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.05it/s, batch_loss=1.15, loss=1.09]\n",
      "EPOCH 16/100: Validation average loss: 1.0869325301770507 + AUC SCORE = 0.4283513097072419 + AUC SCORE THRESH 0.04081632653061224 = 0.5078582434514638\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.145, loss=0.269]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.00it/s, batch_loss=1.27, loss=1.14]\n",
      "EPOCH 17/100: Validation average loss: 1.1441490773496956 + AUC SCORE = 0.43420647149460706 + AUC SCORE THRESH 0.02040816326530612 = 0.5084745762711864\n",
      "Saving the model...\n",
      "100%|████████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.136, loss=0.25]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 29/29 [00:07<00:00,  4.00it/s, batch_loss=1.4, loss=1.22]\n",
      "EPOCH 18/100: Validation average loss: 1.221558310348412 + AUC SCORE = 0.4446841294298921 + AUC SCORE THRESH 0.02040816326530612 = 0.5169491525423728\n",
      "Saving the model...\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.122, loss=0.234]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:06<00:00,  4.22it/s, batch_loss=1.44, loss=1.28]\n",
      "EPOCH 19/100: Validation average loss: 1.2784315357948173 + AUC SCORE = 0.44745762711864406 + AUC SCORE THRESH 0.02040816326530612 = 0.5078582434514638\n",
      "Saving the model...\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.106, loss=0.219]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.12it/s, batch_loss=1.38, loss=1.28]\n",
      "EPOCH 20/100: Validation average loss: 1.2792422249913216 + AUC SCORE = 0.437904468412943 + AUC SCORE THRESH 0.9387755102040816 = 0.5006163328197226\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0925, loss=0.215]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|██████████████| 29/29 [00:07<00:00,  4.08it/s, batch_loss=0.976, loss=1.15]\n",
      "EPOCH 21/100: Validation average loss: 1.145640733940848 + AUC SCORE = 0.4206471494607088 + AUC SCORE THRESH 0.9591836734693877 = 0.5006163328197226\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.114, loss=0.231]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 29/29 [00:07<00:00,  4.07it/s, batch_loss=1.02, loss=1.1]\n",
      "EPOCH 22/100: Validation average loss: 1.0981528322244514 + AUC SCORE = 0.4446841294298922 + AUC SCORE THRESH 0.3061224489795918 = 0.510477657935285\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.0901, loss=0.213]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 29/29 [00:07<00:00,  4.14it/s, batch_loss=2.4, loss=1.85]\n",
      "EPOCH 23/100: Validation average loss: 1.8514853403421825 + AUC SCORE = 0.5060092449922958 + AUC SCORE THRESH 0.02040816326530612 = 0.5548536209553159\n",
      "Saving the model...\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0905, loss=0.204]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.00it/s, batch_loss=2.17, loss=1.83]\n",
      "EPOCH 24/100: Validation average loss: 1.8273495189074813 + AUC SCORE = 0.4979969183359014 + AUC SCORE THRESH 0.02040816326530612 = 0.5457627118644068\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.115, loss=0.188]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.05it/s, batch_loss=1.85, loss=1.58]\n",
      "EPOCH 25/100: Validation average loss: 1.5753335839715497 + AUC SCORE = 0.4591679506933744 + AUC SCORE THRESH 0.9387755102040816 = 0.509090909090909\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.103, loss=0.177]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.00it/s, batch_loss=1.75, loss=1.45]\n",
      "EPOCH 26/100: Validation average loss: 1.454237543303391 + AUC SCORE = 0.45608628659476114 + AUC SCORE THRESH 0.02040816326530612 = 0.5308166409861326\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0862, loss=0.17]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.03it/s, batch_loss=1.91, loss=1.53]\n",
      "EPOCH 27/100: Validation average loss: 1.5301748257258843 + AUC SCORE = 0.46070878274268107 + AUC SCORE THRESH 0.8979591836734693 = 0.509090909090909\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0898, loss=0.163]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.07it/s, batch_loss=1.92, loss=1.55]\n",
      "EPOCH 28/100: Validation average loss: 1.5526603068514118 + AUC SCORE = 0.4533127889060093 + AUC SCORE THRESH 0.02040816326530612 = 0.5186440677966102\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0903, loss=0.155]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  3.98it/s, batch_loss=1.81, loss=1.48]\n",
      "EPOCH 29/100: Validation average loss: 1.4791235548668895 + AUC SCORE = 0.44468412942989216 + AUC SCORE THRESH 0.8775510204081632 = 0.509090909090909\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0729, loss=0.148]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.14it/s, batch_loss=1.86, loss=1.43]\n",
      "EPOCH 30/100: Validation average loss: 1.4309714067855785 + AUC SCORE = 0.4440677966101695 + AUC SCORE THRESH 0.02040816326530612 = 0.5126348228043144\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.059, loss=0.141]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.00it/s, batch_loss=1.96, loss=1.45]\n",
      "EPOCH 31/100: Validation average loss: 1.451528213918209 + AUC SCORE = 0.44838212634822805 + AUC SCORE THRESH 0.02040816326530612 = 0.5041602465331279\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0494, loss=0.136]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.10it/s, batch_loss=2.04, loss=1.51]\n",
      "EPOCH 32/100: Validation average loss: 1.514545297828214 + AUC SCORE = 0.4446841294298922 + AUC SCORE THRESH 0.5918367346938775 = 0.5097072419106318\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0449, loss=0.131]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.07it/s, batch_loss=2.12, loss=1.58]\n",
      "EPOCH 33/100: Validation average loss: 1.5822477844254723 + AUC SCORE = 0.4453004622496148 + AUC SCORE THRESH 0.02040816326530612 = 0.5277349768875194\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0411, loss=0.126]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.02it/s, batch_loss=2.44, loss=1.76]\n",
      "EPOCH 34/100: Validation average loss: 1.7571313053626438 + AUC SCORE = 0.4591679506933744 + AUC SCORE THRESH 0.02040816326530612 = 0.5143297380585516\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0361, loss=0.123]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.00it/s, batch_loss=2.66, loss=1.92]\n",
      "EPOCH 35/100: Validation average loss: 1.9198890437275684 + AUC SCORE = 0.46656394453004624 + AUC SCORE THRESH 0.4693877551020408 = 0.5006163328197226\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0322, loss=0.121]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.00it/s, batch_loss=2.46, loss=1.95]\n",
      "EPOCH 36/100: Validation average loss: 1.9454803606495261 + AUC SCORE = 0.44961479198767335 + AUC SCORE THRESH 0.44897959183673464 = 0.5006163328197226\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.032, loss=0.118]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.08it/s, batch_loss=2.86, loss=2.07]\n",
      "EPOCH 37/100: Validation average loss: 2.0721111088220416 + AUC SCORE = 0.46933744221879814 + AUC SCORE THRESH 0.3469387755102041 = 0.5006163328197226\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0612, loss=0.125]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.05it/s, batch_loss=2.63, loss=1.95]\n",
      "EPOCH 38/100: Validation average loss: 1.9524126330326343 + AUC SCORE = 0.4582434514637905 + AUC SCORE THRESH 0.3061224489795918 = 0.5103235747303543\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0292, loss=0.121]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.11it/s, batch_loss=2.02, loss=1.81]\n",
      "EPOCH 39/100: Validation average loss: 1.8128311572403744 + AUC SCORE = 0.42342064714946065 + AUC SCORE THRESH 0.3877551020408163 = 0.5024653312788906\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.0521, loss=0.132]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.08it/s, batch_loss=1.26, loss=1.09]\n",
      "EPOCH 40/100: Validation average loss: 1.0949769826798603 + AUC SCORE = 0.3895223420647149 + AUC SCORE THRESH 0.5918367346938775 = 0.5328197226502311\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0284, loss=0.113]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.06it/s, batch_loss=1.44, loss=1.25]\n",
      "EPOCH 41/100: Validation average loss: 1.2465769725626912 + AUC SCORE = 0.39537750385208015 + AUC SCORE THRESH 0.4081632653061224 = 0.5158705701078583\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0331, loss=0.118]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.03it/s, batch_loss=1.34, loss=1.05]\n",
      "EPOCH 42/100: Validation average loss: 1.0534143689377555 + AUC SCORE = 0.3879815100154083 + AUC SCORE THRESH 0.7551020408163265 = 0.5231124807395994\n",
      "100%|███████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.113, loss=0.109]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.01it/s, batch_loss=1.75, loss=1.16]\n",
      "EPOCH 43/100: Validation average loss: 1.1616666984969173 + AUC SCORE = 0.4184899845916795 + AUC SCORE THRESH 0.7551020408163265 = 0.5097072419106318\n",
      "100%|████████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0437, loss=0.1]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.01it/s, batch_loss=1.92, loss=1.17]\n",
      "EPOCH 44/100: Validation average loss: 1.1687129895234931 + AUC SCORE = 0.4261941448382126 + AUC SCORE THRESH 0.061224489795918366 = 0.5380585516178736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0581, loss=0.104]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.09it/s, batch_loss=2.06, loss=1.45]\n",
      "EPOCH 45/100: Validation average loss: 1.448846079152206 + AUC SCORE = 0.43728813559322033 + AUC SCORE THRESH 0.02040816326530612 = 0.5035439137134052\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0253, loss=0.0864]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.11it/s, batch_loss=1.88, loss=1.27]\n",
      "EPOCH 46/100: Validation average loss: 1.2706241962210885 + AUC SCORE = 0.4228043143297381 + AUC SCORE THRESH 0.36734693877551017 = 0.5134052388289677\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.026, loss=0.0912]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  3.95it/s, batch_loss=2.06, loss=1.46]\n",
      "EPOCH 47/100: Validation average loss: 1.4636258444395558 + AUC SCORE = 0.4098613251155624 + AUC SCORE THRESH 0.6938775510204082 = 0.5006163328197226\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0321, loss=0.0909]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.01it/s, batch_loss=1.51, loss=1.13]\n",
      "EPOCH 48/100: Validation average loss: 1.1258060038089752 + AUC SCORE = 0.39291217257318956 + AUC SCORE THRESH 0.6530612244897959 = 0.5134052388289677\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0257, loss=0.0772]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 29/29 [00:07<00:00,  4.08it/s, batch_loss=1.97, loss=1.3]\n",
      "EPOCH 49/100: Validation average loss: 1.3042492833116959 + AUC SCORE = 0.3963020030816642 + AUC SCORE THRESH 0.6938775510204082 = 0.5012326656394452\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0273, loss=0.0731]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 29/29 [00:07<00:00,  4.02it/s, batch_loss=1.7, loss=1.11]\n",
      "EPOCH 50/100: Validation average loss: 1.1071425326939286 + AUC SCORE = 0.39784283513097074 + AUC SCORE THRESH 0.5918367346938775 = 0.5134052388289677\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.029, loss=0.0701]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.13it/s, batch_loss=2.22, loss=1.43]\n",
      "EPOCH 51/100: Validation average loss: 1.428575240846338 + AUC SCORE = 0.41294298921417566 + AUC SCORE THRESH 0.02040816326530612 = 0.5126348228043144\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.86it/s, batch_loss=0.0208, loss=0.0665]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.01it/s, batch_loss=1.91, loss=1.23]\n",
      "EPOCH 52/100: Validation average loss: 1.2269835297403664 + AUC SCORE = 0.39999999999999997 + AUC SCORE THRESH 0.8775510204081632 = 0.5097072419106318\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0205, loss=0.0618]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  3.98it/s, batch_loss=2.02, loss=1.42]\n",
      "EPOCH 53/100: Validation average loss: 1.4183536803927914 + AUC SCORE = 0.40585516178736514 + AUC SCORE THRESH 0.6530612244897959 = 0.5012326656394452\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0191, loss=0.0578]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.11it/s, batch_loss=1.96, loss=1.25]\n",
      "EPOCH 54/100: Validation average loss: 1.2459946839973843 + AUC SCORE = 0.3904468412942989 + AUC SCORE THRESH 0.6326530612244897 = 0.5030816640986132\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0203, loss=0.0543]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|██████████████████| 29/29 [00:07<00:00,  4.05it/s, batch_loss=2, loss=1.29]\n",
      "EPOCH 55/100: Validation average loss: 1.2932505453455037 + AUC SCORE = 0.39876733436055467 + AUC SCORE THRESH 0.7346938775510203 = 0.5012326656394452\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0179, loss=0.0515]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.02it/s, batch_loss=2.09, loss=1.34]\n",
      "EPOCH 56/100: Validation average loss: 1.339900137535457 + AUC SCORE = 0.39938366718027735 + AUC SCORE THRESH 0.7346938775510203 = 0.5012326656394452\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.84it/s, batch_loss=0.0182, loss=0.0489]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  3.94it/s, batch_loss=1.97, loss=1.32]\n",
      "EPOCH 57/100: Validation average loss: 1.3170674458659928 + AUC SCORE = 0.398151001540832 + AUC SCORE THRESH 0.7551020408163265 = 0.5012326656394452\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0199, loss=0.0476]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  3.95it/s, batch_loss=2.14, loss=1.48]\n",
      "EPOCH 58/100: Validation average loss: 1.4800284283942189 + AUC SCORE = 0.4033898305084746 + AUC SCORE THRESH 0.9183673469387754 = 0.5006163328197226\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.84it/s, batch_loss=0.0204, loss=0.0486]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  3.94it/s, batch_loss=1.74, loss=1.12]\n",
      "EPOCH 59/100: Validation average loss: 1.1233283723222798 + AUC SCORE = 0.3956856702619414 + AUC SCORE THRESH 0.9591836734693877 = 0.5097072419106318\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0306, loss=0.048]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.04it/s, batch_loss=2.29, loss=1.58]\n",
      "EPOCH 60/100: Validation average loss: 1.5849190313240578 + AUC SCORE = 0.41664098613251155 + AUC SCORE THRESH 0.8979591836734693 = 0.5006163328197226\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0201, loss=0.0469]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.11it/s, batch_loss=1.94, loss=1.16]\n",
      "EPOCH 61/100: Validation average loss: 1.1600531447550346 + AUC SCORE = 0.39815100154083205 + AUC SCORE THRESH 0.8571428571428571 = 0.5103235747303543\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0324, loss=0.0447]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████████| 29/29 [00:06<00:00,  4.22it/s, batch_loss=2.3, loss=1.6]\n",
      "EPOCH 62/100: Validation average loss: 1.6032443008032338 + AUC SCORE = 0.4184899845916795 + AUC SCORE THRESH 0.836734693877551 = 0.5006163328197226\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0178, loss=0.0408]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  3.99it/s, batch_loss=2.14, loss=1.25]\n",
      "EPOCH 63/100: Validation average loss: 1.2463163748897355 + AUC SCORE = 0.3929121725731895 + AUC SCORE THRESH 0.7755102040816326 = 0.5018489984591679\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0188, loss=0.035]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.01it/s, batch_loss=2.53, loss=1.68]\n",
      "EPOCH 64/100: Validation average loss: 1.6817760691046715 + AUC SCORE = 0.4141756548536209 + AUC SCORE THRESH 0.9183673469387754 = 0.5006163328197226\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0136, loss=0.0334]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.05it/s, batch_loss=2.17, loss=1.34]\n",
      "EPOCH 65/100: Validation average loss: 1.34240926904925 + AUC SCORE = 0.39599383667180277 + AUC SCORE THRESH 0.3061224489795918 = 0.5080123266563944\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0164, loss=0.0309]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:06<00:00,  4.16it/s, batch_loss=2.44, loss=1.63]\n",
      "EPOCH 66/100: Validation average loss: 1.6259790006382713 + AUC SCORE = 0.41047765793528507 + AUC SCORE THRESH 0.8571428571428571 = 0.5006163328197226\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0121, loss=0.0289]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 29/29 [00:07<00:00,  4.06it/s, batch_loss=2.2, loss=1.37]\n",
      "EPOCH 67/100: Validation average loss: 1.3671363129697998 + AUC SCORE = 0.39784283513097074 + AUC SCORE THRESH 0.836734693877551 = 0.5012326656394452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0129, loss=0.0273]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.02it/s, batch_loss=2.36, loss=1.51]\n",
      "EPOCH 68/100: Validation average loss: 1.510220160515144 + AUC SCORE = 0.40739599383667185 + AUC SCORE THRESH 0.7551020408163265 = 0.5012326656394452\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0132, loss=0.0259]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.02it/s, batch_loss=2.36, loss=1.51]\n",
      "EPOCH 69/100: Validation average loss: 1.5054346813723958 + AUC SCORE = 0.40431432973805853 + AUC SCORE THRESH 0.7755102040816326 = 0.5012326656394452\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0112, loss=0.0244]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.00it/s, batch_loss=2.33, loss=1.44]\n",
      "EPOCH 70/100: Validation average loss: 1.4445842242446438 + AUC SCORE = 0.40092449922958395 + AUC SCORE THRESH 0.8163265306122448 = 0.5012326656394452\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0124, loss=0.0232]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.06it/s, batch_loss=2.41, loss=1.55]\n",
      "EPOCH 71/100: Validation average loss: 1.5450006147910809 + AUC SCORE = 0.4067796610169492 + AUC SCORE THRESH 0.7755102040816326 = 0.5012326656394452\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0102, loss=0.022]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.07it/s, batch_loss=2.33, loss=1.44]\n",
      "EPOCH 72/100: Validation average loss: 1.4423152444691494 + AUC SCORE = 0.40061633281972264 + AUC SCORE THRESH 0.836734693877551 = 0.5012326656394452\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0117, loss=0.021]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.01it/s, batch_loss=2.45, loss=1.57]\n",
      "EPOCH 73/100: Validation average loss: 1.5746389049394378 + AUC SCORE = 0.40616332819722645 + AUC SCORE THRESH 0.9591836734693877 = 0.5006163328197226\n",
      "100%|████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00931, loss=0.0199]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.03it/s, batch_loss=2.34, loss=1.44]\n",
      "EPOCH 74/100: Validation average loss: 1.4407514724238166 + AUC SCORE = 0.4012326656394453 + AUC SCORE THRESH 0.836734693877551 = 0.5012326656394452\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.84it/s, batch_loss=0.0109, loss=0.0191]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 29/29 [00:07<00:00,  4.12it/s, batch_loss=2.49, loss=1.6]\n",
      "EPOCH 75/100: Validation average loss: 1.5961509390637791 + AUC SCORE = 0.4086286594761171 + AUC SCORE THRESH 0.9591836734693877 = 0.5006163328197226\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00854, loss=0.018]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:06<00:00,  4.22it/s, batch_loss=2.37, loss=1.46]\n",
      "EPOCH 76/100: Validation average loss: 1.4563510782759765 + AUC SCORE = 0.40092449922958395 + AUC SCORE THRESH 0.836734693877551 = 0.5012326656394452\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0101, loss=0.0173]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 29/29 [00:07<00:00,  3.92it/s, batch_loss=2.5, loss=1.61]\n",
      "EPOCH 77/100: Validation average loss: 1.6073585884838268 + AUC SCORE = 0.4089368258859784 + AUC SCORE THRESH 0.9591836734693877 = 0.5006163328197226\n",
      "100%|████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00781, loss=0.0163]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.01it/s, batch_loss=2.38, loss=1.46]\n",
      "EPOCH 78/100: Validation average loss: 1.4582300648607056 + AUC SCORE = 0.4027734976887519 + AUC SCORE THRESH 0.8571428571428571 = 0.5012326656394452\n",
      "100%|████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00947, loss=0.0157]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:06<00:00,  4.18it/s, batch_loss=2.54, loss=1.63]\n",
      "EPOCH 79/100: Validation average loss: 1.6341767067025448 + AUC SCORE = 0.410477657935285 + AUC SCORE THRESH 0.9795918367346939 = 0.5006163328197226\n",
      "100%|████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00716, loss=0.0147]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 29/29 [00:07<00:00,  4.05it/s, batch_loss=2.4, loss=1.47]\n",
      "EPOCH 80/100: Validation average loss: 1.4677860870443542 + AUC SCORE = 0.40431432973805853 + AUC SCORE THRESH 0.8571428571428571 = 0.5012326656394452\n",
      "100%|████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00925, loss=0.0142]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  3.99it/s, batch_loss=2.58, loss=1.67]\n",
      "EPOCH 81/100: Validation average loss: 1.6702893520223683 + AUC SCORE = 0.41540832049306625 + AUC SCORE THRESH 0.9795918367346939 = 0.5006163328197226\n",
      "100%|████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00665, loss=0.0134]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 29/29 [00:07<00:00,  4.07it/s, batch_loss=2.4, loss=1.46]\n",
      "EPOCH 82/100: Validation average loss: 1.4646819978952408 + AUC SCORE = 0.4064714946070878 + AUC SCORE THRESH 0.32653061224489793 = 0.5073959938366718\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00962, loss=0.013]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.05it/s, batch_loss=2.63, loss=1.72]\n",
      "EPOCH 83/100: Validation average loss: 1.7242855956328327 + AUC SCORE = 0.41602465331278893 + AUC SCORE THRESH 0.9795918367346939 = 0.5006163328197226\n",
      "100%|████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00649, loss=0.0122]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 29/29 [00:07<00:00,  4.00it/s, batch_loss=2.4, loss=1.45]\n",
      "EPOCH 84/100: Validation average loss: 1.446720988072198 + AUC SCORE = 0.40308166409861323 + AUC SCORE THRESH 0.3469387755102041 = 0.5158705701078583\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0118, loss=0.0121]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.11it/s, batch_loss=2.69, loss=1.81]\n",
      "EPOCH 85/100: Validation average loss: 1.8133393043074115 + AUC SCORE = 0.41848998459167946 + AUC SCORE THRESH 0.9795918367346939 = 0.5006163328197226\n",
      "100%|████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00775, loss=0.0114]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 29/29 [00:07<00:00,  4.13it/s, batch_loss=2.34, loss=1.4]\n",
      "EPOCH 86/100: Validation average loss: 1.3962167116074726 + AUC SCORE = 0.40832049306625573 + AUC SCORE THRESH 0.32653061224489793 = 0.5249614791987673\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0205, loss=0.0118]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.11it/s, batch_loss=2.62, loss=1.86]\n",
      "EPOCH 87/100: Validation average loss: 1.8591402503180092 + AUC SCORE = 0.4200308166409862 + AUC SCORE THRESH 0.9591836734693877 = 0.5006163328197226\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0232, loss=0.0134]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.02it/s, batch_loss=2.26, loss=1.36]\n",
      "EPOCH 88/100: Validation average loss: 1.358714613935043 + AUC SCORE = 0.40770416024653316 + AUC SCORE THRESH 0.4693877551020408 = 0.5249614791987673\n",
      "100%|██████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0931, loss=0.204]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 29/29 [00:07<00:00,  4.05it/s, batch_loss=1.6, loss=1.11]\n",
      "EPOCH 89/100: Validation average loss: 1.1059842602959995 + AUC SCORE = 0.37904468412942993 + AUC SCORE THRESH 0.02040816326530612 = 0.5078582434514638\n",
      "100%|████████| 103/103 [00:55<00:00,  1.84it/s, batch_loss=0.00706, loss=0.0649]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.07it/s, batch_loss=3.19, loss=1.77]\n",
      "EPOCH 90/100: Validation average loss: 1.7748181119818112 + AUC SCORE = 0.4388289676425269 + AUC SCORE THRESH 0.24489795918367346 = 0.5049306625577812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 103/103 [00:55<00:00,  1.84it/s, batch_loss=0.0143, loss=0.0281]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.08it/s, batch_loss=2.71, loss=1.43]\n",
      "EPOCH 91/100: Validation average loss: 1.434608327417538 + AUC SCORE = 0.39506933744221884 + AUC SCORE THRESH 0.6326530612244897 = 0.5043143297380585\n",
      "100%|████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00821, loss=0.0167]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  3.96it/s, batch_loss=3.36, loss=1.94]\n",
      "EPOCH 92/100: Validation average loss: 1.9363023109477142 + AUC SCORE = 0.4046224961479199 + AUC SCORE THRESH 0.9795918367346939 = 0.5006163328197226\n",
      "100%|█████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00684, loss=0.013]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:06<00:00,  4.16it/s, batch_loss=2.64, loss=1.43]\n",
      "EPOCH 93/100: Validation average loss: 1.4252057013840511 + AUC SCORE = 0.38120184899845916 + AUC SCORE THRESH 0.0 = 0.5\n",
      "100%|████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00546, loss=0.0114]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.03it/s, batch_loss=2.65, loss=1.43]\n",
      "EPOCH 94/100: Validation average loss: 1.4341034370249715 + AUC SCORE = 0.3855161787365177 + AUC SCORE THRESH 0.0 = 0.5\n",
      "100%|████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00526, loss=0.0106]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.03it/s, batch_loss=2.59, loss=1.41]\n",
      "EPOCH 95/100: Validation average loss: 1.4133914267194683 + AUC SCORE = 0.3870570107858244 + AUC SCORE THRESH 0.5510204081632653 = 0.5055469953775038\n",
      "100%|████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00506, loss=0.0101]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.08it/s, batch_loss=2.54, loss=1.39]\n",
      "EPOCH 96/100: Validation average loss: 1.394863478582481 + AUC SCORE = 0.3889060092449923 + AUC SCORE THRESH 0.5510204081632653 = 0.5061633281972265\n",
      "100%|███████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00486, loss=0.00968]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.10it/s, batch_loss=2.49, loss=1.38]\n",
      "EPOCH 97/100: Validation average loss: 1.3805144352131877 + AUC SCORE = 0.39044684129429896 + AUC SCORE THRESH 0.5714285714285714 = 0.514637904468413\n",
      "100%|███████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.00467, loss=0.00929]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.02it/s, batch_loss=2.47, loss=1.37]\n",
      "EPOCH 98/100: Validation average loss: 1.3715215027332306 + AUC SCORE = 0.3907550077041602 + AUC SCORE THRESH 0.5918367346938775 = 0.514637904468413\n",
      "100%|████████| 103/103 [00:55<00:00,  1.85it/s, batch_loss=0.0045, loss=0.00893]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 29/29 [00:07<00:00,  4.11it/s, batch_loss=2.44, loss=1.36]\n",
      "EPOCH 99/100: Validation average loss: 1.3648499281241977 + AUC SCORE = 0.3913713405238829 + AUC SCORE THRESH 0.5918367346938775 = 0.514637904468413\n",
      "0.5060092449922958\n"
     ]
    }
   ],
   "source": [
    "!python3 ../rsnaresnet10/working/custom_train.py --csv_file train.csv --type T1wCE --model_name resnet10_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_T1wCE\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 283/283 [00:36<00:00,  7.73it/s]\n",
      "Caulculating the best scans for every case...\n",
      "100%|███████████████████████████████████████████| 77/77 [00:09<00:00,  7.99it/s]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|█████████████| 70/70 [00:39<00:00,  1.79it/s, batch_loss=0.395, loss=0.651]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|█████████████| 20/20 [00:04<00:00,  4.05it/s, batch_loss=0.411, loss=0.617]\n",
      "EPOCH 0/100: Validation average loss: 0.6168386295437813 + AUC SCORE = 0.5915384615384616 + AUC SCORE THRESH 0.673469387755102 = 0.5684615384615385\n",
      "Saving the model...\n",
      "100%|█████████████| 70/70 [00:37<00:00,  1.87it/s, batch_loss=0.405, loss=0.638]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.98it/s, batch_loss=0.388, loss=0.623]\n",
      "EPOCH 1/100: Validation average loss: 0.6230489850044251 + AUC SCORE = 0.5638461538461539 + AUC SCORE THRESH 0.6530612244897959 = 0.575\n",
      "100%|█████████████| 70/70 [00:37<00:00,  1.85it/s, batch_loss=0.408, loss=0.627]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.92it/s, batch_loss=0.389, loss=0.631]\n",
      "EPOCH 2/100: Validation average loss: 0.6312400057911873 + AUC SCORE = 0.5484615384615383 + AUC SCORE THRESH 0.6530612244897959 = 0.5676923076923077\n",
      "100%|█████████████| 70/70 [00:37<00:00,  1.85it/s, batch_loss=0.415, loss=0.616]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|█████████████| 20/20 [00:04<00:00,  4.11it/s, batch_loss=0.414, loss=0.646]\n",
      "EPOCH 3/100: Validation average loss: 0.6455674067139625 + AUC SCORE = 0.5207692307692308 + AUC SCORE THRESH 0.6938775510204082 = 0.5561538461538461\n",
      "100%|██████████████| 70/70 [00:37<00:00,  1.85it/s, batch_loss=0.42, loss=0.603]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|█████████████| 20/20 [00:04<00:00,  4.00it/s, batch_loss=0.498, loss=0.684]\n",
      "EPOCH 4/100: Validation average loss: 0.6836688786745071 + AUC SCORE = 0.5023076923076923 + AUC SCORE THRESH 0.673469387755102 = 0.5465384615384615\n",
      "100%|██████████████| 70/70 [00:37<00:00,  1.85it/s, batch_loss=0.42, loss=0.591]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.91it/s, batch_loss=0.866, loss=0.838]\n",
      "EPOCH 5/100: Validation average loss: 0.8381471425294876 + AUC SCORE = 0.4915384615384616 + AUC SCORE THRESH 0.3469387755102041 = 0.5365384615384616\n",
      "100%|█████████████| 70/70 [00:37<00:00,  1.85it/s, batch_loss=0.413, loss=0.576]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|██████████████| 20/20 [00:05<00:00,  3.99it/s, batch_loss=1.05, loss=0.905]\n",
      "EPOCH 6/100: Validation average loss: 0.9045290172100067 + AUC SCORE = 0.5076923076923077 + AUC SCORE THRESH 0.2857142857142857 = 0.5653846153846154\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.409, loss=0.557]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  3.93it/s, batch_loss=1.01, loss=0.87]\n",
      "EPOCH 7/100: Validation average loss: 0.8702648311853409 + AUC SCORE = 0.5269230769230769 + AUC SCORE THRESH 0.2857142857142857 = 0.5846153846153846\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.394, loss=0.537]\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  4.00it/s, batch_loss=0.878, loss=0.801]\n",
      "EPOCH 8/100: Validation average loss: 0.8007502913475036 + AUC SCORE = 0.543076923076923 + AUC SCORE THRESH 0.36734693877551017 = 0.595\n",
      "100%|██████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.39, loss=0.517]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  3.88it/s, batch_loss=1.42, loss=1.06]\n",
      "EPOCH 9/100: Validation average loss: 1.061313261091709 + AUC SCORE = 0.5515384615384615 + AUC SCORE THRESH 0.16326530612244897 = 0.5934615384615385\n",
      "100%|█████████████| 70/70 [00:37<00:00,  1.84it/s, batch_loss=0.409, loss=0.481]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:04<00:00,  4.10it/s, batch_loss=1.19, loss=1.08]\n",
      "EPOCH 10/100: Validation average loss: 1.0826608002185822 + AUC SCORE = 0.5423076923076923 + AUC SCORE THRESH 0.24489795918367346 = 0.5676923076923077\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.397, loss=0.456]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  4.00it/s, batch_loss=1.65, loss=1.33]\n",
      "EPOCH 11/100: Validation average loss: 1.3315190136432649 + AUC SCORE = 0.5538461538461539 + AUC SCORE THRESH 0.14285714285714285 = 0.5861538461538461\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.389, loss=0.435]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:04<00:00,  4.02it/s, batch_loss=1.79, loss=1.42]\n",
      "EPOCH 12/100: Validation average loss: 1.4182365268468857 + AUC SCORE = 0.5623076923076923 + AUC SCORE THRESH 0.12244897959183673 = 0.6053846153846154\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.381, loss=0.415]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:04<00:00,  4.07it/s, batch_loss=1.84, loss=1.45]\n",
      "EPOCH 13/100: Validation average loss: 1.4521914944052696 + AUC SCORE = 0.5661538461538462 + AUC SCORE THRESH 0.12244897959183673 = 0.5957692307692308\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.374, loss=0.395]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 20/20 [00:05<00:00,  3.97it/s, batch_loss=1.8, loss=1.44]\n",
      "EPOCH 14/100: Validation average loss: 1.4382255762815475 + AUC SCORE = 0.573076923076923 + AUC SCORE THRESH 0.12244897959183673 = 0.6053846153846154\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.367, loss=0.375]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 20/20 [00:05<00:00,  3.95it/s, batch_loss=1.72, loss=1.4]\n",
      "EPOCH 15/100: Validation average loss: 1.401352021098137 + AUC SCORE = 0.5753846153846154 + AUC SCORE THRESH 0.12244897959183673 = 0.595\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.358, loss=0.356]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:04<00:00,  4.07it/s, batch_loss=1.73, loss=1.39]\n",
      "EPOCH 16/100: Validation average loss: 1.3880717754364014 + AUC SCORE = 0.5784615384615386 + AUC SCORE THRESH 0.2857142857142857 = 0.5946153846153845\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.348, loss=0.338]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:04<00:00,  4.22it/s, batch_loss=1.71, loss=1.35]\n",
      "EPOCH 17/100: Validation average loss: 1.348061177134514 + AUC SCORE = 0.5807692307692309 + AUC SCORE THRESH 0.16326530612244897 = 0.5869230769230769\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.339, loss=0.321]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  3.95it/s, batch_loss=1.76, loss=1.34]\n",
      "EPOCH 18/100: Validation average loss: 1.340910303592682 + AUC SCORE = 0.5800000000000001 + AUC SCORE THRESH 0.16326530612244897 = 0.5965384615384616\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.331, loss=0.306]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  3.94it/s, batch_loss=1.87, loss=1.37]\n",
      "EPOCH 19/100: Validation average loss: 1.3667510434985162 + AUC SCORE = 0.5776923076923077 + AUC SCORE THRESH 0.16326530612244897 = 0.5965384615384616\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.323, loss=0.293]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  3.88it/s, batch_loss=2.01, loss=1.41]\n",
      "EPOCH 20/100: Validation average loss: 1.4098449885845183 + AUC SCORE = 0.576923076923077 + AUC SCORE THRESH 0.16326530612244897 = 0.6069230769230769\n",
      "100%|███████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.32, loss=0.28]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  3.93it/s, batch_loss=2.18, loss=1.48]\n",
      "EPOCH 21/100: Validation average loss: 1.4750233590602875 + AUC SCORE = 0.5700000000000001 + AUC SCORE THRESH 0.14285714285714285 = 0.6157692307692308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.311, loss=0.27]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 20/20 [00:05<00:00,  3.93it/s, batch_loss=2.4, loss=1.56]\n",
      "EPOCH 22/100: Validation average loss: 1.5563359260559082 + AUC SCORE = 0.5738461538461539 + AUC SCORE THRESH 0.12244897959183673 = 0.6157692307692308\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.324, loss=0.259]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  3.89it/s, batch_loss=2.54, loss=1.63]\n",
      "EPOCH 23/100: Validation average loss: 1.630346167087555 + AUC SCORE = 0.5661538461538462 + AUC SCORE THRESH 0.1020408163265306 = 0.5757692307692308\n",
      "100%|███████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.3, loss=0.252]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  3.95it/s, batch_loss=2.83, loss=1.76]\n",
      "EPOCH 24/100: Validation average loss: 1.7571789294481277 + AUC SCORE = 0.5769230769230769 + AUC SCORE THRESH 0.16326530612244897 = 0.5915384615384616\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.458, loss=0.245]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  3.98it/s, batch_loss=2.43, loss=1.69]\n",
      "EPOCH 25/100: Validation average loss: 1.6866945266723632 + AUC SCORE = 0.5507692307692308 + AUC SCORE THRESH 0.12244897959183673 = 0.5684615384615385\n",
      "100%|███████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.3, loss=0.248]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 20/20 [00:05<00:00,  3.92it/s, batch_loss=2.91, loss=1.8]\n",
      "EPOCH 26/100: Validation average loss: 1.8031065821647645 + AUC SCORE = 0.5815384615384616 + AUC SCORE THRESH 0.08163265306122448 = 0.6165384615384616\n",
      "100%|██████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.455, loss=0.24]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:04<00:00,  4.03it/s, batch_loss=2.61, loss=1.95]\n",
      "EPOCH 27/100: Validation average loss: 1.9508771508932115 + AUC SCORE = 0.5384615384615385 + AUC SCORE THRESH 0.12244897959183673 = 0.5611538461538461\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.258, loss=0.226]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  3.94it/s, batch_loss=2.37, loss=1.69]\n",
      "EPOCH 28/100: Validation average loss: 1.6937730759382248 + AUC SCORE = 0.5715384615384616 + AUC SCORE THRESH 0.16326530612244897 = 0.5915384615384616\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.268, loss=0.213]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  3.95it/s, batch_loss=2.42, loss=1.84]\n",
      "EPOCH 29/100: Validation average loss: 1.8437646865844726 + AUC SCORE = 0.5492307692307692 + AUC SCORE THRESH 0.08163265306122448 = 0.5869230769230769\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.242, loss=0.205]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 20/20 [00:05<00:00,  3.95it/s, batch_loss=2.4, loss=1.81]\n",
      "EPOCH 30/100: Validation average loss: 1.8142082124948502 + AUC SCORE = 0.5538461538461539 + AUC SCORE THRESH 0.1020408163265306 = 0.5892307692307692\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.237, loss=0.198]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:04<00:00,  4.07it/s, batch_loss=2.12, loss=1.74]\n",
      "EPOCH 31/100: Validation average loss: 1.7395549356937408 + AUC SCORE = 0.5330769230769231 + AUC SCORE THRESH 0.12244897959183673 = 0.57\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.232, loss=0.193]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  3.85it/s, batch_loss=1.73, loss=1.52]\n",
      "EPOCH 32/100: Validation average loss: 1.5150044918060304 + AUC SCORE = 0.5392307692307693 + AUC SCORE THRESH 0.16326530612244897 = 0.5588461538461539\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.223, loss=0.188]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  3.97it/s, batch_loss=1.31, loss=1.35]\n",
      "EPOCH 33/100: Validation average loss: 1.3450738489627838 + AUC SCORE = 0.5123076923076924 + AUC SCORE THRESH 0.32653061224489793 = 0.5330769230769231\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.227, loss=0.186]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|██████████████| 20/20 [00:05<00:00,  3.79it/s, batch_loss=0.862, loss=1.06]\n",
      "EPOCH 34/100: Validation average loss: 1.0636481940746307 + AUC SCORE = 0.5015384615384616 + AUC SCORE THRESH 0.5714285714285714 = 0.5561538461538461\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.228, loss=0.183]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:04<00:00,  4.02it/s, batch_loss=0.397, loss=0.914]\n",
      "EPOCH 35/100: Validation average loss: 0.9144785344600678 + AUC SCORE = 0.4707692307692307 + AUC SCORE THRESH 0.22448979591836732 = 0.5326923076923077\n",
      "100%|██████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.26, loss=0.186]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:04<00:00,  4.03it/s, batch_loss=0.329, loss=0.821]\n",
      "EPOCH 36/100: Validation average loss: 0.8205014437437057 + AUC SCORE = 0.47307692307692306 + AUC SCORE THRESH 0.7959183673469387 = 0.5642307692307692\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.267, loss=0.187]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.94it/s, batch_loss=0.113, loss=0.888]\n",
      "EPOCH 37/100: Validation average loss: 0.8877698093652725 + AUC SCORE = 0.4484615384615384 + AUC SCORE THRESH 0.16326530612244897 = 0.5303846153846153\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.312, loss=0.188]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.85it/s, batch_loss=0.143, loss=0.796]\n",
      "EPOCH 38/100: Validation average loss: 0.7955231837928295 + AUC SCORE = 0.47615384615384615 + AUC SCORE THRESH 0.44897959183673464 = 0.5711538461538461\n",
      "100%|██████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.22, loss=0.181]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.87it/s, batch_loss=0.109, loss=0.862]\n",
      "EPOCH 39/100: Validation average loss: 0.8616125147789717 + AUC SCORE = 0.4392307692307692 + AUC SCORE THRESH 0.3469387755102041 = 0.5503846153846154\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.202, loss=0.173]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████| 20/20 [00:05<00:00,  3.81it/s, batch_loss=0.0546, loss=0.917]\n",
      "EPOCH 40/100: Validation average loss: 0.9166037634015083 + AUC SCORE = 0.44076923076923075 + AUC SCORE THRESH 0.5102040816326531 = 0.5711538461538461\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.194, loss=0.166]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████| 20/20 [00:05<00:00,  3.93it/s, batch_loss=0.0849, loss=0.894]\n",
      "EPOCH 41/100: Validation average loss: 0.8941037472337484 + AUC SCORE = 0.4276923076923077 + AUC SCORE THRESH 0.4693877551020408 = 0.551923076923077\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.195, loss=0.162]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████| 20/20 [00:05<00:00,  4.00it/s, batch_loss=0.0709, loss=0.896]\n",
      "EPOCH 42/100: Validation average loss: 0.8957297820597887 + AUC SCORE = 0.43153846153846154 + AUC SCORE THRESH 0.42857142857142855 = 0.5615384615384615\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.191, loss=0.157]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████| 20/20 [00:05<00:00,  3.99it/s, batch_loss=0.0539, loss=0.948]\n",
      "EPOCH 43/100: Validation average loss: 0.948247161693871 + AUC SCORE = 0.413076923076923 + AUC SCORE THRESH 0.4897959183673469 = 0.5615384615384615\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.213, loss=0.157]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████| 20/20 [00:05<00:00,  3.86it/s, batch_loss=0.0638, loss=0.899]\n",
      "EPOCH 44/100: Validation average loss: 0.8988425724208355 + AUC SCORE = 0.43384615384615377 + AUC SCORE THRESH 0.4081632653061224 = 0.5615384615384615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.193, loss=0.152]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████| 20/20 [00:05<00:00,  3.63it/s, batch_loss=0.0472, loss=0.978]\n",
      "EPOCH 45/100: Validation average loss: 0.9779336847364902 + AUC SCORE = 0.41384615384615386 + AUC SCORE THRESH 0.36734693877551017 = 0.5503846153846154\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.279, loss=0.158]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████| 20/20 [00:05<00:00,  3.94it/s, batch_loss=0.0616, loss=0.873]\n",
      "EPOCH 46/100: Validation average loss: 0.8732766542583704 + AUC SCORE = 0.4692307692307692 + AUC SCORE THRESH 0.4081632653061224 = 0.551923076923077\n",
      "100%|██████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.177, loss=0.15]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.97it/s, batch_loss=0.0463, loss=0.98]\n",
      "EPOCH 47/100: Validation average loss: 0.9801586830988527 + AUC SCORE = 0.42692307692307696 + AUC SCORE THRESH 0.5510204081632653 = 0.5415384615384616\n",
      "100%|██████████████| 70/70 [00:38<00:00,  1.82it/s, batch_loss=0.234, loss=0.15]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.91it/s, batch_loss=0.0451, loss=0.91]\n",
      "EPOCH 48/100: Validation average loss: 0.9103322958573699 + AUC SCORE = 0.46769230769230763 + AUC SCORE THRESH 0.8163265306122448 = 0.5349999999999999\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.178, loss=0.139]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.95it/s, batch_loss=0.0377, loss=1.01]\n",
      "EPOCH 49/100: Validation average loss: 1.013985908217728 + AUC SCORE = 0.4307692307692308 + AUC SCORE THRESH 0.7551020408163265 = 0.5423076923076923\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.165, loss=0.139]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.78it/s, batch_loss=0.034, loss=0.995]\n",
      "EPOCH 50/100: Validation average loss: 0.9947552561759949 + AUC SCORE = 0.44999999999999996 + AUC SCORE THRESH 0.836734693877551 = 0.5542307692307692\n",
      "100%|██████████████| 70/70 [00:38<00:00,  1.82it/s, batch_loss=0.182, loss=0.13]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.95it/s, batch_loss=0.0346, loss=1.04]\n",
      "EPOCH 51/100: Validation average loss: 1.0437257319688797 + AUC SCORE = 0.42846153846153845 + AUC SCORE THRESH 0.6326530612244897 = 0.5415384615384616\n",
      "100%|██████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.157, loss=0.13]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████| 20/20 [00:05<00:00,  3.94it/s, batch_loss=0.0464, loss=0.965]\n",
      "EPOCH 52/100: Validation average loss: 0.9654412727802992 + AUC SCORE = 0.4461538461538461 + AUC SCORE THRESH 0.6326530612244897 = 0.5423076923076923\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.172, loss=0.122]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.85it/s, batch_loss=0.0337, loss=1.05]\n",
      "EPOCH 53/100: Validation average loss: 1.0465175814926624 + AUC SCORE = 0.423076923076923 + AUC SCORE THRESH 0.5918367346938775 = 0.5511538461538462\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.145, loss=0.122]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████████| 20/20 [00:05<00:00,  3.92it/s, batch_loss=0.0377, loss=1]\n",
      "EPOCH 54/100: Validation average loss: 1.0012241069227457 + AUC SCORE = 0.4361538461538461 + AUC SCORE THRESH 0.6326530612244897 = 0.5423076923076923\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.84it/s, batch_loss=0.167, loss=0.116]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.84it/s, batch_loss=0.0308, loss=1.07]\n",
      "EPOCH 55/100: Validation average loss: 1.0665853695943952 + AUC SCORE = 0.4161538461538462 + AUC SCORE THRESH 0.5102040816326531 = 0.5503846153846154\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.82it/s, batch_loss=0.146, loss=0.116]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████| 20/20 [00:05<00:00,  3.95it/s, batch_loss=0.0501, loss=0.963]\n",
      "EPOCH 56/100: Validation average loss: 0.9626434557139874 + AUC SCORE = 0.4376923076923077 + AUC SCORE THRESH 0.5714285714285714 = 0.5423076923076923\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.82it/s, batch_loss=0.164, loss=0.111]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.90it/s, batch_loss=0.0297, loss=1.08]\n",
      "EPOCH 57/100: Validation average loss: 1.075018984824419 + AUC SCORE = 0.4076923076923077 + AUC SCORE THRESH 0.4693877551020408 = 0.5503846153846154\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.137, loss=0.112]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████| 20/20 [00:04<00:00,  4.07it/s, batch_loss=0.0418, loss=0.991]\n",
      "EPOCH 58/100: Validation average loss: 0.9913905445486307 + AUC SCORE = 0.4361538461538461 + AUC SCORE THRESH 0.5918367346938775 = 0.5423076923076923\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.167, loss=0.107]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.91it/s, batch_loss=0.0319, loss=1.08]\n",
      "EPOCH 59/100: Validation average loss: 1.0842813346534967 + AUC SCORE = 0.4076923076923077 + AUC SCORE THRESH 0.6122448979591836 = 0.5415384615384616\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.159, loss=0.108]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████| 20/20 [00:05<00:00,  3.97it/s, batch_loss=0.0696, loss=0.929]\n",
      "EPOCH 60/100: Validation average loss: 0.9285508062690496 + AUC SCORE = 0.4523076923076923 + AUC SCORE THRESH 0.7755102040816326 = 0.5261538461538462\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.178, loss=0.104]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.88it/s, batch_loss=0.0321, loss=1.09]\n",
      "EPOCH 61/100: Validation average loss: 1.090233325213194 + AUC SCORE = 0.4138461538461538 + AUC SCORE THRESH 0.6530612244897959 = 0.5319230769230769\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.127, loss=0.104]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████| 20/20 [00:05<00:00,  3.95it/s, batch_loss=0.0504, loss=0.992]\n",
      "EPOCH 62/100: Validation average loss: 0.9923658095300197 + AUC SCORE = 0.44153846153846155 + AUC SCORE THRESH 0.5510204081632653 = 0.5319230769230769\n",
      "100%|████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.134, loss=0.0972]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:04<00:00,  4.01it/s, batch_loss=0.0633, loss=1.01]\n",
      "EPOCH 63/100: Validation average loss: 1.0055049363523723 + AUC SCORE = 0.4307692307692308 + AUC SCORE THRESH 0.7959183673469387 = 0.5246153846153847\n",
      "100%|████████████| 70/70 [00:38<00:00,  1.82it/s, batch_loss=0.142, loss=0.0959]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.94it/s, batch_loss=0.113, loss=0.896]\n",
      "EPOCH 64/100: Validation average loss: 0.8963178679347038 + AUC SCORE = 0.44461538461538463 + AUC SCORE THRESH 0.6530612244897959 = 0.5438461538461539\n",
      "100%|█████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.145, loss=0.094]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.99it/s, batch_loss=0.0326, loss=1.11]\n",
      "EPOCH 65/100: Validation average loss: 1.10821206625551 + AUC SCORE = 0.4176923076923077 + AUC SCORE THRESH 0.44897959183673464 = 0.5303846153846153\n",
      "100%|████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.143, loss=0.0941]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:04<00:00,  4.00it/s, batch_loss=0.0318, loss=1.13]\n",
      "EPOCH 66/100: Validation average loss: 1.1329295901581644 + AUC SCORE = 0.42846153846153845 + AUC SCORE THRESH 0.3061224489795918 = 0.5303846153846153\n",
      "100%|████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.107, loss=0.0877]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|██████████████| 20/20 [00:05<00:00,  3.97it/s, batch_loss=0.165, loss=0.94]\n",
      "EPOCH 67/100: Validation average loss: 0.9397876717150211 + AUC SCORE = 0.43153846153846154 + AUC SCORE THRESH 0.7346938775510203 = 0.5261538461538462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.245, loss=0.0936]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.93it/s, batch_loss=0.409, loss=0.833]\n",
      "EPOCH 68/100: Validation average loss: 0.833241181075573 + AUC SCORE = 0.46692307692307694 + AUC SCORE THRESH 0.4081632653061224 = 0.5542307692307692\n",
      "100%|████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.241, loss=0.0981]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.99it/s, batch_loss=0.0203, loss=1.23]\n",
      "EPOCH 69/100: Validation average loss: 1.2344615891575814 + AUC SCORE = 0.403076923076923 + AUC SCORE THRESH 0.36734693877551017 = 0.5303846153846153\n",
      "100%|████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.121, loss=0.0961]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|██████████████| 20/20 [00:05<00:00,  4.00it/s, batch_loss=0.092, loss=1.01]\n",
      "EPOCH 70/100: Validation average loss: 1.0111267019063235 + AUC SCORE = 0.4307692307692307 + AUC SCORE THRESH 0.7959183673469387 = 0.5261538461538462\n",
      "100%|████████████| 70/70 [00:38<00:00,  1.82it/s, batch_loss=0.179, loss=0.0896]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:04<00:00,  4.00it/s, batch_loss=0.469, loss=0.828]\n",
      "EPOCH 71/100: Validation average loss: 0.8283093303442002 + AUC SCORE = 0.44999999999999996 + AUC SCORE THRESH 0.2857142857142857 = 0.5423076923076923\n",
      "100%|████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.137, loss=0.0838]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:04<00:00,  4.05it/s, batch_loss=0.123, loss=0.898]\n",
      "EPOCH 72/100: Validation average loss: 0.8975408777594567 + AUC SCORE = 0.4376923076923076 + AUC SCORE THRESH 0.7755102040816326 = 0.5357692307692308\n",
      "100%|████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.113, loss=0.0766]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.87it/s, batch_loss=0.074, loss=0.995]\n",
      "EPOCH 73/100: Validation average loss: 0.9949824865907431 + AUC SCORE = 0.42999999999999994 + AUC SCORE THRESH 0.8571428571428571 = 0.5269230769230769\n",
      "100%|████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.123, loss=0.0729]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.94it/s, batch_loss=0.0672, loss=1.02]\n",
      "EPOCH 74/100: Validation average loss: 1.0222501687705516 + AUC SCORE = 0.4261538461538461 + AUC SCORE THRESH 0.8571428571428571 = 0.5269230769230769\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0883, loss=0.0686]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.86it/s, batch_loss=0.106, loss=0.953]\n",
      "EPOCH 75/100: Validation average loss: 0.9533428560942412 + AUC SCORE = 0.43 + AUC SCORE THRESH 0.26530612244897955 = 0.5311538461538461\n",
      "100%|████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.103, loss=0.0664]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.95it/s, batch_loss=0.161, loss=0.886]\n",
      "EPOCH 76/100: Validation average loss: 0.8864471308887005 + AUC SCORE = 0.44153846153846155 + AUC SCORE THRESH 0.4897959183673469 = 0.5230769230769231\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0881, loss=0.0647]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.83it/s, batch_loss=0.163, loss=0.894]\n",
      "EPOCH 77/100: Validation average loss: 0.8937445275485516 + AUC SCORE = 0.4423076923076923 + AUC SCORE THRESH 0.42857142857142855 = 0.5119230769230769\n",
      "100%|████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0814, loss=0.062]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.93it/s, batch_loss=0.153, loss=0.906]\n",
      "EPOCH 78/100: Validation average loss: 0.9063879817724227 + AUC SCORE = 0.43153846153846154 + AUC SCORE THRESH 0.7551020408163265 = 0.5165384615384616\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0887, loss=0.0599]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|████████████| 20/20 [00:05<00:00,  3.86it/s, batch_loss=0.0973, loss=0.982]\n",
      "EPOCH 79/100: Validation average loss: 0.9824392784386873 + AUC SCORE = 0.42000000000000004 + AUC SCORE THRESH 0.5510204081632653 = 0.5223076923076923\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0811, loss=0.0582]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|███████████████| 20/20 [00:05<00:00,  3.80it/s, batch_loss=0.216, loss=0.9]\n",
      "EPOCH 80/100: Validation average loss: 0.9004965782165527 + AUC SCORE = 0.43538461538461537 + AUC SCORE THRESH 0.4081632653061224 = 0.5230769230769231\n",
      "100%|████████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0751, loss=0.056]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|██████████████| 20/20 [00:05<00:00,  3.63it/s, batch_loss=0.156, loss=0.91]\n",
      "EPOCH 81/100: Validation average loss: 0.9099252477288247 + AUC SCORE = 0.42846153846153834 + AUC SCORE THRESH 0.5306122448979591 = 0.5230769230769231\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.82it/s, batch_loss=0.0722, loss=0.0544]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.93it/s, batch_loss=0.192, loss=0.893]\n",
      "EPOCH 82/100: Validation average loss: 0.8930638149380684 + AUC SCORE = 0.4346153846153846 + AUC SCORE THRESH 0.4081632653061224 = 0.5126923076923077\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0855, loss=0.0529]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.82it/s, batch_loss=0.112, loss=0.966]\n",
      "EPOCH 83/100: Validation average loss: 0.9655705325305461 + AUC SCORE = 0.4238461538461539 + AUC SCORE THRESH 0.3877551020408163 = 0.5215384615384616\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0739, loss=0.0522]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.79it/s, batch_loss=0.237, loss=0.909]\n",
      "EPOCH 84/100: Validation average loss: 0.9088605262339116 + AUC SCORE = 0.4346153846153846 + AUC SCORE THRESH 0.4081632653061224 = 0.5134615384615384\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0723, loss=0.0501]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.82it/s, batch_loss=0.158, loss=0.929]\n",
      "EPOCH 85/100: Validation average loss: 0.9289220631122589 + AUC SCORE = 0.4176923076923077 + AUC SCORE THRESH 0.2857142857142857 = 0.5311538461538461\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0798, loss=0.0496]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.85it/s, batch_loss=0.288, loss=0.883]\n",
      "EPOCH 86/100: Validation average loss: 0.8830250911414623 + AUC SCORE = 0.43846153846153846 + AUC SCORE THRESH 0.32653061224489793 = 0.5223076923076923\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0863, loss=0.0478]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:04<00:00,  4.05it/s, batch_loss=0.154, loss=0.918]\n",
      "EPOCH 87/100: Validation average loss: 0.9183679819107056 + AUC SCORE = 0.4207692307692308 + AUC SCORE THRESH 0.4897959183673469 = 0.5223076923076923\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0661, loss=0.0478]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|██████████████| 20/20 [00:05<00:00,  3.90it/s, batch_loss=0.206, loss=0.91]\n",
      "EPOCH 88/100: Validation average loss: 0.9102939397096634 + AUC SCORE = 0.4338461538461539 + AUC SCORE THRESH 0.2040816326530612 = 0.5311538461538461\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.82it/s, batch_loss=0.0672, loss=0.0443]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.97it/s, batch_loss=0.208, loss=0.902]\n",
      "EPOCH 89/100: Validation average loss: 0.9018497437238693 + AUC SCORE = 0.4292307692307693 + AUC SCORE THRESH 0.44897959183673464 = 0.5134615384615384\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.82it/s, batch_loss=0.0609, loss=0.0431]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.98it/s, batch_loss=0.186, loss=0.912]\n",
      "EPOCH 90/100: Validation average loss: 0.9116801381111145 + AUC SCORE = 0.42538461538461536 + AUC SCORE THRESH 0.3877551020408163 = 0.5223076923076923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0638, loss=0.0409]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.93it/s, batch_loss=0.159, loss=0.933]\n",
      "EPOCH 91/100: Validation average loss: 0.9325252287089825 + AUC SCORE = 0.42000000000000004 + AUC SCORE THRESH 0.4897959183673469 = 0.5134615384615384\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0528, loss=0.0397]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.89it/s, batch_loss=0.142, loss=0.953]\n",
      "EPOCH 92/100: Validation average loss: 0.9533443652093411 + AUC SCORE = 0.42846153846153845 + AUC SCORE THRESH 0.5714285714285714 = 0.5230769230769231\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0544, loss=0.0382]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.91it/s, batch_loss=0.267, loss=0.914]\n",
      "EPOCH 93/100: Validation average loss: 0.9136553540825844 + AUC SCORE = 0.42615384615384616 + AUC SCORE THRESH 0.32653061224489793 = 0.5126923076923077\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0501, loss=0.0372]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:04<00:00,  4.03it/s, batch_loss=0.149, loss=0.942]\n",
      "EPOCH 94/100: Validation average loss: 0.942014779895544 + AUC SCORE = 0.4176923076923077 + AUC SCORE THRESH 0.4693877551020408 = 0.5223076923076923\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0512, loss=0.0355]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.93it/s, batch_loss=0.212, loss=0.932]\n",
      "EPOCH 95/100: Validation average loss: 0.9319903440773487 + AUC SCORE = 0.4230769230769231 + AUC SCORE THRESH 0.36734693877551017 = 0.5126923076923077\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.82it/s, batch_loss=0.0482, loss=0.0339]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:04<00:00,  4.05it/s, batch_loss=0.168, loss=0.956]\n",
      "EPOCH 96/100: Validation average loss: 0.9559621982276439 + AUC SCORE = 0.4246153846153846 + AUC SCORE THRESH 0.18367346938775508 = 0.5207692307692308\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0509, loss=0.0328]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.97it/s, batch_loss=0.275, loss=0.924]\n",
      "EPOCH 97/100: Validation average loss: 0.9242663875222206 + AUC SCORE = 0.42615384615384616 + AUC SCORE THRESH 0.36734693877551017 = 0.5134615384615384\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0473, loss=0.0321]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.89it/s, batch_loss=0.167, loss=0.948]\n",
      "EPOCH 98/100: Validation average loss: 0.9481742449104786 + AUC SCORE = 0.4146153846153846 + AUC SCORE THRESH 0.4897959183673469 = 0.5230769230769231\n",
      "100%|███████████| 70/70 [00:38<00:00,  1.83it/s, batch_loss=0.0441, loss=0.0308]\n",
      "Adjusting learning rate of group 0 to 5.0000e-06.\n",
      "100%|█████████████| 20/20 [00:05<00:00,  3.94it/s, batch_loss=0.246, loss=0.936]\n",
      "EPOCH 99/100: Validation average loss: 0.9358913153409958 + AUC SCORE = 0.4292307692307693 + AUC SCORE THRESH 0.3877551020408163 = 0.5134615384615384\n",
      "0.5915384615384616\n"
     ]
    }
   ],
   "source": [
    "!python3 ../rsnaresnet10/working/custom_train.py --csv_file train_f.csv --type T1wCE --model_name resnet10_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caulculating the best scans for every case...\n",
      "100%|███████████████████████████████████████████| 58/58 [00:06<00:00,  9.02it/s]\n",
      "the final socre of the type T1wCE\n",
      "0.39761904761904765\n",
      "\n",
      "\n",
      "\n",
      "Prediction AUC: 0.3976\n",
      "Prediction Accuracy: 0.5000\n",
      "Prediction Specificity: 0.9333\n",
      "Prediction Sensitivity: 0.0357\n",
      "Prediction Precision: 0.3333\n",
      "        model       AUC  acc      spec      sens      prec\n",
      "0  resnet10_m  0.397619  0.5  0.933333  0.035714  0.333333\n"
     ]
    }
   ],
   "source": [
    "!python3 ../rsnaresnet10/working/custom_test.py --csv_file train.csv --type T1wCE --model_name resnet10_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caulculating the best scans for every case...\n",
      "100%|███████████████████████████████████████████| 58/58 [00:06<00:00,  9.58it/s]\n",
      "the final socre of the type T1wCE\n",
      "0.525\n",
      "\n",
      "\n",
      "\n",
      "Prediction AUC: 0.5250\n",
      "Prediction Accuracy: 0.4828\n",
      "Prediction Specificity: 0.0000\n",
      "Prediction Sensitivity: 1.0000\n",
      "Prediction Precision: 0.4828\n",
      "        model    AUC       acc  spec  sens      prec\n",
      "0  resnet10_f  0.525  0.482759   0.0   1.0  0.482759\n"
     ]
    }
   ],
   "source": [
    "!python3 ../rsnaresnet10/working/custom_test.py --csv_file train.csv --type T1wCE --model_name resnet10_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros:\n",
      "00009 2\n",
      "00017 2\n",
      "00018 0\n",
      "00019 0\n",
      "00021 0\n",
      "00022 0\n",
      "00024 2\n",
      "00030 0\n",
      "00032 2\n",
      "00036 0\n",
      "00044 2\n",
      "00045 2\n",
      "00049 2\n",
      "00053 0\n",
      "00061 2\n",
      "00064 0\n",
      "00072 0\n",
      "00081 2\n",
      "00084 2\n",
      "00088 0\n",
      "00090 0\n",
      "00095 0\n",
      "00097 0\n",
      "00099 0\n",
      "00102 2\n",
      "00104 2\n",
      "00110 2\n",
      "00111 2\n",
      "00112 2\n",
      "00113 2\n",
      "00116 0\n",
      "00121 0\n",
      "00122 0\n",
      "00123 2\n",
      "00124 0\n",
      "00130 0\n",
      "00133 0\n",
      "00142 0\n",
      "00149 2\n",
      "00150 0\n",
      "00151 2\n",
      "00154 0\n",
      "00157 0\n",
      "00158 0\n",
      "00162 2\n",
      "00165 0\n",
      "00167 0\n",
      "00169 0\n",
      "00170 2\n",
      "00172 0\n",
      "00176 0\n",
      "00183 0\n",
      "00184 0\n",
      "00191 0\n",
      "00192 2\n",
      "00193 2\n",
      "00194 2\n",
      "00195 0\n",
      "00201 0\n",
      "00206 0\n",
      "00209 0\n",
      "00211 0\n",
      "00214 0\n",
      "00216 0\n",
      "00217 2\n",
      "00218 2\n",
      "00219 2\n",
      "00221 0\n",
      "00227 2\n",
      "00228 2\n",
      "00231 0\n",
      "00236 2\n",
      "00237 0\n",
      "00238 0\n",
      "00239 0\n",
      "00241 2\n",
      "00242 0\n",
      "00243 2\n",
      "00247 0\n",
      "00249 0\n",
      "00251 2\n",
      "00258 2\n",
      "00259 0\n",
      "00261 2\n",
      "00262 2\n",
      "00266 0\n",
      "00267 0\n",
      "00269 2\n",
      "00274 2\n",
      "00275 2\n",
      "00280 2\n",
      "00283 0\n",
      "00286 2\n",
      "00288 2\n",
      "00289 0\n",
      "00290 0\n",
      "00297 0\n",
      "00298 2\n",
      "00300 0\n",
      "00301 0\n",
      "00308 2\n",
      "00309 0\n",
      "00310 0\n",
      "00312 0\n",
      "00314 2\n",
      "00316 0\n",
      "00318 2\n",
      "00320 0\n",
      "00324 0\n",
      "00325 0\n",
      "00327 0\n",
      "00336 0\n",
      "00339 2\n",
      "00341 2\n",
      "00343 2\n",
      "00346 2\n",
      "00347 0\n",
      "00348 2\n",
      "00349 2\n",
      "00351 0\n",
      "00353 2\n",
      "00356 0\n",
      "00373 0\n",
      "00376 2\n",
      "00377 2\n",
      "00378 2\n",
      "00379 2\n",
      "00380 2\n",
      "00382 0\n",
      "00387 2\n",
      "00388 0\n",
      "00389 2\n",
      "00390 2\n",
      "00391 0\n",
      "00392 0\n",
      "00395 0\n",
      "00397 2\n",
      "00399 2\n",
      "00401 0\n",
      "00402 2\n",
      "00405 2\n",
      "00407 2\n",
      "00410 2\n",
      "00412 2\n",
      "00414 2\n",
      "00417 0\n",
      "00418 2\n",
      "00419 2\n",
      "00421 0\n",
      "00423 2\n",
      "00430 0\n",
      "00432 2\n",
      "00433 0\n",
      "00441 2\n",
      "00444 2\n",
      "00445 0\n",
      "00446 2\n",
      "00452 0\n",
      "00454 2\n",
      "00455 0\n",
      "00459 2\n",
      "00464 2\n",
      "00469 2\n",
      "00477 0\n",
      "00481 0\n",
      "00495 0\n",
      "00496 2\n",
      "00498 0\n",
      "00507 2\n",
      "00510 2\n",
      "00512 0\n",
      "00514 2\n",
      "00518 2\n",
      "00519 2\n",
      "00530 2\n",
      "00533 2\n",
      "00538 2\n",
      "00540 2\n",
      "00545 2\n",
      "00547 2\n",
      "00555 2\n",
      "00563 0\n",
      "00565 2\n",
      "00567 2\n",
      "00568 0\n",
      "00569 0\n",
      "00571 2\n",
      "00572 2\n",
      "00574 2\n",
      "00575 2\n",
      "00578 2\n",
      "00581 2\n",
      "00587 0\n",
      "00588 0\n",
      "00589 0\n",
      "00591 0\n",
      "00596 0\n",
      "00601 0\n",
      "00605 0\n",
      "00616 0\n",
      "00619 2\n",
      "00620 2\n",
      "00623 2\n",
      "00624 2\n",
      "00630 2\n",
      "00636 2\n",
      "00641 0\n",
      "00642 2\n",
      "00645 2\n",
      "00649 2\n",
      "00651 2\n",
      "00654 0\n",
      "00657 2\n",
      "00663 0\n",
      "00667 2\n",
      "00668 0\n",
      "00682 0\n",
      "00683 0\n",
      "00684 2\n",
      "00685 2\n",
      "00686 0\n",
      "00687 0\n",
      "00688 2\n",
      "00703 2\n",
      "00706 0\n",
      "00709 2\n",
      "00723 2\n",
      "00724 0\n",
      "00727 0\n",
      "00728 2\n",
      "00729 2\n",
      "00730 0\n",
      "00733 0\n",
      "00734 2\n",
      "00735 2\n",
      "00742 0\n",
      "00744 2\n",
      "00747 0\n",
      "00751 2\n",
      "00753 2\n",
      "00756 0\n",
      "00759 0\n",
      "00764 0\n",
      "00767 0\n",
      "00774 0\n",
      "00778 2\n",
      "00780 0\n",
      "00788 2\n",
      "00792 0\n",
      "00796 2\n",
      "00797 0\n",
      "00799 2\n",
      "00800 2\n",
      "00802 2\n",
      "00803 2\n",
      "00804 0\n",
      "00805 2\n",
      "00806 2\n",
      "00809 2\n",
      "00810 0\n",
      "00814 0\n",
      "00818 0\n",
      "00820 2\n",
      "00824 2\n",
      "00830 0\n",
      "00836 2\n",
      "00837 2\n",
      "00839 2\n",
      "01004 0\n",
      "01009 0\n",
      "Ones:\n",
      "00000 1\n",
      "00002 1\n",
      "00005 1\n",
      "00006 1\n",
      "00008 1\n",
      "00011 1\n",
      "00012 1\n",
      "00014 1\n",
      "00020 1\n",
      "00025 1\n",
      "00026 1\n",
      "00028 1\n",
      "00031 1\n",
      "00033 1\n",
      "00035 1\n",
      "00043 1\n",
      "00046 1\n",
      "00052 1\n",
      "00054 1\n",
      "00056 1\n",
      "00058 1\n",
      "00059 1\n",
      "00060 1\n",
      "00062 1\n",
      "00063 1\n",
      "00066 1\n",
      "00068 1\n",
      "00070 1\n",
      "00071 1\n",
      "00074 1\n",
      "00077 1\n",
      "00085 1\n",
      "00087 1\n",
      "00094 1\n",
      "00096 1\n",
      "00098 1\n",
      "00100 1\n",
      "00105 1\n",
      "00106 1\n",
      "00109 1\n",
      "00117 1\n",
      "00128 1\n",
      "00136 1\n",
      "00138 1\n",
      "00139 1\n",
      "00140 1\n",
      "00146 1\n",
      "00155 1\n",
      "00156 1\n",
      "00159 1\n",
      "00160 1\n",
      "00166 1\n",
      "00177 1\n",
      "00178 1\n",
      "00185 1\n",
      "00186 1\n",
      "00188 1\n",
      "00196 1\n",
      "00197 1\n",
      "00203 1\n",
      "00204 1\n",
      "00210 1\n",
      "00212 1\n",
      "00220 1\n",
      "00222 1\n",
      "00230 1\n",
      "00233 1\n",
      "00234 1\n",
      "00235 1\n",
      "00246 1\n",
      "00250 1\n",
      "00253 1\n",
      "00254 1\n",
      "00260 1\n",
      "00263 1\n",
      "00270 1\n",
      "00271 1\n",
      "00273 1\n",
      "00281 1\n",
      "00282 1\n",
      "00284 1\n",
      "00285 1\n",
      "00291 1\n",
      "00293 1\n",
      "00294 1\n",
      "00296 1\n",
      "00303 1\n",
      "00304 1\n",
      "00305 1\n",
      "00306 1\n",
      "00311 1\n",
      "00313 1\n",
      "00317 1\n",
      "00321 1\n",
      "00322 1\n",
      "00328 1\n",
      "00329 1\n",
      "00331 1\n",
      "00332 1\n",
      "00334 1\n",
      "00338 1\n",
      "00340 1\n",
      "00344 1\n",
      "00350 1\n",
      "00352 1\n",
      "00359 1\n",
      "00360 1\n",
      "00364 1\n",
      "00366 1\n",
      "00367 1\n",
      "00369 1\n",
      "00370 1\n",
      "00371 1\n",
      "00383 1\n",
      "00386 1\n",
      "00400 1\n",
      "00403 1\n",
      "00404 1\n",
      "00406 1\n",
      "00409 1\n",
      "00413 1\n",
      "00425 1\n",
      "00426 1\n",
      "00429 1\n",
      "00431 1\n",
      "00436 1\n",
      "00440 1\n",
      "00442 1\n",
      "00443 1\n",
      "00449 1\n",
      "00451 1\n",
      "00456 1\n",
      "00468 1\n",
      "00470 1\n",
      "00472 1\n",
      "00478 1\n",
      "00479 1\n",
      "00480 1\n",
      "00483 1\n",
      "00485 1\n",
      "00488 1\n",
      "00491 1\n",
      "00493 1\n",
      "00494 1\n",
      "00499 1\n",
      "00500 1\n",
      "00501 1\n",
      "00504 1\n",
      "00505 1\n",
      "00506 1\n",
      "00511 1\n",
      "00513 1\n",
      "00516 1\n",
      "00517 1\n",
      "00520 1\n",
      "00523 1\n",
      "00525 1\n",
      "00526 1\n",
      "00528 1\n",
      "00529 1\n",
      "00532 1\n",
      "00537 1\n",
      "00539 1\n",
      "00542 1\n",
      "00543 1\n",
      "00544 1\n",
      "00548 1\n",
      "00550 1\n",
      "00551 1\n",
      "00554 1\n",
      "00556 1\n",
      "00557 1\n",
      "00558 1\n",
      "00559 1\n",
      "00561 1\n",
      "00564 1\n",
      "00570 1\n",
      "00576 1\n",
      "00579 1\n",
      "00582 1\n",
      "00583 1\n",
      "00584 1\n",
      "00586 1\n",
      "00590 1\n",
      "00593 1\n",
      "00594 1\n",
      "00597 1\n",
      "00598 1\n",
      "00599 1\n",
      "00602 1\n",
      "00604 1\n",
      "00606 1\n",
      "00607 1\n",
      "00608 1\n",
      "00612 1\n",
      "00613 1\n",
      "00615 1\n",
      "00618 1\n",
      "00621 1\n",
      "00622 1\n",
      "00625 1\n",
      "00626 1\n",
      "00628 1\n",
      "00631 1\n",
      "00639 1\n",
      "00640 1\n",
      "00650 1\n",
      "00652 1\n",
      "00655 1\n",
      "00656 1\n",
      "00659 1\n",
      "00661 1\n",
      "00674 1\n",
      "00675 1\n",
      "00676 1\n",
      "00677 1\n",
      "00679 1\n",
      "00690 1\n",
      "00691 1\n",
      "00693 1\n",
      "00697 1\n",
      "00698 1\n",
      "00704 1\n",
      "00705 1\n",
      "00708 1\n",
      "00715 1\n",
      "00716 1\n",
      "00718 1\n",
      "00725 1\n",
      "00731 1\n",
      "00732 1\n",
      "00736 1\n",
      "00737 1\n",
      "00739 1\n",
      "00740 1\n",
      "00746 1\n",
      "00750 1\n",
      "00757 1\n",
      "00758 1\n",
      "00760 1\n",
      "00765 1\n",
      "00768 1\n",
      "00772 1\n",
      "00773 1\n",
      "00775 1\n",
      "00777 1\n",
      "00781 1\n",
      "00782 1\n",
      "00784 1\n",
      "00787 1\n",
      "00789 1\n",
      "00791 1\n",
      "00793 1\n",
      "00794 1\n",
      "00795 1\n",
      "00801 1\n",
      "00807 1\n",
      "00811 1\n",
      "00816 1\n",
      "00819 1\n",
      "00823 1\n",
      "00828 1\n",
      "00838 1\n",
      "00840 1\n",
      "00998 1\n",
      "00999 1\n",
      "01000 1\n",
      "01001 1\n",
      "01002 1\n",
      "01003 1\n",
      "01005 1\n",
      "01007 1\n",
      "01008 1\n",
      "129 273 141\n",
      "['00018', '00019', '00021', '00022', '00030', '00036', '00053', '00064', '00072', '00088', '00090', '00095', '00097', '00099', '00116', '00121', '00122', '00124', '00130', '00133', '00142', '00150', '00154', '00157', '00158', '00165', '00167', '00169', '00172', '00176', '00183', '00184', '00191', '00195', '00201', '00206', '00209', '00211', '00214', '00216', '00221', '00231', '00237', '00238', '00239', '00242', '00247', '00249', '00259', '00266', '00267', '00283', '00289', '00290', '00297', '00300', '00301', '00309', '00310', '00312', '00316', '00320', '00324', '00325', '00327', '00336', '00347', '00351', '00356', '00373', '00382', '00388', '00391', '00392', '00395', '00401', '00417', '00421', '00430', '00433', '00445', '00452', '00455', '00477', '00481', '00495', '00498', '00512', '00563', '00568', '00569', '00587', '00588', '00589', '00591', '00596', '00601', '00605', '00616', '00641', '00654', '00663', '00668', '00682', '00683', '00686', '00687', '00706', '00724', '00727', '00730', '00733', '00742', '00747', '00756', '00759', '00764', '00767', '00774', '00780', '00792', '00797', '00804', '00810', '00814', '00818', '00830', '01004', '01009']\n",
      "['00000', '00002', '00005', '00006', '00008', '00011', '00012', '00014', '00020', '00025', '00026', '00028', '00031', '00033', '00035', '00043', '00046', '00052', '00054', '00056', '00058', '00059', '00060', '00062', '00063', '00066', '00068', '00070', '00071', '00074', '00077', '00085', '00087', '00094', '00096', '00098', '00100', '00105', '00106', '00109', '00117', '00128', '00136', '00138', '00139', '00140', '00146', '00155', '00156', '00159', '00160', '00166', '00177', '00178', '00185', '00186', '00188', '00196', '00197', '00203', '00204', '00210', '00212', '00220', '00222', '00230', '00233', '00234', '00235', '00246', '00250', '00253', '00254', '00260', '00263', '00270', '00271', '00273', '00281', '00282', '00284', '00285', '00291', '00293', '00294', '00296', '00303', '00304', '00305', '00306', '00311', '00313', '00317', '00321', '00322', '00328', '00329', '00331', '00332', '00334', '00338', '00340', '00344', '00350', '00352', '00359', '00360', '00364', '00366', '00367', '00369', '00370', '00371', '00383', '00386', '00400', '00403', '00404', '00406', '00409', '00413', '00425', '00426', '00429', '00431', '00436', '00440', '00442', '00443', '00449', '00451', '00456', '00468', '00470', '00472', '00478', '00479', '00480', '00483', '00485', '00488', '00491', '00493', '00494', '00499', '00500', '00501', '00504', '00505', '00506', '00511', '00513', '00516', '00517', '00520', '00523', '00525', '00526', '00528', '00529', '00532', '00537', '00539', '00542', '00543', '00544', '00548', '00550', '00551', '00554', '00556', '00557', '00558', '00559', '00561', '00564', '00570', '00576', '00579', '00582', '00583', '00584', '00586', '00590', '00593', '00594', '00597', '00598', '00599', '00602', '00604', '00606', '00607', '00608', '00612', '00613', '00615', '00618', '00621', '00622', '00625', '00626', '00628', '00631', '00639', '00640', '00650', '00652', '00655', '00656', '00659', '00661', '00674', '00675', '00676', '00677', '00679', '00690', '00691', '00693', '00697', '00698', '00704', '00705', '00708', '00715', '00716', '00718', '00725', '00731', '00732', '00736', '00737', '00739', '00740', '00746', '00750', '00757', '00758', '00760', '00765', '00768', '00772', '00773', '00775', '00777', '00781', '00782', '00784', '00787', '00789', '00791', '00793', '00794', '00795', '00801', '00807', '00811', '00816', '00819', '00823', '00828', '00838', '00840', '00998', '00999', '01000', '01001', '01002', '01003', '01005', '01007', '01008']\n",
      "['00009', '00017', '00024', '00032', '00044', '00045', '00049', '00061', '00081', '00084', '00102', '00104', '00110', '00111', '00112', '00113', '00123', '00149', '00151', '00162', '00170', '00192', '00193', '00194', '00217', '00218', '00219', '00227', '00228', '00236', '00241', '00243', '00251', '00258', '00261', '00262', '00269', '00274', '00275', '00280', '00286', '00288', '00298', '00308', '00314', '00318', '00339', '00341', '00343', '00346', '00348', '00349', '00353', '00376', '00377', '00378', '00379', '00380', '00387', '00389', '00390', '00397', '00399', '00402', '00405', '00407', '00410', '00412', '00414', '00418', '00419', '00423', '00432', '00441', '00444', '00446', '00454', '00459', '00464', '00469', '00496', '00507', '00510', '00514', '00518', '00519', '00530', '00533', '00538', '00540', '00545', '00547', '00555', '00565', '00567', '00571', '00572', '00574', '00575', '00578', '00581', '00619', '00620', '00623', '00624', '00630', '00636', '00642', '00645', '00649', '00651', '00657', '00667', '00684', '00685', '00688', '00703', '00709', '00723', '00728', '00729', '00734', '00735', '00744', '00751', '00753', '00778', '00788', '00796', '00799', '00800', '00802', '00803', '00805', '00806', '00809', '00820', '00824', '00836', '00837', '00839']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "common_path = \"../../RSNA-BTC-Datasets/train_mat/T1wCE/\"\n",
    "tumor_path = \"../../RSNA-BTC-Datasets/ec_train_mat/T1wCE/\"\n",
    "print(\"Zeros:\")\n",
    "full_0 = os.listdir(common_path+\"0\")\n",
    "full_0.sort()\n",
    "full_1 = os.listdir(common_path+\"1\")\n",
    "full_1.sort()\n",
    "tumor_only_0 = os.listdir(tumor_path+\"0\") # t=1 and m=0\n",
    "tumor_only_1 = os.listdir(tumor_path+\"1\") #t=1 and m=1\n",
    "count_0 = 0 #f0\n",
    "count_1 = 0 #f1\n",
    "count_2 = 0 #h0\n",
    "f0_list = []\n",
    "f1_list = []\n",
    "h0_list = []\n",
    "\n",
    "for file in full_0:\n",
    "    if file in tumor_only_0:\n",
    "        print(file[:5],0) #tumor = 1 and meth = 0\n",
    "        count_0 += 1\n",
    "        f0_list.append(file[:5])\n",
    "    else:\n",
    "        print(file[:5],2) #tumor = 0 and meth = 0\n",
    "        count_2 += 1\n",
    "        h0_list.append(file[:5])\n",
    "print(\"Ones:\")\n",
    "for file in full_1:\n",
    "    if file in tumor_only_1:\n",
    "        print(file[:5],1) # tumor = 1 and meth = 1\n",
    "        count_1 += 1\n",
    "        f1_list.append(file[:5])\n",
    "    \n",
    "print(count_0, count_1, count_2)\n",
    "print(f0_list)\n",
    "print(f1_list)\n",
    "print(h0_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.dataset_utils import *\n",
    "from utils.classifier_utils import *\n",
    "\n",
    "import os\n",
    "\n",
    "import monai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format='%(asctime)s - %(message)s', datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "#import config\n",
    "#from dataset import BrainRSNADataset\n",
    "\n",
    "dir_path = \"../../RSNA-BTC-Datasets/train_mat\"\n",
    "test_dir_path = \"../../RSNA-BTC-Datasets/test_mat\"\n",
    "tumor_only_dir_path = \"../../RSNA-BTC-Datasets/ec_train_mat\"\n",
    "tumor_only_test_dir_path = \"../../RSNA-BTC-Datasets/ec_test_mat\"\n",
    "no_tumor_dir_path = \"../../RSNA-BTC-Datasets/no_tumor_train_mat\"\n",
    "#ext_test_1_dir_path = \"../../RSNA-BTC-Datasets/brats18_mat\"\n",
    "#ext_test_0_dir_path = \"../../RSNA-BTC-Datasets/OpenNeuroDS000221_ss_mat\"\n",
    "new_dir_path = \"../../RSNA-BTC-Datasets/UPENN-GBM_mat\"\n",
    "\n",
    "def generate_datasets(types):\n",
    "    data_packs = {}\n",
    "    ext = \"mat\"\n",
    "    transform = None\n",
    "    dims = 3\n",
    "    sel_slices = None\n",
    "    for t in types:\n",
    "        print(\"Type: \"+t)\n",
    "        # Competition Train + Val + Test\n",
    "        m_dataset_0 = Dataset(dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        logging.info(\"m0 Train/Val datasets size: {}\".format(len(m_dataset_0)))\n",
    "\n",
    "        m_dataset_1 = Dataset(dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "        \n",
    "        logging.info(\"m1 Train/Val datasets size: {}\".format(len(m_dataset_1)))\n",
    "\n",
    "        # External Train + Val + Test\n",
    "        #t_dataset_0 = Dataset(ext_test_0_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        #logging.info(\"Train/Val datasets size: {}\".format(len(t_dataset_0)))\n",
    "\n",
    "        #t_dataset_1 = Dataset(ext_test_1_dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        #logging.info(\"Train/Val datasets size: {}\".format(len(t_dataset_1)))\n",
    "\n",
    "        # UPENN Train + Val + Test\n",
    "        n_dataset_0 = Dataset(new_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        logging.info(\"n0 Train/Val datasets size: {}\".format(len(n_dataset_0)))\n",
    "\n",
    "        n_dataset_1 = Dataset(new_dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "        \n",
    "        logging.info(\"n1 Train/Val datasets size: {}\".format(len(n_dataset_1)))\n",
    "        \n",
    "        if t == \"KLF\" or t == \"T1wCE\":\n",
    "            # Competition (Tumor Only) Train + Val + Test\n",
    "            f_dataset_0 = Dataset(tumor_only_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "            logging.info(\"f0 Train/Val datasets size: {}\".format(len(f_dataset_0)))\n",
    "\n",
    "            f_dataset_1 = Dataset(tumor_only_dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "            logging.info(\"f1 Train/Val datasets size: {}\".format(len(f_dataset_1)))\n",
    "            \n",
    "            # Competition (No Tumor) Train + Val + Test\n",
    "            h_dataset_0 = Dataset(no_tumor_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "            logging.info(\"h0 Train/Val datasets size: {}\".format(len(h_dataset_0)))\n",
    "            \n",
    "            # Competition (Tumor Only) + UPENN Train + Val + Test\n",
    "            fn_dataset_0 = Dataset().concat_datasets(f_dataset_0, n_dataset_0)\n",
    "            \n",
    "            logging.info(\"fn0 Train/Val datasets size: {}\".format(len(fn_dataset_0)))\n",
    "            \n",
    "            fn_dataset_1 = Dataset().concat_datasets(f_dataset_1, n_dataset_1)\n",
    "            \n",
    "            logging.info(\"fn1 Train/Val datasets size: {}\".format(len(fn_dataset_1)))\n",
    "        \n",
    "        if t == \"KLF\" or t == \"T1wCE\":\n",
    "            data_packs[t] = {\n",
    "                \"m_dataset_0\": m_dataset_0,\n",
    "                \"m_dataset_1\": m_dataset_1,\n",
    "                \"f_dataset_0\": f_dataset_0,\n",
    "                \"f_dataset_1\": f_dataset_1,\n",
    "                \"h_dataset_0\": h_dataset_0,\n",
    "                #\"t_dataset_0\": t_dataset_0,\n",
    "                #\"t_dataset_1\": t_dataset_1,\n",
    "                \"n_dataset_0\": n_dataset_0,\n",
    "                \"n_dataset_1\": n_dataset_1,\n",
    "                \"fn_dataset_0\": fn_dataset_0,\n",
    "                \"fn_dataset_1\": fn_dataset_1\n",
    "            }\n",
    "        else:\n",
    "            data_packs[t] = {\n",
    "                \"m_dataset_0\": m_dataset_0,\n",
    "                \"m_dataset_1\": m_dataset_1,\n",
    "                #\"t_dataset_0\": t_dataset_0,\n",
    "                #\"t_dataset_1\": t_dataset_1,\n",
    "                \"n_dataset_0\": n_dataset_0,\n",
    "                \"n_dataset_1\": n_dataset_1\n",
    "            }\n",
    "    return data_packs\n",
    "\n",
    "def get_merged_dataset(dataset_0, dataset_1, k=1):\n",
    "    dataset_merged = Dataset().concat_datasets(dataset_0, dataset_1)\n",
    "    dataset_merged_no_tr = Dataset().concat_datasets(dataset_0, dataset_1, import_transform=False)\n",
    "\n",
    "    val_total_ratio = 0.2\n",
    "    is_k_fold = (k > 1)\n",
    "    splits = dataset_utils.get_splits(dataset_0, dataset_1, val_total_ratio, is_k_fold, 0.1, k)\n",
    "    print(splits)\n",
    "    return dataset_merged, dataset_merged_no_tr, splits\n",
    "\n",
    "def get_loaders(packs, batch_size):\n",
    "    loader_packs = {}\n",
    "    for t, pack in packs.items():\n",
    "        print(\"Type: \"+t)\n",
    "        m_dataset_merged, m_dataset_merged_no_tr, m_splits = get_merged_dataset(pack['m_dataset_0'], pack['m_dataset_1'])\n",
    "        n_dataset_merged, n_dataset_merged_no_tr, n_splits = get_merged_dataset(pack['n_dataset_0'], pack['n_dataset_1'])\n",
    "        #t_dataset_merged, t_dataset_merged_no_tr, t_splits = get_merged_dataset(pack['t_dataset_0'], pack['t_dataset_1'])\n",
    "        if t == \"KLF\" or t == \"T1wCE\":\n",
    "            f_dataset_merged, f_dataset_merged_no_tr, f_splits = get_merged_dataset(pack['f_dataset_0'], pack['f_dataset_1'])\n",
    "            h_dataset_merged, h_dataset_merged_no_tr, h_splits = get_merged_dataset(pack['h_dataset_0'], None)\n",
    "            fn_dataset_merged, fn_dataset_merged_no_tr, fn_splits = get_merged_dataset(pack['fn_dataset_0'], pack['fn_dataset_1'])\n",
    "        \n",
    "        m_dataloader = get_all_split_loaders(m_dataset_merged, m_dataset_merged_no_tr, m_splits, batch_size)\n",
    "        m_dataloaders = list(m_dataloader[0])\n",
    "        logging.info(\"(M) Train validation test splitted: {} {} {}\".format(len(m_splits[0][0]),len(m_splits[0][1]),len(m_splits[0][2])))\n",
    "\n",
    "        #t_dataloader = get_all_split_loaders(t_dataset_merged, t_dataset_merged_no_tr, t_splits, info[\"batch_size\"])\n",
    "        #t_dataloaders = list(t_dataloader[0])\n",
    "        #logging.info(\"(T) Train validation test splitted: {} {} {}\".format(len(t_splits[0][0]),len(t_splits[0][1]),len(t_splits[0][2])))\n",
    "\n",
    "        n_dataloader = get_all_split_loaders(n_dataset_merged, n_dataset_merged_no_tr, n_splits, batch_size)\n",
    "        n_dataloaders = list(n_dataloader[0])\n",
    "        logging.info(\"(N) Train validation test splitted: {} {} {}\".format(len(n_splits[0][0]),len(n_splits[0][1]),len(n_splits[0][2])))\n",
    "        \n",
    "        if t == \"KLF\" or t == \"T1wCE\":\n",
    "            f_dataloader = get_all_split_loaders(f_dataset_merged, f_dataset_merged_no_tr, f_splits, batch_size)\n",
    "            f_dataloaders = list(f_dataloader[0])\n",
    "            logging.info(\"(F) Train validation test splitted: {} {} {}\".format(len(f_splits[0][0]),len(f_splits[0][1]),len(f_splits[0][2])))\n",
    "            \n",
    "            h_dataloader = get_all_split_loaders(h_dataset_merged, h_dataset_merged_no_tr, h_splits, batch_size)\n",
    "            h_dataloaders = list(h_dataloader[0])\n",
    "            logging.info(\"(H) Train validation test splitted: {} {} {}\".format(len(h_splits[0][0]),len(h_splits[0][1]),len(h_splits[0][2])))\n",
    "\n",
    "            fn_dataloader = get_all_split_loaders(fn_dataset_merged, fn_dataset_merged_no_tr, fn_splits, batch_size)\n",
    "            fn_dataloaders = list(fn_dataloader[0])\n",
    "            logging.info(\"(FN) Train validation test splitted: {} {} {}\".format(len(fn_splits[0][0]),len(fn_splits[0][1]),len(fn_splits[0][2])))\n",
    "        \n",
    "        if t == \"KLF\" or t == \"T1wCE\":\n",
    "            loader_packs[t] = {\n",
    "                \"m_dataloaders\": m_dataloaders,\n",
    "                \"f_dataloaders\": f_dataloaders,\n",
    "                \"h_dataloaders\": h_dataloaders,\n",
    "                \"n_dataloaders\": n_dataloaders,\n",
    "                #\"t_dataloaders\": t_dataloaders,\n",
    "                \"fn_dataloaders\": fn_dataloaders\n",
    "            }\n",
    "        else:\n",
    "            loader_packs[t] = {\n",
    "                \"m_dataloaders\": m_dataloaders,\n",
    "                \"n_dataloaders\": n_dataloaders,\n",
    "                #\"t_dataloaders\": t_dataloaders\n",
    "            }\n",
    "        \n",
    "    return loader_packs\n",
    "\n",
    "import importlib\n",
    "from utils import dataset_utils\n",
    "importlib.reload(dataset_utils)\n",
    "\n",
    "def train_model(train_dl, validation_dl, fold_number, mri_type, model_name, epochs):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.5, last_epoch=-1, verbose=True)\n",
    "\n",
    "    model.zero_grad()\n",
    "    model.to(device)\n",
    "    best_loss = 9999\n",
    "    best_auc = 0\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    train_writer = SummaryWriter()\n",
    "    for counter in range(epochs):\n",
    "\n",
    "        epoch_iterator_train = tqdm(train_dl)\n",
    "        tr_loss = 0.0\n",
    "        for step, batch in enumerate(epoch_iterator_train):\n",
    "            model.train()\n",
    "            (img_ids, imgs, labels) = batch\n",
    "            images, targets = imgs[0].to(device), labels.to(device)\n",
    "            #images, targets = batch[\"image\"].to(device), batch[\"target\"].to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            targets = targets  # .view(-1, 1)\n",
    "            loss = criterion(outputs.squeeze(1), targets.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            epoch_iterator_train.set_postfix(\n",
    "                batch_loss=(loss.item()), loss=(tr_loss / (step + 1))\n",
    "            )\n",
    "\n",
    "        train_writer.add_scalar('loss', (tr_loss/(step+1)), counter+1)\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            preds = []\n",
    "            true_labels = []\n",
    "            case_ids = []\n",
    "            epoch_iterator_val = tqdm(validation_dl)\n",
    "            for step, batch in enumerate(epoch_iterator_val):\n",
    "                model.eval()\n",
    "                (img_ids, imgs, labels) = batch\n",
    "                images, targets = imgs[0].to(device), labels.to(device)\n",
    "                #images, targets = batch[\"image\"].to(device), batch[\"target\"].to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                targets = targets  # .view(-1, 1)\n",
    "                loss = criterion(outputs.squeeze(1), targets.float())\n",
    "                val_loss += loss.item()\n",
    "                epoch_iterator_val.set_postfix(\n",
    "                    batch_loss=(loss.item()), loss=(val_loss / (step + 1))\n",
    "                )\n",
    "                preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "                true_labels.append(targets.cpu().numpy())\n",
    "                #case_ids.append(batch[\"case_id\"])\n",
    "                if img_ids[0][0][0].isnumeric():\n",
    "                    img_ids_fixed = [img_id[:5] for img_id in img_ids[0]]\n",
    "                else:\n",
    "                    img_ids_fixed = [img_id[:-4] for img_id in img_ids[0]]\n",
    "                case_ids.append(img_ids_fixed)\n",
    "        preds = np.vstack(preds).T[0].tolist()\n",
    "        true_labels = np.hstack(true_labels).tolist()\n",
    "        case_ids = np.hstack(case_ids).tolist()\n",
    "        auc_score = roc_auc_score(true_labels, preds)\n",
    "        auc_score_adj_best = 0\n",
    "        for thresh in np.linspace(0, 1, 50):\n",
    "            auc_score_adj = roc_auc_score(true_labels, list(np.array(preds) > thresh))\n",
    "            if auc_score_adj > auc_score_adj_best:\n",
    "                best_thresh = thresh\n",
    "                auc_score_adj_best = auc_score_adj\n",
    "\n",
    "        print(\n",
    "            f\"EPOCH {counter+1}/{epochs}: Validation average loss: {val_loss/(step+1)} + AUC SCORE = {auc_score} + AUC SCORE THRESH {best_thresh} = {auc_score_adj_best}\"\n",
    "        )\n",
    "        train_writer.add_scalar('val_loss', val_loss/(step+1), counter+1)\n",
    "        train_writer.add_scalar('val_auc', auc_score, counter+1)\n",
    "        if auc_score > best_auc:\n",
    "            print(\"Saving the model...\")\n",
    "            date_time = datetime.now()\n",
    "            date_str = date_time.strftime(\"%b%d_%H-%M-%S\")\n",
    "    \n",
    "            #modelname = model.__class__.__name__\n",
    "        \n",
    "            model_fullname = f\"{model_name}_{date_str}\"\n",
    "\n",
    "            if not os.path.exists(\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/\"):\n",
    "                os.mkdir(\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/\")\n",
    "            if not os.path.exists(f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/{model_fullname}\"):\n",
    "                os.mkdir(f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/{model_fullname}\")\n",
    "            all_files = os.listdir(f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/{model_fullname}\")\n",
    "\n",
    "            for f in all_files:\n",
    "                if f\"{model_name}_{mri_type}_fold{fold_number}\" in f:\n",
    "                    os.remove(f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/{model_fullname}/{f}\")\n",
    "\n",
    "            best_auc = auc_score\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/{model_fullname}/3d-{model_name}_{mri_type}_fold{fold_number}_{round(best_auc,3)}.pth\",\n",
    "            )\n",
    "\n",
    "    print(best_auc)\n",
    "\n",
    "def train_folded_models(fold, mri_type, model_name, batch_size, epochs, train_origins):\n",
    "    #data = pd.read_csv(\"train.csv\")\n",
    "    #train_df = data[data.fold != fold].reset_index(drop=False)\n",
    "    #val_df = data[data.fold == fold].reset_index(drop=False)\n",
    "    \n",
    "    print(f\"train_{mri_type}_{fold}\")\n",
    "    #train_dataset = BrainRSNADataset(data=train_df, mri_type=args.type, ds_type=f\"train_{args.type}_{args.fold}\")\n",
    "\n",
    "    #valid_dataset = BrainRSNADataset(data=val_df, mri_type=args.type, ds_type=f\"val_{args.type}_{args.fold}\")\n",
    "\n",
    "    ##packs = generate_datasets([mri_type])\n",
    "    \n",
    "    loader_packs = {}\n",
    "    for t, pack in packs.items():\n",
    "        print(\"Type: \"+t)\n",
    "        m_dataset_merged, m_dataset_merged_no_tr, m_splits = get_merged_dataset(pack['m_dataset_0'], pack['m_dataset_1'], fold)\n",
    "        n_dataset_merged, n_dataset_merged_no_tr, n_splits = get_merged_dataset(pack['n_dataset_0'], pack['n_dataset_1'], fold)\n",
    "        fn_dataset_merged, fn_dataset_merged_no_tr, fn_splits = get_merged_dataset(pack['fn_dataset_0'], pack['fn_dataset_1'], fold)\n",
    "        f_dataset_merged, f_dataset_merged_no_tr, f_splits = get_merged_dataset(pack['f_dataset_0'], pack['f_dataset_1'], fold)\n",
    "        print(\"SPLITS:\")\n",
    "        print(\"- folds:\")\n",
    "        print(len(m_splits))\n",
    "        print(\"- splits per fold:\")\n",
    "        print(len(m_splits[0]))\n",
    "        #print(len(n_splits))\n",
    "        for to in train_origins:\n",
    "            if to == \"m\":\n",
    "                i = 0\n",
    "                for split in m_splits:\n",
    "                    m_dataloader = get_all_split_loaders(m_dataset_merged, m_dataset_merged_no_tr, [split], batch_size)\n",
    "                    m_dataloaders = list(m_dataloader[0])\n",
    "                    print(f\"(M) Train validation splitted: {len(split[0])} {len(split[1])}\")\n",
    "                    print(m_dataloaders)\n",
    "                    train_dl = m_dataloaders[0]\n",
    "                    validation_dl = m_dataloaders[1]\n",
    "                    train_model(train_dl, validation_dl, i, mri_type, model_name+\"_m\", epochs)\n",
    "                    \"\"\"\n",
    "                    device = torch.device(\"cuda\")\n",
    "                    model = monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1)\n",
    "                    model.to(device)\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "                    criterion = nn.BCEWithLogitsLoss()\n",
    "                    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.5, last_epoch=-1, verbose=True)\n",
    "                    trainer = Trainer(\n",
    "                        model, \n",
    "                        device, \n",
    "                        optimizer, \n",
    "                        criterion,\n",
    "                        scheduler,\n",
    "                        1\n",
    "                    )\n",
    "\n",
    "                    history = trainer.fit(\n",
    "                        device,\n",
    "                        epochs, \n",
    "                        train_dl,\n",
    "                        validation_dl,\n",
    "                        model_name+\"_m\", \n",
    "                        15\n",
    "                    )\n",
    "\n",
    "                    trainer.train_writer.flush()\n",
    "                    \"\"\"\n",
    "                    i += 1\n",
    "\n",
    "            elif to == \"n\":\n",
    "                i = 0\n",
    "                for split in n_splits:\n",
    "                    n_dataloader = get_all_split_loaders(n_dataset_merged, n_dataset_merged_no_tr, [split], batch_size)\n",
    "                    n_dataloaders = list(n_dataloader[0])\n",
    "                    print(f\"(N) Train validation splitted: {len(split[0])} {len(split[1])}\")\n",
    "                    train_dl = n_dataloaders[0]\n",
    "                    validation_dl = n_dataloaders[1]\n",
    "                    train_model(train_dl, validation_dl, i, mri_type, model_name+\"_n\", epochs)\n",
    "                    i += 1\n",
    "            elif to == \"fn\":\n",
    "                i = 0\n",
    "                for split in fn_splits:\n",
    "                    print(f\"Fold n.{i} started\")\n",
    "                    fn_dataloader = get_all_split_loaders(fn_dataset_merged, fn_dataset_merged_no_tr, [split], batch_size)\n",
    "                    fn_dataloaders = list(fn_dataloader[0])\n",
    "                    print(f\"(FN) Train validation splitted: {len(split[0])} {len(split[1])}\")\n",
    "                    train_dl = fn_dataloaders[0]\n",
    "                    validation_dl = fn_dataloaders[1]\n",
    "                    train_model(train_dl, validation_dl, i, mri_type, model_name+\"_fn\", epochs)\n",
    "                    i += 1\n",
    "            elif to == \"f\":\n",
    "                i = 0\n",
    "                for split in f_splits:\n",
    "                    f_dataloader = get_all_split_loaders(f_dataset_merged, f_dataset_merged_no_tr, [split], batch_size)\n",
    "                    f_dataloaders = list(f_dataloader[0])\n",
    "                    print(f\"(F) Train validation splitted: {len(split[0])} {len(split[1])}\")\n",
    "                    train_dl = f_dataloaders[0]\n",
    "                    validation_dl = f_dataloaders[1]\n",
    "                    train_model(train_dl, validation_dl, i, mri_type, model_name+\"_f\", epochs)\n",
    "                    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14356929"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce RTX 3090\n",
      "1.12.1\n",
      "11.3\n",
      "tensor([-1.2654], device='cuda:0')\n",
      "2022-08-09 19:35:23 - Printing one: 1\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\"\"\"\n",
    "for file in os.listdir(no_tumor_dir_path+\"/KLF/0\"):\n",
    "    fixed_file = file[:-7]+\"T1wCE.mat\"\n",
    "    shutil.copy(dir_path+\"/T1wCE/0/\"+fixed_file, no_tumor_dir_path+\"/T1wCE/0/\"+fixed_file)\n",
    "    \n",
    "for file in os.listdir(tumor_only_dir_path+\"/KLF/0\"):\n",
    "    fixed_file = file[:-7]+\"T1wCE.mat\"\n",
    "    shutil.copy(dir_path+\"/T1wCE/0/\"+fixed_file, tumor_only_dir_path+\"/T1wCE/0/\"+fixed_file)\n",
    "    \n",
    "for file in os.listdir(tumor_only_dir_path+\"/KLF/1\"):\n",
    "    fixed_file = file[:-7]+\"T1wCE.mat\"\n",
    "    shutil.copy(dir_path+\"/T1wCE/1/\"+fixed_file, tumor_only_dir_path+\"/T1wCE/1/\"+fixed_file)\n",
    "\"\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "x = torch.randn(1).cuda()\n",
    "print(x)\n",
    "logging.info(\"Printing one: {}\".format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: T1wCE\n",
      "2022-08-09 19:35:24 - m0 Train/Val datasets size: 270\n",
      "2022-08-09 19:35:24 - m1 Train/Val datasets size: 303\n",
      "2022-08-09 19:35:24 - n0 Train/Val datasets size: 170\n",
      "2022-08-09 19:35:24 - n1 Train/Val datasets size: 121\n",
      "2022-08-09 19:35:24 - f0 Train/Val datasets size: 129\n",
      "2022-08-09 19:35:24 - f1 Train/Val datasets size: 273\n",
      "2022-08-09 19:35:24 - h0 Train/Val datasets size: 141\n",
      "Length of concatenated dataset: 340\n",
      "2022-08-09 19:35:24 - fn0 Train/Val datasets size: 340\n",
      "Length of concatenated dataset: 546\n",
      "2022-08-09 19:35:24 - fn1 Train/Val datasets size: 546\n",
      "Type: T1wCE\n",
      "Length of concatenated dataset: 606\n",
      "Length of concatenated dataset: 606\n",
      "Train Idx:\n",
      "[238, 137, 106, 284, 44, 139, 247, 288, 156, 297, 252, 54, 234, 18, 205, 254, 182, 56, 71, 144, 249, 209, 290, 219, 158, 176, 33, 83, 136, 210, 118, 60, 159, 282, 110, 21, 29, 150, 16, 75, 109, 179, 283, 4, 96, 229, 61, 67, 295, 266, 171, 281, 40, 189, 13, 107, 200, 3, 161, 125, 24, 30, 77, 279, 190, 19, 257, 235, 268, 80, 51, 2, 239, 104, 262, 86, 10, 224, 58, 41, 14, 155, 50, 215, 237, 123, 220, 62, 191, 230, 130, 213, 187, 43, 114, 138, 199, 222, 149, 112, 298, 98, 221, 93, 208, 162, 36, 178, 113, 0, 94, 294, 95, 299, 263, 256, 69, 49, 48, 85, 300, 141, 207, 23, 250, 148, 143, 78, 180, 100, 204, 131, 269, 301, 196, 6, 68, 203, 84, 170, 121, 140, 258, 276, 142, 259, 91, 82, 285, 11, 119, 102, 35, 57, 169, 231, 65, 1, 120, 267, 186, 42, 105, 132, 79, 17, 271, 38, 53, 260, 128, 28, 183, 163, 151, 244, 202, 31, 32, 127, 185, 280, 273, 147, 278, 177, 99, 197, 243, 115, 265, 72, 25, 165, 289, 174, 291, 39, 193, 88, 70, 87, 292, 242, 277, 211, 9, 195, 251, 192, 117, 47, 172, 516, 380, 549, 365, 554, 536, 489, 433, 486, 369, 338, 320, 465, 589, 448, 528, 499, 348, 353, 360, 556, 547, 531, 544, 335, 381, 449, 436, 399, 517, 401, 505, 471, 392, 543, 561, 550, 435, 349, 500, 410, 473, 303, 542, 374, 579, 405, 370, 411, 525, 387, 584, 557, 428, 539, 412, 329, 484, 602, 545, 490, 437, 372, 402, 527, 521, 342, 496, 493, 432, 551, 443, 434, 564, 416, 321, 379, 495, 552, 414, 479, 312, 492, 462, 599, 346, 394, 407, 441, 478, 415, 371, 339, 513, 368, 345, 429, 306, 420, 451, 596, 580, 574, 431, 485, 440, 600, 310, 389, 482, 422, 569, 418, 464, 332, 458, 563, 488, 404, 400, 323, 456, 357, 333, 583, 352, 403, 565, 594, 454, 417, 359, 447, 363, 497, 535, 515, 502, 601, 309, 562, 311, 520, 382, 576, 511, 577, 546, 568, 470, 341, 373, 424, 582, 347, 603, 597, 480, 361, 466, 427, 457, 383, 362, 595, 351, 356, 461, 354, 575, 522, 377, 307, 442, 510, 590, 559, 308, 444, 364, 438, 386, 530, 325, 573, 523, 506, 423, 384, 316, 587, 375, 450, 463, 390, 541, 605, 439, 498, 494, 419, 327, 397, 467, 409, 319, 366, 408, 512, 331, 504, 477, 396]\n",
      "Val Idx:\n",
      "[225, 152, 228, 201, 52, 245, 175, 168, 223, 217, 111, 135, 218, 12, 15, 66, 97, 90, 198, 103, 22, 212, 226, 264, 133, 216, 275, 270, 154, 55, 194, 255, 134, 8, 157, 241, 240, 81, 214, 167, 5, 59, 92, 274, 34, 145, 116, 188, 246, 7, 45, 129, 122, 63, 124, 227, 146, 302, 26, 108, 560, 472, 367, 518, 487, 343, 514, 459, 588, 426, 524, 355, 538, 566, 395, 474, 425, 468, 558, 324, 567, 326, 591, 328, 592, 571, 337, 322, 314, 391, 421, 586, 453, 455, 508, 570, 491, 406, 501, 388, 378, 534, 452, 598, 385, 578, 315, 336, 581, 555, 413, 507, 334, 445, 529, 330, 340, 317, 604, 481]\n",
      "Test Idx:\n",
      "[89, 74, 153, 64, 296, 287, 286, 236, 126, 73, 20, 46, 160, 232, 181, 27, 173, 261, 37, 101, 166, 233, 184, 164, 206, 248, 253, 293, 76, 272, 305, 585, 304, 475, 476, 533, 548, 553, 344, 318, 393, 483, 532, 509, 540, 313, 430, 350, 526, 572, 460, 446, 398, 469, 537, 593, 358, 376, 519, 503]\n",
      "[([238, 137, 106, 284, 44, 139, 247, 288, 156, 297, 252, 54, 234, 18, 205, 254, 182, 56, 71, 144, 249, 209, 290, 219, 158, 176, 33, 83, 136, 210, 118, 60, 159, 282, 110, 21, 29, 150, 16, 75, 109, 179, 283, 4, 96, 229, 61, 67, 295, 266, 171, 281, 40, 189, 13, 107, 200, 3, 161, 125, 24, 30, 77, 279, 190, 19, 257, 235, 268, 80, 51, 2, 239, 104, 262, 86, 10, 224, 58, 41, 14, 155, 50, 215, 237, 123, 220, 62, 191, 230, 130, 213, 187, 43, 114, 138, 199, 222, 149, 112, 298, 98, 221, 93, 208, 162, 36, 178, 113, 0, 94, 294, 95, 299, 263, 256, 69, 49, 48, 85, 300, 141, 207, 23, 250, 148, 143, 78, 180, 100, 204, 131, 269, 301, 196, 6, 68, 203, 84, 170, 121, 140, 258, 276, 142, 259, 91, 82, 285, 11, 119, 102, 35, 57, 169, 231, 65, 1, 120, 267, 186, 42, 105, 132, 79, 17, 271, 38, 53, 260, 128, 28, 183, 163, 151, 244, 202, 31, 32, 127, 185, 280, 273, 147, 278, 177, 99, 197, 243, 115, 265, 72, 25, 165, 289, 174, 291, 39, 193, 88, 70, 87, 292, 242, 277, 211, 9, 195, 251, 192, 117, 47, 172, 516, 380, 549, 365, 554, 536, 489, 433, 486, 369, 338, 320, 465, 589, 448, 528, 499, 348, 353, 360, 556, 547, 531, 544, 335, 381, 449, 436, 399, 517, 401, 505, 471, 392, 543, 561, 550, 435, 349, 500, 410, 473, 303, 542, 374, 579, 405, 370, 411, 525, 387, 584, 557, 428, 539, 412, 329, 484, 602, 545, 490, 437, 372, 402, 527, 521, 342, 496, 493, 432, 551, 443, 434, 564, 416, 321, 379, 495, 552, 414, 479, 312, 492, 462, 599, 346, 394, 407, 441, 478, 415, 371, 339, 513, 368, 345, 429, 306, 420, 451, 596, 580, 574, 431, 485, 440, 600, 310, 389, 482, 422, 569, 418, 464, 332, 458, 563, 488, 404, 400, 323, 456, 357, 333, 583, 352, 403, 565, 594, 454, 417, 359, 447, 363, 497, 535, 515, 502, 601, 309, 562, 311, 520, 382, 576, 511, 577, 546, 568, 470, 341, 373, 424, 582, 347, 603, 597, 480, 361, 466, 427, 457, 383, 362, 595, 351, 356, 461, 354, 575, 522, 377, 307, 442, 510, 590, 559, 308, 444, 364, 438, 386, 530, 325, 573, 523, 506, 423, 384, 316, 587, 375, 450, 463, 390, 541, 605, 439, 498, 494, 419, 327, 397, 467, 409, 319, 366, 408, 512, 331, 504, 477, 396], [225, 152, 228, 201, 52, 245, 175, 168, 223, 217, 111, 135, 218, 12, 15, 66, 97, 90, 198, 103, 22, 212, 226, 264, 133, 216, 275, 270, 154, 55, 194, 255, 134, 8, 157, 241, 240, 81, 214, 167, 5, 59, 92, 274, 34, 145, 116, 188, 246, 7, 45, 129, 122, 63, 124, 227, 146, 302, 26, 108, 560, 472, 367, 518, 487, 343, 514, 459, 588, 426, 524, 355, 538, 566, 395, 474, 425, 468, 558, 324, 567, 326, 591, 328, 592, 571, 337, 322, 314, 391, 421, 586, 453, 455, 508, 570, 491, 406, 501, 388, 378, 534, 452, 598, 385, 578, 315, 336, 581, 555, 413, 507, 334, 445, 529, 330, 340, 317, 604, 481], [89, 74, 153, 64, 296, 287, 286, 236, 126, 73, 20, 46, 160, 232, 181, 27, 173, 261, 37, 101, 166, 233, 184, 164, 206, 248, 253, 293, 76, 272, 305, 585, 304, 475, 476, 533, 548, 553, 344, 318, 393, 483, 532, 509, 540, 313, 430, 350, 526, 572, 460, 446, 398, 469, 537, 593, 358, 376, 519, 503])]\n",
      "Length of concatenated dataset: 546\n",
      "Length of concatenated dataset: 546\n",
      "Train Idx:\n",
      "[33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441]\n",
      "Val Idx:\n",
      "[218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529]\n",
      "Test Idx:\n",
      "[201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358]\n",
      "[([33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441], [218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529], [201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358])]\n",
      "Length of concatenated dataset: 546\n",
      "Length of concatenated dataset: 546\n",
      "Train Idx:\n",
      "[33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441]\n",
      "Val Idx:\n",
      "[218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529]\n",
      "Test Idx:\n",
      "[201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358]\n",
      "[([33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441], [218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529], [201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358])]\n",
      "Length of concatenated dataset: 141\n",
      "Length of concatenated dataset: 141\n",
      "Train Idx:\n",
      "[112, 78, 132, 68, 93, 85, 48, 135, 13, 92, 95, 73, 119, 15, 116, 40, 62, 128, 138, 3, 52, 63, 113, 6, 139, 12, 86, 104, 109, 127, 11, 94, 110, 41, 101, 1, 97, 130, 42, 4, 114, 17, 38, 5, 53, 134, 89, 0, 34, 28, 55, 75, 35, 23, 74, 31, 102, 57, 120, 65, 32, 129, 14, 106, 19, 29, 49, 126, 99, 82, 64, 140, 79, 69, 118, 80, 115, 20, 136, 72, 77, 25, 37, 81, 131, 46, 133, 39, 58, 88, 70, 87, 36, 21, 9, 103, 67, 117, 47]\n",
      "Val Idx:\n",
      "[45, 60, 7, 51, 66, 27, 71, 54, 123, 8, 76, 16, 125, 122, 124, 98, 105, 83, 33, 56, 91, 22, 137, 24, 2, 111, 26, 121]\n",
      "Test Idx:\n",
      "[18, 10, 96, 43, 100, 108, 50, 84, 61, 107, 90, 59, 44, 30]\n",
      "[([112, 78, 132, 68, 93, 85, 48, 135, 13, 92, 95, 73, 119, 15, 116, 40, 62, 128, 138, 3, 52, 63, 113, 6, 139, 12, 86, 104, 109, 127, 11, 94, 110, 41, 101, 1, 97, 130, 42, 4, 114, 17, 38, 5, 53, 134, 89, 0, 34, 28, 55, 75, 35, 23, 74, 31, 102, 57, 120, 65, 32, 129, 14, 106, 19, 29, 49, 126, 99, 82, 64, 140, 79, 69, 118, 80, 115, 20, 136, 72, 77, 25, 37, 81, 131, 46, 133, 39, 58, 88, 70, 87, 36, 21, 9, 103, 67, 117, 47], [45, 60, 7, 51, 66, 27, 71, 54, 123, 8, 76, 16, 125, 122, 124, 98, 105, 83, 33, 56, 91, 22, 137, 24, 2, 111, 26, 121], [18, 10, 96, 43, 100, 108, 50, 84, 61, 107, 90, 59, 44, 30])]\n",
      "Length of concatenated dataset: 1092\n",
      "Length of concatenated dataset: 1092\n",
      "Train Idx:\n",
      "[386, 463, 206, 38, 188, 361, 339, 272, 289, 437, 462, 124, 154, 526, 59, 252, 466, 491, 541, 235, 211, 420, 55, 171, 233, 205, 158, 385, 34, 367, 18, 506, 247, 529, 52, 74, 26, 173, 92, 167, 4, 435, 181, 246, 443, 5, 141, 301, 200, 135, 263, 122, 22, 68, 210, 20, 306, 336, 14, 170, 374, 281, 271, 220, 537, 64, 520, 250, 120, 81, 421, 500, 240, 308, 534, 528, 160, 536, 238, 497, 484, 392, 478, 465, 51, 195, 191, 116, 342, 395, 164, 106, 372, 63, 511, 284, 519, 445, 316, 93, 366, 332, 198, 145, 150, 39, 495, 439, 253, 344, 464, 2, 221, 514, 146, 241, 538, 114, 391, 176, 168, 515, 346, 513, 136, 424, 254, 476, 299, 457, 432, 255, 232, 133, 33, 88, 290, 44, 61, 199, 505, 525, 544, 340, 218, 302, 297, 73, 295, 35, 467, 29, 427, 446, 412, 309, 523, 217, 27, 469, 347, 156, 493, 409, 138, 212, 104, 414, 410, 416, 215, 521, 189, 214, 501, 204, 234, 259, 67, 24, 216, 300, 223, 129, 111, 166, 498, 470, 40, 274, 422, 79, 403, 468, 327, 13, 287, 326, 489, 251, 228, 415, 161, 83, 117, 25, 110, 149, 152, 16, 402, 331, 109, 417, 139, 237, 260, 352, 527, 317, 323, 477, 248, 389, 479, 19, 328, 296, 447, 269, 363, 226, 458, 3, 413, 125, 280, 286, 77, 184, 371, 461, 535, 275, 294, 517, 182, 32, 80, 307, 258, 11, 360, 440, 86, 266, 36, 193, 58, 41, 270, 411, 50, 209, 474, 473, 496, 123, 222, 419, 62, 449, 377, 130, 187, 23, 444, 43, 370, 394, 0, 383, 201, 405, 368, 522, 98, 387, 349, 304, 418, 292, 178, 369, 256, 94, 197, 95, 531, 163, 169, 69, 305, 48, 341, 373, 397, 207, 279, 509, 227, 148, 143, 334, 180, 356, 460, 131, 127, 47, 452, 262, 324, 203, 84, 426, 121, 539, 516, 530, 398, 384, 91, 82, 430, 267, 119, 358, 291, 57, 425, 487, 321, 257, 376, 31, 442, 42, 105, 388, 335, 273, 488, 53, 518, 128, 28, 183, 459, 510, 151, 244, 265, 288, 423, 147, 177, 99, 448, 431, 115, 72, 174, 87, 486, 314, 396, 472, 70, 277, 9, 359, 192, 1064, 1012, 998, 663, 1010, 712, 953, 551, 937, 791, 548, 866, 748, 628, 786, 790, 821, 572, 1052, 1049, 1007, 976, 685, 1070, 568, 693, 964, 982, 589, 799, 1041, 587, 794, 680, 635, 842, 737, 657, 851, 988, 898, 746, 569, 611, 1072, 1027, 930, 562, 672, 829, 640, 575, 800, 766, 967, 1063, 734, 854, 715, 844, 606, 760, 907, 947, 1087, 652, 694, 550, 793, 576, 843, 714, 816, 911, 1037, 879, 675, 1055, 987, 1019, 755, 642, 554, 653, 565, 647, 863, 874, 939, 1051, 658, 951, 968, 965, 709, 600, 940, 557, 660, 868, 1078, 833, 1089, 881, 553, 774, 1025, 776, 870, 736, 1033, 691, 855, 801, 1057, 1068, 960, 690, 607, 974, 798, 753, 761, 1043, 626, 952, 1003, 841, 1004, 700, 807, 999, 629, 838, 696, 639, 869, 991, 956, 641, 659, 605, 583, 689, 704, 586, 969, 941, 886, 759, 897, 782, 638, 932, 559, 958, 1077, 695, 972, 1036, 608, 625, 845, 739, 1001, 727, 1013, 989, 555, 996, 980, 1006, 853, 1085, 877, 950, 808, 552, 812, 803, 584, 697, 579, 1005, 817, 686, 1029, 740, 1061, 674, 1075, 1071, 957, 1031, 596, 708, 901, 1090, 914, 1032, 546, 856, 1038, 757, 718, 741, 977, 1008, 830, 669, 780, 585, 820, 1066, 702, 768, 822, 756, 890, 852, 763, 645, 835, 924, 713, 771, 650, 995, 556, 651, 614, 636, 1067, 919, 926, 1028, 779, 910, 918, 804, 811, 648, 850, 726, 889, 574, 588, 754, 566, 921, 1076, 630, 1044, 1073, 831, 1045, 617, 595, 725, 1069, 973, 662, 839, 622, 594, 1015, 809, 806, 692, 619, 992, 878, 610, 656, 598, 909, 1083, 955, 670, 633, 661, 1074, 834, 920, 848, 664, 558, 703, 883, 963, 673, 592, 781, 983, 681, 787, 899, 948, 707, 1056, 985, 723, 604, 710, 970, 871, 677, 698, 896, 993, 1023, 563, 934, 732, 743, 884, 752, 1080, 933, 891, 1021, 859, 788, 1079, 997, 716, 733, 593, 679, 847, 745, 618, 864, 624, 984, 620, 892, 942, 744, 935, 931, 929, 711, 665, 1040, 699, 946, 1016, 775, 975, 567, 827, 938, 796, 789, 783, 581, 1053, 1088, 875, 655, 925, 717, 784, 549, 836, 994, 867, 666, 701, 684, 671, 1002, 612, 720, 1054, 724, 767, 961, 646, 792, 765, 880]\n",
      "Val Idx:\n",
      "[85, 436, 96, 186, 134, 37, 450, 90, 502, 179, 140, 429, 66, 325, 285, 330, 196, 393, 137, 298, 407, 337, 503, 278, 230, 320, 175, 338, 162, 142, 451, 311, 261, 485, 113, 225, 242, 243, 15, 155, 380, 283, 17, 303, 475, 355, 353, 45, 532, 365, 456, 185, 406, 504, 512, 345, 438, 249, 433, 540, 224, 348, 108, 89, 401, 46, 102, 239, 21, 107, 315, 208, 103, 71, 75, 313, 78, 378, 357, 441, 379, 322, 310, 190, 236, 480, 219, 318, 381, 351, 157, 159, 276, 481, 492, 153, 268, 350, 1, 172, 12, 132, 390, 453, 434, 483, 245, 76, 229, 959, 1030, 887, 922, 876, 573, 917, 905, 865, 1039, 1062, 1058, 1020, 893, 1014, 772, 560, 903, 582, 637, 885, 1017, 826, 916, 1048, 615, 810, 928, 966, 1060, 616, 778, 872, 923, 764, 900, 936, 979, 1050, 735, 1091, 861, 832, 1035, 577, 873, 912, 578, 777, 986, 795, 621, 762, 785, 590, 602, 944, 742, 705, 631, 906, 580, 888, 846, 1082, 682, 773, 815, 1011, 1047, 915, 1046, 849, 1022, 688, 913, 721, 981, 954, 599, 564, 547, 758, 609, 769, 840, 818, 978, 728, 882, 654, 908, 747, 837, 927, 722, 824, 814, 862, 603, 632, 797, 1084, 949, 945, 613, 683, 601, 667]\n",
      "Test Idx:\n",
      "[312, 118, 400, 543, 202, 165, 508, 454, 264, 524, 455, 329, 375, 10, 482, 112, 282, 343, 293, 542, 65, 404, 126, 490, 545, 231, 213, 408, 194, 7, 507, 499, 494, 533, 471, 101, 97, 382, 54, 30, 364, 49, 100, 428, 362, 319, 399, 56, 144, 60, 6, 8, 354, 333, 823, 1024, 749, 813, 649, 1081, 1065, 1042, 561, 802, 904, 719, 770, 1000, 1026, 962, 805, 751, 943, 597, 729, 706, 902, 857, 591, 1018, 731, 571, 894, 738, 643, 1009, 750, 860, 895, 668, 1059, 644, 627, 687, 730, 623, 828, 990, 676, 858, 570, 678, 819, 971, 825, 634, 1086, 1034]\n",
      "[([386, 463, 206, 38, 188, 361, 339, 272, 289, 437, 462, 124, 154, 526, 59, 252, 466, 491, 541, 235, 211, 420, 55, 171, 233, 205, 158, 385, 34, 367, 18, 506, 247, 529, 52, 74, 26, 173, 92, 167, 4, 435, 181, 246, 443, 5, 141, 301, 200, 135, 263, 122, 22, 68, 210, 20, 306, 336, 14, 170, 374, 281, 271, 220, 537, 64, 520, 250, 120, 81, 421, 500, 240, 308, 534, 528, 160, 536, 238, 497, 484, 392, 478, 465, 51, 195, 191, 116, 342, 395, 164, 106, 372, 63, 511, 284, 519, 445, 316, 93, 366, 332, 198, 145, 150, 39, 495, 439, 253, 344, 464, 2, 221, 514, 146, 241, 538, 114, 391, 176, 168, 515, 346, 513, 136, 424, 254, 476, 299, 457, 432, 255, 232, 133, 33, 88, 290, 44, 61, 199, 505, 525, 544, 340, 218, 302, 297, 73, 295, 35, 467, 29, 427, 446, 412, 309, 523, 217, 27, 469, 347, 156, 493, 409, 138, 212, 104, 414, 410, 416, 215, 521, 189, 214, 501, 204, 234, 259, 67, 24, 216, 300, 223, 129, 111, 166, 498, 470, 40, 274, 422, 79, 403, 468, 327, 13, 287, 326, 489, 251, 228, 415, 161, 83, 117, 25, 110, 149, 152, 16, 402, 331, 109, 417, 139, 237, 260, 352, 527, 317, 323, 477, 248, 389, 479, 19, 328, 296, 447, 269, 363, 226, 458, 3, 413, 125, 280, 286, 77, 184, 371, 461, 535, 275, 294, 517, 182, 32, 80, 307, 258, 11, 360, 440, 86, 266, 36, 193, 58, 41, 270, 411, 50, 209, 474, 473, 496, 123, 222, 419, 62, 449, 377, 130, 187, 23, 444, 43, 370, 394, 0, 383, 201, 405, 368, 522, 98, 387, 349, 304, 418, 292, 178, 369, 256, 94, 197, 95, 531, 163, 169, 69, 305, 48, 341, 373, 397, 207, 279, 509, 227, 148, 143, 334, 180, 356, 460, 131, 127, 47, 452, 262, 324, 203, 84, 426, 121, 539, 516, 530, 398, 384, 91, 82, 430, 267, 119, 358, 291, 57, 425, 487, 321, 257, 376, 31, 442, 42, 105, 388, 335, 273, 488, 53, 518, 128, 28, 183, 459, 510, 151, 244, 265, 288, 423, 147, 177, 99, 448, 431, 115, 72, 174, 87, 486, 314, 396, 472, 70, 277, 9, 359, 192, 1064, 1012, 998, 663, 1010, 712, 953, 551, 937, 791, 548, 866, 748, 628, 786, 790, 821, 572, 1052, 1049, 1007, 976, 685, 1070, 568, 693, 964, 982, 589, 799, 1041, 587, 794, 680, 635, 842, 737, 657, 851, 988, 898, 746, 569, 611, 1072, 1027, 930, 562, 672, 829, 640, 575, 800, 766, 967, 1063, 734, 854, 715, 844, 606, 760, 907, 947, 1087, 652, 694, 550, 793, 576, 843, 714, 816, 911, 1037, 879, 675, 1055, 987, 1019, 755, 642, 554, 653, 565, 647, 863, 874, 939, 1051, 658, 951, 968, 965, 709, 600, 940, 557, 660, 868, 1078, 833, 1089, 881, 553, 774, 1025, 776, 870, 736, 1033, 691, 855, 801, 1057, 1068, 960, 690, 607, 974, 798, 753, 761, 1043, 626, 952, 1003, 841, 1004, 700, 807, 999, 629, 838, 696, 639, 869, 991, 956, 641, 659, 605, 583, 689, 704, 586, 969, 941, 886, 759, 897, 782, 638, 932, 559, 958, 1077, 695, 972, 1036, 608, 625, 845, 739, 1001, 727, 1013, 989, 555, 996, 980, 1006, 853, 1085, 877, 950, 808, 552, 812, 803, 584, 697, 579, 1005, 817, 686, 1029, 740, 1061, 674, 1075, 1071, 957, 1031, 596, 708, 901, 1090, 914, 1032, 546, 856, 1038, 757, 718, 741, 977, 1008, 830, 669, 780, 585, 820, 1066, 702, 768, 822, 756, 890, 852, 763, 645, 835, 924, 713, 771, 650, 995, 556, 651, 614, 636, 1067, 919, 926, 1028, 779, 910, 918, 804, 811, 648, 850, 726, 889, 574, 588, 754, 566, 921, 1076, 630, 1044, 1073, 831, 1045, 617, 595, 725, 1069, 973, 662, 839, 622, 594, 1015, 809, 806, 692, 619, 992, 878, 610, 656, 598, 909, 1083, 955, 670, 633, 661, 1074, 834, 920, 848, 664, 558, 703, 883, 963, 673, 592, 781, 983, 681, 787, 899, 948, 707, 1056, 985, 723, 604, 710, 970, 871, 677, 698, 896, 993, 1023, 563, 934, 732, 743, 884, 752, 1080, 933, 891, 1021, 859, 788, 1079, 997, 716, 733, 593, 679, 847, 745, 618, 864, 624, 984, 620, 892, 942, 744, 935, 931, 929, 711, 665, 1040, 699, 946, 1016, 775, 975, 567, 827, 938, 796, 789, 783, 581, 1053, 1088, 875, 655, 925, 717, 784, 549, 836, 994, 867, 666, 701, 684, 671, 1002, 612, 720, 1054, 724, 767, 961, 646, 792, 765, 880], [85, 436, 96, 186, 134, 37, 450, 90, 502, 179, 140, 429, 66, 325, 285, 330, 196, 393, 137, 298, 407, 337, 503, 278, 230, 320, 175, 338, 162, 142, 451, 311, 261, 485, 113, 225, 242, 243, 15, 155, 380, 283, 17, 303, 475, 355, 353, 45, 532, 365, 456, 185, 406, 504, 512, 345, 438, 249, 433, 540, 224, 348, 108, 89, 401, 46, 102, 239, 21, 107, 315, 208, 103, 71, 75, 313, 78, 378, 357, 441, 379, 322, 310, 190, 236, 480, 219, 318, 381, 351, 157, 159, 276, 481, 492, 153, 268, 350, 1, 172, 12, 132, 390, 453, 434, 483, 245, 76, 229, 959, 1030, 887, 922, 876, 573, 917, 905, 865, 1039, 1062, 1058, 1020, 893, 1014, 772, 560, 903, 582, 637, 885, 1017, 826, 916, 1048, 615, 810, 928, 966, 1060, 616, 778, 872, 923, 764, 900, 936, 979, 1050, 735, 1091, 861, 832, 1035, 577, 873, 912, 578, 777, 986, 795, 621, 762, 785, 590, 602, 944, 742, 705, 631, 906, 580, 888, 846, 1082, 682, 773, 815, 1011, 1047, 915, 1046, 849, 1022, 688, 913, 721, 981, 954, 599, 564, 547, 758, 609, 769, 840, 818, 978, 728, 882, 654, 908, 747, 837, 927, 722, 824, 814, 862, 603, 632, 797, 1084, 949, 945, 613, 683, 601, 667], [312, 118, 400, 543, 202, 165, 508, 454, 264, 524, 455, 329, 375, 10, 482, 112, 282, 343, 293, 542, 65, 404, 126, 490, 545, 231, 213, 408, 194, 7, 507, 499, 494, 533, 471, 101, 97, 382, 54, 30, 364, 49, 100, 428, 362, 319, 399, 56, 144, 60, 6, 8, 354, 333, 823, 1024, 749, 813, 649, 1081, 1065, 1042, 561, 802, 904, 719, 770, 1000, 1026, 962, 805, 751, 943, 597, 729, 706, 902, 857, 591, 1018, 731, 571, 894, 738, 643, 1009, 750, 860, 895, 668, 1059, 644, 627, 687, 730, 623, 828, 990, 676, 858, 570, 678, 819, 971, 825, 634, 1086, 1034])]\n",
      "2022-08-09 19:35:24 - (M) Train validation test splitted: 426 120 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-09 19:35:24 - (N) Train validation test splitted: 384 108 54\n",
      "2022-08-09 19:35:24 - (F) Train validation test splitted: 384 108 54\n",
      "2022-08-09 19:35:24 - (H) Train validation test splitted: 99 28 14\n",
      "2022-08-09 19:35:24 - (FN) Train validation test splitted: 766 218 108\n"
     ]
    }
   ],
   "source": [
    "fold = 1 #5\n",
    "mri_type = \"T1wCE\"\n",
    "batch_size = 1\n",
    "epochs = 15\n",
    "train_origins = [\"f\"]#[\"m\",\"n\",\"fn\",\"f\"]\n",
    "packs = generate_datasets([mri_type])\n",
    "loader_packs = get_loaders(packs, batch_size)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "#print(loader_packs['KLF']['m_dataloaders'])\n",
    "\n",
    "m_dataloader = loader_packs[mri_type]['m_dataloaders']#m_dataloaders[0]\n",
    "# Competition Train\n",
    "m_train_loader = m_dataloader[0]\n",
    "# Competition Val\n",
    "m_val_loader = m_dataloader[1]\n",
    "# Competition Test\n",
    "m_test_loader = m_dataloader[2]\n",
    "\n",
    "#t_dataloader = loader_packs[selected_type]['t_dataloaders']#t_dataloaders[0]\n",
    "# External Train\n",
    "#t_train_loader = t_dataloader[0]\n",
    "# External Val\n",
    "#t_val_loader = t_dataloader[1]\n",
    "# External Test\n",
    "#t_test_loader = t_dataloader[2]\n",
    "\n",
    "n_dataloader = loader_packs[mri_type]['n_dataloaders']#n_dataloaders[0]\n",
    "# UPENN Train\n",
    "n_train_loader = n_dataloader[0]\n",
    "# UPENN Val\n",
    "n_val_loader = n_dataloader[1]\n",
    "# UPENN Test\n",
    "n_test_loader = n_dataloader[2]\n",
    "\n",
    "#if selected_type == \"KLF\":\n",
    "f_dataloader = loader_packs[mri_type]['f_dataloaders']#f_dataloaders[0]\n",
    "# Competition (Tumor Only) Train\n",
    "f_train_loader = f_dataloader[0]\n",
    "# Competition (Tumor Only) Val\n",
    "f_val_loader = f_dataloader[1]\n",
    "# Competition (Tumor Only) Test\n",
    "f_test_loader = f_dataloader[2]\n",
    "\n",
    "h_dataloader = loader_packs[mri_type]['h_dataloaders']#h_dataloaders[0]\n",
    "# Competition (No Tumor) Train\n",
    "h_train_loader = h_dataloader[0]\n",
    "# Competition (No Tumor) Val\n",
    "h_val_loader = h_dataloader[1]\n",
    "# Competition (No Tumor) Test\n",
    "h_test_loader = h_dataloader[2]\n",
    "    \n",
    "fn_dataloader = loader_packs[mri_type]['fn_dataloaders']#fn_dataloaders[0]\n",
    "# Competition (Tumor Only) + UPENN Train\n",
    "fn_train_loader = fn_dataloader[0]\n",
    "# Competition (Tumor Only) + UPENN Val\n",
    "fn_val_loader = fn_dataloader[1]\n",
    "# Competition (Tumor Only) + UPENN Test\n",
    "fn_test_loader = fn_dataloader[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_T1wCE_1\n",
      "Type: T1wCE\n",
      "Length of concatenated dataset: 606\n",
      "Length of concatenated dataset: 606\n",
      "Train Idx:\n",
      "[238, 137, 106, 284, 44, 139, 247, 288, 156, 297, 252, 54, 234, 18, 205, 254, 182, 56, 71, 144, 249, 209, 290, 219, 158, 176, 33, 83, 136, 210, 118, 60, 159, 282, 110, 21, 29, 150, 16, 75, 109, 179, 283, 4, 96, 229, 61, 67, 295, 266, 171, 281, 40, 189, 13, 107, 200, 3, 161, 125, 24, 30, 77, 279, 190, 19, 257, 235, 268, 80, 51, 2, 239, 104, 262, 86, 10, 224, 58, 41, 14, 155, 50, 215, 237, 123, 220, 62, 191, 230, 130, 213, 187, 43, 114, 138, 199, 222, 149, 112, 298, 98, 221, 93, 208, 162, 36, 178, 113, 0, 94, 294, 95, 299, 263, 256, 69, 49, 48, 85, 300, 141, 207, 23, 250, 148, 143, 78, 180, 100, 204, 131, 269, 301, 196, 6, 68, 203, 84, 170, 121, 140, 258, 276, 142, 259, 91, 82, 285, 11, 119, 102, 35, 57, 169, 231, 65, 1, 120, 267, 186, 42, 105, 132, 79, 17, 271, 38, 53, 260, 128, 28, 183, 163, 151, 244, 202, 31, 32, 127, 185, 280, 273, 147, 278, 177, 99, 197, 243, 115, 265, 72, 25, 165, 289, 174, 291, 39, 193, 88, 70, 87, 292, 242, 277, 211, 9, 195, 251, 192, 117, 47, 172, 516, 380, 549, 365, 554, 536, 489, 433, 486, 369, 338, 320, 465, 589, 448, 528, 499, 348, 353, 360, 556, 547, 531, 544, 335, 381, 449, 436, 399, 517, 401, 505, 471, 392, 543, 561, 550, 435, 349, 500, 410, 473, 303, 542, 374, 579, 405, 370, 411, 525, 387, 584, 557, 428, 539, 412, 329, 484, 602, 545, 490, 437, 372, 402, 527, 521, 342, 496, 493, 432, 551, 443, 434, 564, 416, 321, 379, 495, 552, 414, 479, 312, 492, 462, 599, 346, 394, 407, 441, 478, 415, 371, 339, 513, 368, 345, 429, 306, 420, 451, 596, 580, 574, 431, 485, 440, 600, 310, 389, 482, 422, 569, 418, 464, 332, 458, 563, 488, 404, 400, 323, 456, 357, 333, 583, 352, 403, 565, 594, 454, 417, 359, 447, 363, 497, 535, 515, 502, 601, 309, 562, 311, 520, 382, 576, 511, 577, 546, 568, 470, 341, 373, 424, 582, 347, 603, 597, 480, 361, 466, 427, 457, 383, 362, 595, 351, 356, 461, 354, 575, 522, 377, 307, 442, 510, 590, 559, 308, 444, 364, 438, 386, 530, 325, 573, 523, 506, 423, 384, 316, 587, 375, 450, 463, 390, 541, 605, 439, 498, 494, 419, 327, 397, 467, 409, 319, 366, 408, 512, 331, 504, 477, 396]\n",
      "Val Idx:\n",
      "[225, 152, 228, 201, 52, 245, 175, 168, 223, 217, 111, 135, 218, 12, 15, 66, 97, 90, 198, 103, 22, 212, 226, 264, 133, 216, 275, 270, 154, 55, 194, 255, 134, 8, 157, 241, 240, 81, 214, 167, 5, 59, 92, 274, 34, 145, 116, 188, 246, 7, 45, 129, 122, 63, 124, 227, 146, 302, 26, 108, 560, 472, 367, 518, 487, 343, 514, 459, 588, 426, 524, 355, 538, 566, 395, 474, 425, 468, 558, 324, 567, 326, 591, 328, 592, 571, 337, 322, 314, 391, 421, 586, 453, 455, 508, 570, 491, 406, 501, 388, 378, 534, 452, 598, 385, 578, 315, 336, 581, 555, 413, 507, 334, 445, 529, 330, 340, 317, 604, 481]\n",
      "Test Idx:\n",
      "[89, 74, 153, 64, 296, 287, 286, 236, 126, 73, 20, 46, 160, 232, 181, 27, 173, 261, 37, 101, 166, 233, 184, 164, 206, 248, 253, 293, 76, 272, 305, 585, 304, 475, 476, 533, 548, 553, 344, 318, 393, 483, 532, 509, 540, 313, 430, 350, 526, 572, 460, 446, 398, 469, 537, 593, 358, 376, 519, 503]\n",
      "[([238, 137, 106, 284, 44, 139, 247, 288, 156, 297, 252, 54, 234, 18, 205, 254, 182, 56, 71, 144, 249, 209, 290, 219, 158, 176, 33, 83, 136, 210, 118, 60, 159, 282, 110, 21, 29, 150, 16, 75, 109, 179, 283, 4, 96, 229, 61, 67, 295, 266, 171, 281, 40, 189, 13, 107, 200, 3, 161, 125, 24, 30, 77, 279, 190, 19, 257, 235, 268, 80, 51, 2, 239, 104, 262, 86, 10, 224, 58, 41, 14, 155, 50, 215, 237, 123, 220, 62, 191, 230, 130, 213, 187, 43, 114, 138, 199, 222, 149, 112, 298, 98, 221, 93, 208, 162, 36, 178, 113, 0, 94, 294, 95, 299, 263, 256, 69, 49, 48, 85, 300, 141, 207, 23, 250, 148, 143, 78, 180, 100, 204, 131, 269, 301, 196, 6, 68, 203, 84, 170, 121, 140, 258, 276, 142, 259, 91, 82, 285, 11, 119, 102, 35, 57, 169, 231, 65, 1, 120, 267, 186, 42, 105, 132, 79, 17, 271, 38, 53, 260, 128, 28, 183, 163, 151, 244, 202, 31, 32, 127, 185, 280, 273, 147, 278, 177, 99, 197, 243, 115, 265, 72, 25, 165, 289, 174, 291, 39, 193, 88, 70, 87, 292, 242, 277, 211, 9, 195, 251, 192, 117, 47, 172, 516, 380, 549, 365, 554, 536, 489, 433, 486, 369, 338, 320, 465, 589, 448, 528, 499, 348, 353, 360, 556, 547, 531, 544, 335, 381, 449, 436, 399, 517, 401, 505, 471, 392, 543, 561, 550, 435, 349, 500, 410, 473, 303, 542, 374, 579, 405, 370, 411, 525, 387, 584, 557, 428, 539, 412, 329, 484, 602, 545, 490, 437, 372, 402, 527, 521, 342, 496, 493, 432, 551, 443, 434, 564, 416, 321, 379, 495, 552, 414, 479, 312, 492, 462, 599, 346, 394, 407, 441, 478, 415, 371, 339, 513, 368, 345, 429, 306, 420, 451, 596, 580, 574, 431, 485, 440, 600, 310, 389, 482, 422, 569, 418, 464, 332, 458, 563, 488, 404, 400, 323, 456, 357, 333, 583, 352, 403, 565, 594, 454, 417, 359, 447, 363, 497, 535, 515, 502, 601, 309, 562, 311, 520, 382, 576, 511, 577, 546, 568, 470, 341, 373, 424, 582, 347, 603, 597, 480, 361, 466, 427, 457, 383, 362, 595, 351, 356, 461, 354, 575, 522, 377, 307, 442, 510, 590, 559, 308, 444, 364, 438, 386, 530, 325, 573, 523, 506, 423, 384, 316, 587, 375, 450, 463, 390, 541, 605, 439, 498, 494, 419, 327, 397, 467, 409, 319, 366, 408, 512, 331, 504, 477, 396], [225, 152, 228, 201, 52, 245, 175, 168, 223, 217, 111, 135, 218, 12, 15, 66, 97, 90, 198, 103, 22, 212, 226, 264, 133, 216, 275, 270, 154, 55, 194, 255, 134, 8, 157, 241, 240, 81, 214, 167, 5, 59, 92, 274, 34, 145, 116, 188, 246, 7, 45, 129, 122, 63, 124, 227, 146, 302, 26, 108, 560, 472, 367, 518, 487, 343, 514, 459, 588, 426, 524, 355, 538, 566, 395, 474, 425, 468, 558, 324, 567, 326, 591, 328, 592, 571, 337, 322, 314, 391, 421, 586, 453, 455, 508, 570, 491, 406, 501, 388, 378, 534, 452, 598, 385, 578, 315, 336, 581, 555, 413, 507, 334, 445, 529, 330, 340, 317, 604, 481], [89, 74, 153, 64, 296, 287, 286, 236, 126, 73, 20, 46, 160, 232, 181, 27, 173, 261, 37, 101, 166, 233, 184, 164, 206, 248, 253, 293, 76, 272, 305, 585, 304, 475, 476, 533, 548, 553, 344, 318, 393, 483, 532, 509, 540, 313, 430, 350, 526, 572, 460, 446, 398, 469, 537, 593, 358, 376, 519, 503])]\n",
      "Length of concatenated dataset: 546\n",
      "Length of concatenated dataset: 546\n",
      "Train Idx:\n",
      "[33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441]\n",
      "Val Idx:\n",
      "[218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529]\n",
      "Test Idx:\n",
      "[201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358]\n",
      "[([33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441], [218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529], [201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358])]\n",
      "Length of concatenated dataset: 1092\n",
      "Length of concatenated dataset: 1092\n",
      "Train Idx:\n",
      "[386, 463, 206, 38, 188, 361, 339, 272, 289, 437, 462, 124, 154, 526, 59, 252, 466, 491, 541, 235, 211, 420, 55, 171, 233, 205, 158, 385, 34, 367, 18, 506, 247, 529, 52, 74, 26, 173, 92, 167, 4, 435, 181, 246, 443, 5, 141, 301, 200, 135, 263, 122, 22, 68, 210, 20, 306, 336, 14, 170, 374, 281, 271, 220, 537, 64, 520, 250, 120, 81, 421, 500, 240, 308, 534, 528, 160, 536, 238, 497, 484, 392, 478, 465, 51, 195, 191, 116, 342, 395, 164, 106, 372, 63, 511, 284, 519, 445, 316, 93, 366, 332, 198, 145, 150, 39, 495, 439, 253, 344, 464, 2, 221, 514, 146, 241, 538, 114, 391, 176, 168, 515, 346, 513, 136, 424, 254, 476, 299, 457, 432, 255, 232, 133, 33, 88, 290, 44, 61, 199, 505, 525, 544, 340, 218, 302, 297, 73, 295, 35, 467, 29, 427, 446, 412, 309, 523, 217, 27, 469, 347, 156, 493, 409, 138, 212, 104, 414, 410, 416, 215, 521, 189, 214, 501, 204, 234, 259, 67, 24, 216, 300, 223, 129, 111, 166, 498, 470, 40, 274, 422, 79, 403, 468, 327, 13, 287, 326, 489, 251, 228, 415, 161, 83, 117, 25, 110, 149, 152, 16, 402, 331, 109, 417, 139, 237, 260, 352, 527, 317, 323, 477, 248, 389, 479, 19, 328, 296, 447, 269, 363, 226, 458, 3, 413, 125, 280, 286, 77, 184, 371, 461, 535, 275, 294, 517, 182, 32, 80, 307, 258, 11, 360, 440, 86, 266, 36, 193, 58, 41, 270, 411, 50, 209, 474, 473, 496, 123, 222, 419, 62, 449, 377, 130, 187, 23, 444, 43, 370, 394, 0, 383, 201, 405, 368, 522, 98, 387, 349, 304, 418, 292, 178, 369, 256, 94, 197, 95, 531, 163, 169, 69, 305, 48, 341, 373, 397, 207, 279, 509, 227, 148, 143, 334, 180, 356, 460, 131, 127, 47, 452, 262, 324, 203, 84, 426, 121, 539, 516, 530, 398, 384, 91, 82, 430, 267, 119, 358, 291, 57, 425, 487, 321, 257, 376, 31, 442, 42, 105, 388, 335, 273, 488, 53, 518, 128, 28, 183, 459, 510, 151, 244, 265, 288, 423, 147, 177, 99, 448, 431, 115, 72, 174, 87, 486, 314, 396, 472, 70, 277, 9, 359, 192, 1064, 1012, 998, 663, 1010, 712, 953, 551, 937, 791, 548, 866, 748, 628, 786, 790, 821, 572, 1052, 1049, 1007, 976, 685, 1070, 568, 693, 964, 982, 589, 799, 1041, 587, 794, 680, 635, 842, 737, 657, 851, 988, 898, 746, 569, 611, 1072, 1027, 930, 562, 672, 829, 640, 575, 800, 766, 967, 1063, 734, 854, 715, 844, 606, 760, 907, 947, 1087, 652, 694, 550, 793, 576, 843, 714, 816, 911, 1037, 879, 675, 1055, 987, 1019, 755, 642, 554, 653, 565, 647, 863, 874, 939, 1051, 658, 951, 968, 965, 709, 600, 940, 557, 660, 868, 1078, 833, 1089, 881, 553, 774, 1025, 776, 870, 736, 1033, 691, 855, 801, 1057, 1068, 960, 690, 607, 974, 798, 753, 761, 1043, 626, 952, 1003, 841, 1004, 700, 807, 999, 629, 838, 696, 639, 869, 991, 956, 641, 659, 605, 583, 689, 704, 586, 969, 941, 886, 759, 897, 782, 638, 932, 559, 958, 1077, 695, 972, 1036, 608, 625, 845, 739, 1001, 727, 1013, 989, 555, 996, 980, 1006, 853, 1085, 877, 950, 808, 552, 812, 803, 584, 697, 579, 1005, 817, 686, 1029, 740, 1061, 674, 1075, 1071, 957, 1031, 596, 708, 901, 1090, 914, 1032, 546, 856, 1038, 757, 718, 741, 977, 1008, 830, 669, 780, 585, 820, 1066, 702, 768, 822, 756, 890, 852, 763, 645, 835, 924, 713, 771, 650, 995, 556, 651, 614, 636, 1067, 919, 926, 1028, 779, 910, 918, 804, 811, 648, 850, 726, 889, 574, 588, 754, 566, 921, 1076, 630, 1044, 1073, 831, 1045, 617, 595, 725, 1069, 973, 662, 839, 622, 594, 1015, 809, 806, 692, 619, 992, 878, 610, 656, 598, 909, 1083, 955, 670, 633, 661, 1074, 834, 920, 848, 664, 558, 703, 883, 963, 673, 592, 781, 983, 681, 787, 899, 948, 707, 1056, 985, 723, 604, 710, 970, 871, 677, 698, 896, 993, 1023, 563, 934, 732, 743, 884, 752, 1080, 933, 891, 1021, 859, 788, 1079, 997, 716, 733, 593, 679, 847, 745, 618, 864, 624, 984, 620, 892, 942, 744, 935, 931, 929, 711, 665, 1040, 699, 946, 1016, 775, 975, 567, 827, 938, 796, 789, 783, 581, 1053, 1088, 875, 655, 925, 717, 784, 549, 836, 994, 867, 666, 701, 684, 671, 1002, 612, 720, 1054, 724, 767, 961, 646, 792, 765, 880]\n",
      "Val Idx:\n",
      "[85, 436, 96, 186, 134, 37, 450, 90, 502, 179, 140, 429, 66, 325, 285, 330, 196, 393, 137, 298, 407, 337, 503, 278, 230, 320, 175, 338, 162, 142, 451, 311, 261, 485, 113, 225, 242, 243, 15, 155, 380, 283, 17, 303, 475, 355, 353, 45, 532, 365, 456, 185, 406, 504, 512, 345, 438, 249, 433, 540, 224, 348, 108, 89, 401, 46, 102, 239, 21, 107, 315, 208, 103, 71, 75, 313, 78, 378, 357, 441, 379, 322, 310, 190, 236, 480, 219, 318, 381, 351, 157, 159, 276, 481, 492, 153, 268, 350, 1, 172, 12, 132, 390, 453, 434, 483, 245, 76, 229, 959, 1030, 887, 922, 876, 573, 917, 905, 865, 1039, 1062, 1058, 1020, 893, 1014, 772, 560, 903, 582, 637, 885, 1017, 826, 916, 1048, 615, 810, 928, 966, 1060, 616, 778, 872, 923, 764, 900, 936, 979, 1050, 735, 1091, 861, 832, 1035, 577, 873, 912, 578, 777, 986, 795, 621, 762, 785, 590, 602, 944, 742, 705, 631, 906, 580, 888, 846, 1082, 682, 773, 815, 1011, 1047, 915, 1046, 849, 1022, 688, 913, 721, 981, 954, 599, 564, 547, 758, 609, 769, 840, 818, 978, 728, 882, 654, 908, 747, 837, 927, 722, 824, 814, 862, 603, 632, 797, 1084, 949, 945, 613, 683, 601, 667]\n",
      "Test Idx:\n",
      "[312, 118, 400, 543, 202, 165, 508, 454, 264, 524, 455, 329, 375, 10, 482, 112, 282, 343, 293, 542, 65, 404, 126, 490, 545, 231, 213, 408, 194, 7, 507, 499, 494, 533, 471, 101, 97, 382, 54, 30, 364, 49, 100, 428, 362, 319, 399, 56, 144, 60, 6, 8, 354, 333, 823, 1024, 749, 813, 649, 1081, 1065, 1042, 561, 802, 904, 719, 770, 1000, 1026, 962, 805, 751, 943, 597, 729, 706, 902, 857, 591, 1018, 731, 571, 894, 738, 643, 1009, 750, 860, 895, 668, 1059, 644, 627, 687, 730, 623, 828, 990, 676, 858, 570, 678, 819, 971, 825, 634, 1086, 1034]\n",
      "[([386, 463, 206, 38, 188, 361, 339, 272, 289, 437, 462, 124, 154, 526, 59, 252, 466, 491, 541, 235, 211, 420, 55, 171, 233, 205, 158, 385, 34, 367, 18, 506, 247, 529, 52, 74, 26, 173, 92, 167, 4, 435, 181, 246, 443, 5, 141, 301, 200, 135, 263, 122, 22, 68, 210, 20, 306, 336, 14, 170, 374, 281, 271, 220, 537, 64, 520, 250, 120, 81, 421, 500, 240, 308, 534, 528, 160, 536, 238, 497, 484, 392, 478, 465, 51, 195, 191, 116, 342, 395, 164, 106, 372, 63, 511, 284, 519, 445, 316, 93, 366, 332, 198, 145, 150, 39, 495, 439, 253, 344, 464, 2, 221, 514, 146, 241, 538, 114, 391, 176, 168, 515, 346, 513, 136, 424, 254, 476, 299, 457, 432, 255, 232, 133, 33, 88, 290, 44, 61, 199, 505, 525, 544, 340, 218, 302, 297, 73, 295, 35, 467, 29, 427, 446, 412, 309, 523, 217, 27, 469, 347, 156, 493, 409, 138, 212, 104, 414, 410, 416, 215, 521, 189, 214, 501, 204, 234, 259, 67, 24, 216, 300, 223, 129, 111, 166, 498, 470, 40, 274, 422, 79, 403, 468, 327, 13, 287, 326, 489, 251, 228, 415, 161, 83, 117, 25, 110, 149, 152, 16, 402, 331, 109, 417, 139, 237, 260, 352, 527, 317, 323, 477, 248, 389, 479, 19, 328, 296, 447, 269, 363, 226, 458, 3, 413, 125, 280, 286, 77, 184, 371, 461, 535, 275, 294, 517, 182, 32, 80, 307, 258, 11, 360, 440, 86, 266, 36, 193, 58, 41, 270, 411, 50, 209, 474, 473, 496, 123, 222, 419, 62, 449, 377, 130, 187, 23, 444, 43, 370, 394, 0, 383, 201, 405, 368, 522, 98, 387, 349, 304, 418, 292, 178, 369, 256, 94, 197, 95, 531, 163, 169, 69, 305, 48, 341, 373, 397, 207, 279, 509, 227, 148, 143, 334, 180, 356, 460, 131, 127, 47, 452, 262, 324, 203, 84, 426, 121, 539, 516, 530, 398, 384, 91, 82, 430, 267, 119, 358, 291, 57, 425, 487, 321, 257, 376, 31, 442, 42, 105, 388, 335, 273, 488, 53, 518, 128, 28, 183, 459, 510, 151, 244, 265, 288, 423, 147, 177, 99, 448, 431, 115, 72, 174, 87, 486, 314, 396, 472, 70, 277, 9, 359, 192, 1064, 1012, 998, 663, 1010, 712, 953, 551, 937, 791, 548, 866, 748, 628, 786, 790, 821, 572, 1052, 1049, 1007, 976, 685, 1070, 568, 693, 964, 982, 589, 799, 1041, 587, 794, 680, 635, 842, 737, 657, 851, 988, 898, 746, 569, 611, 1072, 1027, 930, 562, 672, 829, 640, 575, 800, 766, 967, 1063, 734, 854, 715, 844, 606, 760, 907, 947, 1087, 652, 694, 550, 793, 576, 843, 714, 816, 911, 1037, 879, 675, 1055, 987, 1019, 755, 642, 554, 653, 565, 647, 863, 874, 939, 1051, 658, 951, 968, 965, 709, 600, 940, 557, 660, 868, 1078, 833, 1089, 881, 553, 774, 1025, 776, 870, 736, 1033, 691, 855, 801, 1057, 1068, 960, 690, 607, 974, 798, 753, 761, 1043, 626, 952, 1003, 841, 1004, 700, 807, 999, 629, 838, 696, 639, 869, 991, 956, 641, 659, 605, 583, 689, 704, 586, 969, 941, 886, 759, 897, 782, 638, 932, 559, 958, 1077, 695, 972, 1036, 608, 625, 845, 739, 1001, 727, 1013, 989, 555, 996, 980, 1006, 853, 1085, 877, 950, 808, 552, 812, 803, 584, 697, 579, 1005, 817, 686, 1029, 740, 1061, 674, 1075, 1071, 957, 1031, 596, 708, 901, 1090, 914, 1032, 546, 856, 1038, 757, 718, 741, 977, 1008, 830, 669, 780, 585, 820, 1066, 702, 768, 822, 756, 890, 852, 763, 645, 835, 924, 713, 771, 650, 995, 556, 651, 614, 636, 1067, 919, 926, 1028, 779, 910, 918, 804, 811, 648, 850, 726, 889, 574, 588, 754, 566, 921, 1076, 630, 1044, 1073, 831, 1045, 617, 595, 725, 1069, 973, 662, 839, 622, 594, 1015, 809, 806, 692, 619, 992, 878, 610, 656, 598, 909, 1083, 955, 670, 633, 661, 1074, 834, 920, 848, 664, 558, 703, 883, 963, 673, 592, 781, 983, 681, 787, 899, 948, 707, 1056, 985, 723, 604, 710, 970, 871, 677, 698, 896, 993, 1023, 563, 934, 732, 743, 884, 752, 1080, 933, 891, 1021, 859, 788, 1079, 997, 716, 733, 593, 679, 847, 745, 618, 864, 624, 984, 620, 892, 942, 744, 935, 931, 929, 711, 665, 1040, 699, 946, 1016, 775, 975, 567, 827, 938, 796, 789, 783, 581, 1053, 1088, 875, 655, 925, 717, 784, 549, 836, 994, 867, 666, 701, 684, 671, 1002, 612, 720, 1054, 724, 767, 961, 646, 792, 765, 880], [85, 436, 96, 186, 134, 37, 450, 90, 502, 179, 140, 429, 66, 325, 285, 330, 196, 393, 137, 298, 407, 337, 503, 278, 230, 320, 175, 338, 162, 142, 451, 311, 261, 485, 113, 225, 242, 243, 15, 155, 380, 283, 17, 303, 475, 355, 353, 45, 532, 365, 456, 185, 406, 504, 512, 345, 438, 249, 433, 540, 224, 348, 108, 89, 401, 46, 102, 239, 21, 107, 315, 208, 103, 71, 75, 313, 78, 378, 357, 441, 379, 322, 310, 190, 236, 480, 219, 318, 381, 351, 157, 159, 276, 481, 492, 153, 268, 350, 1, 172, 12, 132, 390, 453, 434, 483, 245, 76, 229, 959, 1030, 887, 922, 876, 573, 917, 905, 865, 1039, 1062, 1058, 1020, 893, 1014, 772, 560, 903, 582, 637, 885, 1017, 826, 916, 1048, 615, 810, 928, 966, 1060, 616, 778, 872, 923, 764, 900, 936, 979, 1050, 735, 1091, 861, 832, 1035, 577, 873, 912, 578, 777, 986, 795, 621, 762, 785, 590, 602, 944, 742, 705, 631, 906, 580, 888, 846, 1082, 682, 773, 815, 1011, 1047, 915, 1046, 849, 1022, 688, 913, 721, 981, 954, 599, 564, 547, 758, 609, 769, 840, 818, 978, 728, 882, 654, 908, 747, 837, 927, 722, 824, 814, 862, 603, 632, 797, 1084, 949, 945, 613, 683, 601, 667], [312, 118, 400, 543, 202, 165, 508, 454, 264, 524, 455, 329, 375, 10, 482, 112, 282, 343, 293, 542, 65, 404, 126, 490, 545, 231, 213, 408, 194, 7, 507, 499, 494, 533, 471, 101, 97, 382, 54, 30, 364, 49, 100, 428, 362, 319, 399, 56, 144, 60, 6, 8, 354, 333, 823, 1024, 749, 813, 649, 1081, 1065, 1042, 561, 802, 904, 719, 770, 1000, 1026, 962, 805, 751, 943, 597, 729, 706, 902, 857, 591, 1018, 731, 571, 894, 738, 643, 1009, 750, 860, 895, 668, 1059, 644, 627, 687, 730, 623, 828, 990, 676, 858, 570, 678, 819, 971, 825, 634, 1086, 1034])]\n",
      "Length of concatenated dataset: 546\n",
      "Length of concatenated dataset: 546\n",
      "Train Idx:\n",
      "[33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441]\n",
      "Val Idx:\n",
      "[218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529]\n",
      "Test Idx:\n",
      "[201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358]\n",
      "[([33, 190, 245, 129, 253, 21, 237, 146, 16, 204, 75, 173, 135, 209, 179, 4, 96, 188, 61, 67, 52, 66, 26, 110, 233, 124, 268, 40, 13, 107, 145, 166, 3, 159, 24, 30, 252, 213, 60, 56, 248, 157, 46, 19, 212, 153, 54, 227, 80, 51, 2, 196, 104, 150, 86, 10, 168, 58, 41, 14, 50, 194, 123, 62, 158, 187, 130, 246, 154, 43, 221, 138, 254, 181, 149, 112, 207, 98, 180, 93, 171, 162, 36, 113, 0, 94, 95, 223, 69, 49, 48, 85, 270, 141, 23, 249, 143, 78, 100, 131, 228, 271, 6, 68, 84, 170, 121, 140, 214, 240, 234, 239, 91, 241, 257, 11, 119, 102, 35, 57, 169, 65, 1, 120, 226, 186, 42, 105, 132, 244, 17, 38, 133, 53, 164, 217, 128, 34, 28, 183, 114, 203, 163, 151, 202, 31, 232, 127, 185, 250, 260, 32, 167, 142, 236, 147, 29, 177, 216, 99, 82, 269, 175, 79, 197, 243, 208, 115, 148, 266, 72, 77, 25, 165, 81, 261, 174, 263, 39, 193, 88, 70, 87, 242, 211, 9, 195, 251, 192, 117, 47, 172, 413, 531, 485, 274, 430, 285, 426, 404, 451, 455, 349, 453, 308, 375, 416, 480, 425, 382, 304, 504, 524, 513, 435, 283, 320, 488, 496, 479, 462, 338, 315, 276, 385, 406, 481, 309, 465, 460, 407, 282, 386, 448, 280, 391, 359, 444, 392, 475, 388, 541, 374, 370, 469, 327, 303, 439, 322, 373, 478, 499, 542, 329, 333, 279, 281, 352, 467, 540, 432, 507, 311, 438, 394, 483, 535, 502, 442, 397, 427, 353, 332, 500, 321, 326, 343, 484, 519, 328, 509, 431, 544, 307, 390, 534, 510, 495, 325, 347, 299, 446, 525, 440, 277, 412, 454, 538, 273, 278, 414, 334, 408, 523, 395, 295, 341, 293, 511, 287, 443, 305, 543, 501, 476, 337, 456, 498, 393, 354, 331, 286, 489, 527, 345, 420, 433, 360, 396, 520, 532, 457, 409, 324, 468, 464, 389, 297, 367, 437, 379, 289, 336, 487, 401, 459, 378, 482, 508, 301, 346, 492, 497, 515, 362, 474, 422, 447, 366, 314, 450, 356, 316, 365, 291, 472, 471, 418, 423, 312, 364, 384, 526, 317, 342, 275, 494, 419, 514, 302, 387, 298, 449, 441], [218, 259, 225, 111, 178, 161, 89, 220, 55, 198, 265, 267, 210, 126, 97, 15, 8, 152, 59, 238, 45, 116, 247, 160, 63, 7, 92, 235, 206, 255, 144, 118, 103, 191, 73, 137, 230, 83, 64, 258, 101, 200, 272, 106, 27, 224, 189, 182, 219, 37, 231, 136, 20, 76, 318, 284, 402, 330, 357, 411, 503, 410, 372, 344, 323, 436, 505, 351, 533, 400, 398, 491, 376, 355, 415, 516, 363, 545, 521, 434, 539, 428, 288, 466, 518, 371, 537, 290, 335, 403, 493, 340, 350, 522, 528, 405, 429, 473, 296, 445, 377, 517, 424, 348, 477, 319, 463, 529], [201, 229, 134, 176, 5, 22, 199, 184, 12, 122, 215, 74, 44, 222, 125, 156, 155, 108, 18, 139, 256, 90, 71, 109, 205, 262, 264, 486, 310, 294, 383, 292, 369, 421, 361, 300, 461, 458, 339, 490, 512, 506, 399, 452, 380, 470, 306, 368, 313, 530, 417, 536, 381, 358])]\n",
      "SPLITS:\n",
      "- folds:\n",
      "1\n",
      "- splits per fold:\n",
      "3\n",
      "(F) Train validation splitted: 384 108\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.469, loss=0.713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 108/108 [00:08<00:00, 12.38it/s, batch_loss=0.46, loss=0.703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/15: Validation average loss: 0.7033604642859211 + AUC SCORE = 0.5171467764060356 + AUC SCORE THRESH 0.6122448979591836 = 0.5740740740740741\n",
      "Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:28<00:00,  4.34it/s, batch_loss=0.554, loss=0.709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.40it/s, batch_loss=0.688, loss=0.725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2/15: Validation average loss: 0.7250772489717713 + AUC SCORE = 0.5006858710562414 + AUC SCORE THRESH 0.7755102040816326 = 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:28<00:00,  4.33it/s, batch_loss=0.873, loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.32it/s, batch_loss=0.845, loss=0.715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3/15: Validation average loss: 0.7149383021449601 + AUC SCORE = 0.5006858710562414 + AUC SCORE THRESH 0.6938775510204082 = 0.5740740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 384/384 [01:28<00:00,  4.32it/s, batch_loss=0.53, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.28it/s, batch_loss=0.851, loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4/15: Validation average loss: 0.6989641236486258 + AUC SCORE = 0.46810699588477367 + AUC SCORE THRESH 0.5714285714285714 = 0.5277777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.593, loss=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 108/108 [00:08<00:00, 12.31it/s, batch_loss=0.692, loss=0.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5/15: Validation average loss: 0.6997826565746907 + AUC SCORE = 0.4619341563786008 + AUC SCORE THRESH 0.6122448979591836 = 0.5740740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.634, loss=0.671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.31it/s, batch_loss=0.629, loss=0.716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6/15: Validation average loss: 0.715678444063222 + AUC SCORE = 0.448559670781893 + AUC SCORE THRESH 0.5306122448979591 = 0.5462962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.651, loss=0.665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.32it/s, batch_loss=0.584, loss=0.782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 7/15: Validation average loss: 0.7819199589667497 + AUC SCORE = 0.44890260631001366 + AUC SCORE THRESH 0.32653061224489793 = 0.5092592592592593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.917, loss=0.657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 108/108 [00:08<00:00, 12.32it/s, batch_loss=3.38, loss=0.968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 8/15: Validation average loss: 0.9679068962663964 + AUC SCORE = 0.5216049382716049 + AUC SCORE THRESH 0.9183673469387754 = 0.5740740740740741\n",
      "Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.765, loss=0.702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 108/108 [00:08<00:00, 12.27it/s, batch_loss=0.767, loss=0.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 9/15: Validation average loss: 0.8396988351898337 + AUC SCORE = 0.49965706447187924 + AUC SCORE THRESH 0.8571428571428571 = 0.5740740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.793, loss=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.30it/s, batch_loss=0.878, loss=0.951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 10/15: Validation average loss: 0.9513975078071881 + AUC SCORE = 0.48079561042524005 + AUC SCORE THRESH 0.9387755102040816 = 0.5833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.504, loss=0.686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.29it/s, batch_loss=0.824, loss=0.869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 11/15: Validation average loss: 0.8690216263273248 + AUC SCORE = 0.4783950617283951 + AUC SCORE THRESH 0.8979591836734693 = 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.789, loss=0.668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.28it/s, batch_loss=0.849, loss=0.714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 12/15: Validation average loss: 0.7139648172866415 + AUC SCORE = 0.48731138545953356 + AUC SCORE THRESH 0.6122448979591836 = 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=1.06, loss=0.649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:08<00:00, 12.29it/s, batch_loss=0.00338, loss=0.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 13/15: Validation average loss: 0.9499226041220094 + AUC SCORE = 0.4591906721536351 + AUC SCORE THRESH 0.9387755102040816 = 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.515, loss=0.636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.28it/s, batch_loss=0.778, loss=0.848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 14/15: Validation average loss: 0.8481016096020876 + AUC SCORE = 0.46570644718792864 + AUC SCORE THRESH 0.8571428571428571 = 0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 384/384 [01:29<00:00,  4.31it/s, batch_loss=0.344, loss=0.622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 108/108 [00:08<00:00, 12.25it/s, batch_loss=0.416, loss=0.917]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 15/15: Validation average loss: 0.9166451604278 + AUC SCORE = 0.4646776406035665 + AUC SCORE THRESH 0.9183673469387754 = 0.5740740740740741\n",
      "0.5216049382716049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_folded_models(fold, mri_type, \"resnet10\", batch_size, epochs, train_origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y, y_pred, y_prob, name):\n",
    "    auc = roc_auc_score(y, y_prob)\n",
    "    acc = [1 if yy == out else 0 for (yy,out) in zip(y,y_pred)].count(1)/len(y_pred)\n",
    "    total_0_count = y.count(0)\n",
    "    total_1_count = y.count(1)\n",
    "    total_1_pred_count = list(y_pred).count(1)\n",
    "    true_0 = [1 if yy == out and yy == 0 else 0 for (yy,out) in zip(y,y_pred)].count(1)\n",
    "    true_1 = [1 if yy == out and yy == 1 else 0 for (yy,out) in zip(y,y_pred)].count(1)\n",
    "    spec = true_0/total_0_count\n",
    "    sens = true_1/total_1_count\n",
    "    if total_1_pred_count != 0:\n",
    "        prec = true_1/total_1_pred_count\n",
    "    else:\n",
    "        prec = 0\n",
    "    print(f\"Prediction AUC: {auc:.4f}\")\n",
    "    print(f\"Prediction Accuracy: {acc:.4f}\")\n",
    "    print(f\"Prediction Specificity: {spec:.4f}\")\n",
    "    print(f\"Prediction Sensitivity: {sens:.4f}\")\n",
    "    print(f\"Prediction Precision: {prec:.4f}\")\n",
    "    return pd.DataFrame({\"model\": [name], \"AUC\": [auc], \"acc\": [acc], \"spec\": [spec], \"sens\": [sens], \"prec\": [prec]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(filepath, test_dl):\n",
    "    modelname = os.path.basename(filepath)\n",
    "    model = monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/{filepath}\"))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred = [] #y_pred\n",
    "        preds = [] #y_prob\n",
    "        true_labels = [] #y\n",
    "        case_ids = []\n",
    "        epoch_iterator_test = tqdm(test_dl)\n",
    "        for step, batch in enumerate(epoch_iterator_test):\n",
    "            model.eval()\n",
    "            (img_ids, imgs, labels) = batch\n",
    "            images, targets = imgs[0].to(device), labels.to(device)\n",
    "            #images, targets = batch[\"image\"].to(device), batch[\"target\"].to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            targets = targets  # .view(-1, 1)\n",
    "\n",
    "            preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "            true_labels.append(targets.cpu().numpy())\n",
    "            predicted = (outputs>0.5).int()\n",
    "            predicted = torch.reshape(predicted, (-1,))\n",
    "\n",
    "            y_pred.extend(predicted.tolist())\n",
    "            #case_ids.append(batch[\"case_id\"])\n",
    "            if img_ids[0][0][0].isnumeric():\n",
    "                img_ids_fixed = [img_id[:5] for img_id in img_ids[0]]\n",
    "            else:\n",
    "                img_ids_fixed = [img_id[:-4] for img_id in img_ids[0]]\n",
    "            case_ids.append(img_ids_fixed)\n",
    "    preds = np.vstack(preds).T[0].tolist()\n",
    "    true_labels = np.hstack(true_labels).tolist()\n",
    "    case_ids = np.hstack(case_ids).tolist()\n",
    "    auc_score = roc_auc_score(true_labels, preds)\n",
    "    preddf = get_metrics(true_labels, y_pred, preds, modelname)\n",
    "    return preddf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [00:04<00:00, 12.46it/s]\n",
      "/tmp/ipykernel_2843398/4121842239.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.3856\n",
      "Prediction Accuracy: 0.4333\n",
      "Prediction Specificity: 0.7000\n",
      "Prediction Sensitivity: 0.1667\n",
      "Prediction Precision: 0.3571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [00:04<00:00, 12.52it/s]\n",
      "/tmp/ipykernel_2843398/4121842239.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.5444\n",
      "Prediction Accuracy: 0.5000\n",
      "Prediction Specificity: 1.0000\n",
      "Prediction Sensitivity: 0.0000\n",
      "Prediction Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [00:04<00:00, 12.40it/s]\n",
      "/tmp/ipykernel_2843398/4121842239.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.6856\n",
      "Prediction Accuracy: 0.5000\n",
      "Prediction Specificity: 1.0000\n",
      "Prediction Sensitivity: 0.0000\n",
      "Prediction Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [00:04<00:00, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.3156\n",
      "Prediction Accuracy: 0.3667\n",
      "Prediction Specificity: 0.0000\n",
      "Prediction Sensitivity: 0.7333\n",
      "Prediction Precision: 0.4231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_2843398/4121842239.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    \"resnet10_m_Aug09_17-26-02/3d-resnet10_m_T1wCE_fold0_0.49.pth\", #m\n",
    "    \"resnet10_n_Aug09_17-52-43/3d-resnet10_n_T1wCE_fold0_0.518.pth\", #n\n",
    "    \"resnet10_fn_Aug09_18-39-12/3d-resnet10_fn_T1wCE_fold0_0.577.pth\", #f\n",
    "    \"resnet10_f_Aug09_19-48-33/3d-resnet10_f_T1wCE_fold0_0.522.pth\" #fn\n",
    "]\n",
    "metrics = pd.DataFrame({\"model\": [], \"AUC\": [], \"acc\": [], \"spec\": [], \"sens\": [], \"prec\": []})\n",
    "for filepath in paths:\n",
    "    test_loader = m_test_loader\n",
    "    preddf = test_model(filepath, test_loader)\n",
    "    metrics = metrics.append(preddf, ignore_index=True)\n",
    "    \n",
    "metrics.to_csv(f\"tunisiaai_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 54/54 [00:04<00:00, 12.32it/s]\n",
      "/tmp/ipykernel_2843398/1426414694.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.6269\n",
      "Prediction Accuracy: 0.5741\n",
      "Prediction Specificity: 1.0000\n",
      "Prediction Sensitivity: 0.1481\n",
      "Prediction Precision: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 54/54 [00:04<00:00, 12.42it/s]\n",
      "/tmp/ipykernel_2843398/1426414694.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.2853\n",
      "Prediction Accuracy: 0.5000\n",
      "Prediction Specificity: 1.0000\n",
      "Prediction Sensitivity: 0.0000\n",
      "Prediction Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 54/54 [00:04<00:00, 12.36it/s]\n",
      "/tmp/ipykernel_2843398/1426414694.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.3923\n",
      "Prediction Accuracy: 0.5000\n",
      "Prediction Specificity: 1.0000\n",
      "Prediction Sensitivity: 0.0000\n",
      "Prediction Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 54/54 [00:04<00:00, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction AUC: 0.6283\n",
      "Prediction Accuracy: 0.4815\n",
      "Prediction Specificity: 0.2593\n",
      "Prediction Sensitivity: 0.7037\n",
      "Prediction Precision: 0.4872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_2843398/1426414694.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append(preddf, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    \"resnet10_m_Aug09_17-26-02/3d-resnet10_m_T1wCE_fold0_0.49.pth\", #m\n",
    "    \"resnet10_n_Aug09_17-52-43/3d-resnet10_n_T1wCE_fold0_0.518.pth\", #n\n",
    "    \"resnet10_fn_Aug09_18-39-12/3d-resnet10_fn_T1wCE_fold0_0.577.pth\", #f\n",
    "    \"resnet10_f_Aug09_19-48-33/3d-resnet10_f_T1wCE_fold0_0.522.pth\" #fn\n",
    "]\n",
    "metrics = pd.DataFrame({\"model\": [], \"AUC\": [], \"acc\": [], \"spec\": [], \"sens\": [], \"prec\": []})\n",
    "for filepath in paths:\n",
    "    test_loader = n_test_loader\n",
    "    preddf = test_model(filepath, test_loader)\n",
    "    metrics = metrics.append(preddf, ignore_index=True)\n",
    "    \n",
    "metrics.to_csv(f\"tunisiaai_metrics_n.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
