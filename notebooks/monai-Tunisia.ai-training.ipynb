{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../rsnaresnet10/working/create_folds.py --n_folds 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_T1wCE_0\n",
      "Loading the best images indexes for all the cases...\n",
      "Loading the best images indexes for all the cases...\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-28 23:07:22.170950: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [03:47<00:00,  1.94s/it, batch_loss=0.506, loss=0.714]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:41<00:00,  1.39s/it, batch_loss=0.137, loss=0.701]\n",
      "EPOCH 0/15: Validation average loss: 0.7012121265133222 + AUC SCORE = 0.5387096774193548 + AUC SCORE THRESH 0.6938775510204082 = 0.5472140762463343\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [09:47<00:00,  5.02s/it, batch_loss=0.705, loss=0.709]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:46<00:00,  1.57s/it, batch_loss=0.558, loss=0.692]\n",
      "EPOCH 1/15: Validation average loss: 0.6924694299697876 + AUC SCORE = 0.49149560117302055 + AUC SCORE THRESH 0.5102040816326531 = 0.5304985337243402\n",
      "100%|███████████| 117/117 [10:55<00:00,  5.60s/it, batch_loss=0.692, loss=0.696]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:52<00:00,  1.76s/it, batch_loss=0.738, loss=0.689]\n",
      "EPOCH 2/15: Validation average loss: 0.6894651691118876 + AUC SCORE = 0.5390029325513197 + AUC SCORE THRESH 0.5306122448979591 = 0.5558651026392962\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [10:58<00:00,  5.63s/it, batch_loss=0.619, loss=0.693]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.97s/it, batch_loss=0.189, loss=0.738]\n",
      "EPOCH 3/15: Validation average loss: 0.7383265644311905 + AUC SCORE = 0.5167155425219941 + AUC SCORE THRESH 0.42857142857142855 = 0.5582111436950148\n",
      "100%|███████████| 117/117 [11:19<00:00,  5.80s/it, batch_loss=0.596, loss=0.693]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.79s/it, batch_loss=0.961, loss=0.699]\n",
      "EPOCH 4/15: Validation average loss: 0.6985847502946854 + AUC SCORE = 0.5384164222873901 + AUC SCORE THRESH 0.5306122448979591 = 0.5577712609970674\n",
      "100%|███████████| 117/117 [11:15<00:00,  5.78s/it, batch_loss=0.623, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|███████████████| 30/30 [00:58<00:00,  1.95s/it, batch_loss=1.4, loss=0.744]\n",
      "EPOCH 5/15: Validation average loss: 0.7437388370434443 + AUC SCORE = 0.5428152492668622 + AUC SCORE THRESH 0.6326530612244897 = 0.5759530791788856\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:16<00:00,  5.78s/it, batch_loss=0.568, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:54<00:00,  1.81s/it, batch_loss=1.23, loss=0.767]\n",
      "EPOCH 6/15: Validation average loss: 0.766578687230746 + AUC SCORE = 0.5126099706744868 + AUC SCORE THRESH 0.673469387755102 = 0.5639296187683285\n",
      "100%|███████████| 117/117 [11:03<00:00,  5.67s/it, batch_loss=0.766, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|████████████████| 30/30 [01:01<00:00,  2.05s/it, batch_loss=0.68, loss=0.7]\n",
      "EPOCH 7/15: Validation average loss: 0.6997993469238282 + AUC SCORE = 0.5249266862170088 + AUC SCORE THRESH 0.5714285714285714 = 0.5501466275659824\n",
      "100%|███████████| 117/117 [11:11<00:00,  5.74s/it, batch_loss=0.686, loss=0.682]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.94s/it, batch_loss=0.915, loss=0.765]\n",
      "EPOCH 8/15: Validation average loss: 0.7648158838351568 + AUC SCORE = 0.46920821114369504 + AUC SCORE THRESH 0.673469387755102 = 0.5335777126099707\n",
      "100%|████████████| 117/117 [11:10<00:00,  5.73s/it, batch_loss=0.61, loss=0.675]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.95s/it, batch_loss=0.605, loss=0.796]\n",
      "EPOCH 9/15: Validation average loss: 0.7956684321165085 + AUC SCORE = 0.5457478005865103 + AUC SCORE THRESH 0.5102040816326531 = 0.5784457478005864\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:18<00:00,  5.80s/it, batch_loss=0.645, loss=0.679]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|███████████████| 30/30 [00:54<00:00,  1.82s/it, batch_loss=0.611, loss=0.7]\n",
      "EPOCH 10/15: Validation average loss: 0.6997048377990722 + AUC SCORE = 0.506158357771261 + AUC SCORE THRESH 0.5306122448979591 = 0.5416422287390029\n",
      "100%|███████████| 117/117 [11:29<00:00,  5.89s/it, batch_loss=0.658, loss=0.669]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.95s/it, batch_loss=0.617, loss=0.701]\n",
      "EPOCH 11/15: Validation average loss: 0.7005097776651382 + AUC SCORE = 0.5099706744868034 + AUC SCORE THRESH 0.5102040816326531 = 0.5587976539589443\n",
      "100%|████████████| 117/117 [11:27<00:00,  5.87s/it, batch_loss=0.825, loss=0.67]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.705, loss=0.726]\n",
      "EPOCH 12/15: Validation average loss: 0.7262069682280222 + AUC SCORE = 0.4501466275659824 + AUC SCORE THRESH 0.7142857142857142 = 0.52316715542522\n",
      "100%|███████████| 117/117 [11:34<00:00,  5.93s/it, batch_loss=0.668, loss=0.662]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.376, loss=0.709]\n",
      "EPOCH 13/15: Validation average loss: 0.7085824747880299 + AUC SCORE = 0.4436950146627566 + AUC SCORE THRESH 0.36734693877551017 = 0.5303519061583578\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.547, loss=0.647]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:59<00:00,  1.99s/it, batch_loss=0.999, loss=0.724]\n",
      "EPOCH 14/15: Validation average loss: 0.7243539830048878 + AUC SCORE = 0.4838709677419355 + AUC SCORE THRESH 0.4897959183673469 = 0.5375366568914957\n",
      "0.5457478005865103\n",
      "train_T1wCE_1\n",
      "Loading the best images indexes for all the cases...\n",
      "Loading the best images indexes for all the cases...\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 02:01:30.486845: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|████████████| 117/117 [11:25<00:00,  5.86s/it, batch_loss=0.835, loss=0.74]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.524, loss=0.692]\n",
      "EPOCH 0/15: Validation average loss: 0.6922847022612889 + AUC SCORE = 0.5859237536656892 + AUC SCORE THRESH 0.6530612244897959 = 0.5913489736070381\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:29<00:00,  5.89s/it, batch_loss=0.763, loss=0.705]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:59<00:00,  1.97s/it, batch_loss=1.07, loss=0.768]\n",
      "EPOCH 1/15: Validation average loss: 0.7676209251085917 + AUC SCORE = 0.5782991202346042 + AUC SCORE THRESH 0.3877551020408163 = 0.6013196480938416\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.725, loss=0.694]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.79s/it, batch_loss=0.699, loss=0.693]\n",
      "EPOCH 2/15: Validation average loss: 0.6932193716367085 + AUC SCORE = 0.547800586510264 + AUC SCORE THRESH 0.5714285714285714 = 0.6155425219941348\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.778, loss=0.695]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.92s/it, batch_loss=0.899, loss=0.706]\n",
      "EPOCH 3/15: Validation average loss: 0.7055632929007213 + AUC SCORE = 0.5363636363636364 + AUC SCORE THRESH 0.5306122448979591 = 0.5590909090909091\n",
      "100%|███████████| 117/117 [11:34<00:00,  5.94s/it, batch_loss=0.712, loss=0.686]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:59<00:00,  1.97s/it, batch_loss=0.974, loss=0.711]\n",
      "EPOCH 4/15: Validation average loss: 0.7113186558087666 + AUC SCORE = 0.5129032258064516 + AUC SCORE THRESH 0.4897959183673469 = 0.5439882697947215\n",
      "100%|████████████| 117/117 [11:33<00:00,  5.93s/it, batch_loss=0.695, loss=0.69]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.98, loss=0.714]\n",
      "EPOCH 5/15: Validation average loss: 0.7143624901771546 + AUC SCORE = 0.48856304985337246 + AUC SCORE THRESH 0.4693877551020408 = 0.5598240469208211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████| 117/117 [11:33<00:00,  5.93s/it, batch_loss=0.606, loss=0.685]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|███████████████| 30/30 [01:00<00:00,  2.02s/it, batch_loss=0.738, loss=0.7]\n",
      "EPOCH 6/15: Validation average loss: 0.7001098175843556 + AUC SCORE = 0.5683284457478006 + AUC SCORE THRESH 0.5102040816326531 = 0.569941348973607\n",
      "100%|███████████| 117/117 [11:19<00:00,  5.81s/it, batch_loss=0.719, loss=0.682]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [01:04<00:00,  2.16s/it, batch_loss=1.13, loss=0.723]\n",
      "EPOCH 7/15: Validation average loss: 0.7226691484451294 + AUC SCORE = 0.5624633431085043 + AUC SCORE THRESH 0.4081632653061224 = 0.5649560117302054\n",
      "100%|████████████| 117/117 [11:25<00:00,  5.86s/it, batch_loss=0.59, loss=0.681]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.03s/it, batch_loss=0.661, loss=0.709]\n",
      "EPOCH 8/15: Validation average loss: 0.7088729550441106 + AUC SCORE = 0.48651026392961877 + AUC SCORE THRESH 0.5102040816326531 = 0.5587976539589443\n",
      "100%|███████████| 117/117 [11:24<00:00,  5.85s/it, batch_loss=0.727, loss=0.675]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.92s/it, batch_loss=0.832, loss=0.713]\n",
      "EPOCH 9/15: Validation average loss: 0.7130532304445902 + AUC SCORE = 0.4988269794721407 + AUC SCORE THRESH 0.5510204081632653 = 0.5611436950146628\n",
      "100%|████████████| 117/117 [11:37<00:00,  5.96s/it, batch_loss=0.547, loss=0.65]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|██████████████| 30/30 [00:52<00:00,  1.76s/it, batch_loss=0.48, loss=0.722]\n",
      "EPOCH 10/15: Validation average loss: 0.7216970870892206 + AUC SCORE = 0.4683284457478005 + AUC SCORE THRESH 0.36734693877551017 = 0.5181818181818182\n",
      "100%|████████████| 117/117 [11:34<00:00,  5.93s/it, batch_loss=0.839, loss=0.64]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:56<00:00,  1.89s/it, batch_loss=0.826, loss=0.752]\n",
      "EPOCH 11/15: Validation average loss: 0.7520661314328512 + AUC SCORE = 0.4516129032258065 + AUC SCORE THRESH 0.26530612244897955 = 0.5101173020527859\n",
      "100%|███████████| 117/117 [11:31<00:00,  5.91s/it, batch_loss=0.539, loss=0.621]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:55<00:00,  1.85s/it, batch_loss=0.374, loss=0.737]\n",
      "EPOCH 12/15: Validation average loss: 0.7371406267086665 + AUC SCORE = 0.4718475073313783 + AUC SCORE THRESH 0.44897959183673464 = 0.5385630498533724\n",
      "100%|███████████| 117/117 [11:32<00:00,  5.92s/it, batch_loss=0.486, loss=0.598]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.01s/it, batch_loss=0.675, loss=0.778]\n",
      "EPOCH 13/15: Validation average loss: 0.7776127388079961 + AUC SCORE = 0.48621700879765395 + AUC SCORE THRESH 0.7346938775510203 = 0.5381231671554252\n",
      "100%|████████████| 117/117 [11:25<00:00,  5.86s/it, batch_loss=0.34, loss=0.569]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.03s/it, batch_loss=0.644, loss=0.888]\n",
      "EPOCH 14/15: Validation average loss: 0.8879576275746027 + AUC SCORE = 0.4967741935483871 + AUC SCORE THRESH 0.8775510204081632 = 0.5260997067448681\n",
      "0.5859237536656892\n",
      "train_T1wCE_2\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 468/468 [01:09<00:00,  6.74it/s]\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 117/117 [00:15<00:00,  7.36it/s]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 05:10:09.547425: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [07:09<00:00,  3.67s/it, batch_loss=0.624, loss=0.723]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|███████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.559, loss=0.9]\n",
      "EPOCH 0/15: Validation average loss: 0.9003540525833765 + AUC SCORE = 0.5172716627634661 + AUC SCORE THRESH 0.5102040816326531 = 0.5522540983606558\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [11:29<00:00,  5.89s/it, batch_loss=0.555, loss=0.703]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.73s/it, batch_loss=0.882, loss=0.743]\n",
      "EPOCH 1/15: Validation average loss: 0.7425178209940593 + AUC SCORE = 0.5529859484777517 + AUC SCORE THRESH 0.5918367346938775 = 0.5651346604215457\n",
      "Saving the model...\n",
      "100%|████████████| 117/117 [11:23<00:00,  5.84s/it, batch_loss=0.891, loss=0.69]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:56<00:00,  1.88s/it, batch_loss=0.55, loss=0.802]\n",
      "EPOCH 2/15: Validation average loss: 0.8022603332996369 + AUC SCORE = 0.5283957845433256 + AUC SCORE THRESH 0.4897959183673469 = 0.5440573770491803\n",
      "100%|███████████| 117/117 [11:22<00:00,  5.84s/it, batch_loss=0.712, loss=0.693]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.93s/it, batch_loss=0.711, loss=0.729]\n",
      "EPOCH 3/15: Validation average loss: 0.7292274077733357 + AUC SCORE = 0.4997072599531616 + AUC SCORE THRESH 0.5102040816326531 = 0.5642564402810304\n",
      "100%|███████████| 117/117 [11:17<00:00,  5.79s/it, batch_loss=0.765, loss=0.692]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:55<00:00,  1.85s/it, batch_loss=0.725, loss=0.809]\n",
      "EPOCH 4/15: Validation average loss: 0.8094078809022903 + AUC SCORE = 0.5117096018735362 + AUC SCORE THRESH 0.5714285714285714 = 0.5418618266978923\n",
      "100%|███████████| 117/117 [11:27<00:00,  5.88s/it, batch_loss=0.748, loss=0.691]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [01:02<00:00,  2.09s/it, batch_loss=0.607, loss=0.694]\n",
      "EPOCH 5/15: Validation average loss: 0.6943311750888824 + AUC SCORE = 0.527224824355972 + AUC SCORE THRESH 0.5714285714285714 = 0.5715749414519906\n",
      "100%|███████████| 117/117 [11:05<00:00,  5.69s/it, batch_loss=0.697, loss=0.689]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:58<00:00,  1.97s/it, batch_loss=0.577, loss=0.713]\n",
      "EPOCH 6/15: Validation average loss: 0.7127797623475393 + AUC SCORE = 0.5456674473067915 + AUC SCORE THRESH 0.4693877551020408 = 0.5636709601873536\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.656, loss=0.685]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:55<00:00,  1.86s/it, batch_loss=0.48, loss=0.724]\n",
      "EPOCH 7/15: Validation average loss: 0.7241149435440699 + AUC SCORE = 0.5204918032786885 + AUC SCORE THRESH 0.5102040816326531 = 0.5447892271662764\n",
      "100%|████████████| 117/117 [11:06<00:00,  5.70s/it, batch_loss=0.604, loss=0.68]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:50<00:00,  1.69s/it, batch_loss=0.79, loss=0.736]\n",
      "EPOCH 8/15: Validation average loss: 0.7357085029284159 + AUC SCORE = 0.5333723653395784 + AUC SCORE THRESH 0.5714285714285714 = 0.5509367681498829\n",
      "100%|███████████| 117/117 [11:05<00:00,  5.69s/it, batch_loss=0.789, loss=0.681]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:52<00:00,  1.77s/it, batch_loss=0.692, loss=0.707]\n",
      "EPOCH 9/15: Validation average loss: 0.7074600338935852 + AUC SCORE = 0.514344262295082 + AUC SCORE THRESH 0.5510204081632653 = 0.5620608899297423\n",
      "100%|███████████| 117/117 [10:58<00:00,  5.62s/it, batch_loss=0.675, loss=0.679]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:48<00:00,  1.62s/it, batch_loss=0.578, loss=0.697]\n",
      "EPOCH 10/15: Validation average loss: 0.6972469369570414 + AUC SCORE = 0.5196135831381733 + AUC SCORE THRESH 0.5714285714285714 = 0.5493266978922716\n",
      "100%|███████████| 117/117 [10:51<00:00,  5.57s/it, batch_loss=0.791, loss=0.675]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.566, loss=0.702]\n",
      "EPOCH 11/15: Validation average loss: 0.7024828513463338 + AUC SCORE = 0.5067330210772834 + AUC SCORE THRESH 0.5510204081632653 = 0.5403981264637002\n",
      "100%|████████████| 117/117 [10:47<00:00,  5.54s/it, batch_loss=0.834, loss=0.67]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 30/30 [00:48<00:00,  1.62s/it, batch_loss=0.762, loss=0.715]\n",
      "EPOCH 12/15: Validation average loss: 0.7148974816004435 + AUC SCORE = 0.5257611241217799 + AUC SCORE THRESH 0.5510204081632653 = 0.5613290398126464\n",
      "100%|███████████| 117/117 [10:27<00:00,  5.36s/it, batch_loss=0.698, loss=0.676]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:50<00:00,  1.68s/it, batch_loss=0.625, loss=0.724]\n",
      "EPOCH 13/15: Validation average loss: 0.7237817148367564 + AUC SCORE = 0.5117096018735363 + AUC SCORE THRESH 0.6122448979591836 = 0.5529859484777517\n",
      "100%|███████████| 117/117 [10:48<00:00,  5.54s/it, batch_loss=0.662, loss=0.668]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.698, loss=0.713]\n",
      "EPOCH 14/15: Validation average loss: 0.7131009519100189 + AUC SCORE = 0.5102459016393442 + AUC SCORE THRESH 0.673469387755102 = 0.537324355971897\n",
      "0.5529859484777517\n",
      "train_T1wCE_3\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 468/468 [01:07<00:00,  6.98it/s]\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 117/117 [00:17<00:00,  6.54it/s]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 08:07:34.083197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [08:15<00:00,  4.23s/it, batch_loss=0.615, loss=0.719]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.597, loss=0.687]\n",
      "EPOCH 0/15: Validation average loss: 0.6874020646015803 + AUC SCORE = 0.4944379391100703 + AUC SCORE THRESH 0.3877551020408163 = 0.5661592505854801\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [10:52<00:00,  5.57s/it, batch_loss=0.743, loss=0.705]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:50<00:00,  1.68s/it, batch_loss=1.13, loss=0.682]\n",
      "EPOCH 1/15: Validation average loss: 0.681970696647962 + AUC SCORE = 0.6548594847775177 + AUC SCORE THRESH 0.42857142857142855 = 0.6627634660421545\n",
      "Saving the model...\n",
      "100%|███████████| 117/117 [10:43<00:00,  5.50s/it, batch_loss=0.675, loss=0.702]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.65s/it, batch_loss=0.741, loss=0.683]\n",
      "EPOCH 2/15: Validation average loss: 0.6826387484868367 + AUC SCORE = 0.603337236533958 + AUC SCORE THRESH 0.44897959183673464 = 0.6412470725995316\n",
      "100%|███████████| 117/117 [10:43<00:00,  5.50s/it, batch_loss=0.788, loss=0.696]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:54<00:00,  1.80s/it, batch_loss=1.02, loss=0.708]\n",
      "EPOCH 3/15: Validation average loss: 0.7079744189977646 + AUC SCORE = 0.6009953161592506 + AUC SCORE THRESH 0.42857142857142855 = 0.6001170960187353\n",
      "100%|███████████| 117/117 [10:31<00:00,  5.40s/it, batch_loss=0.822, loss=0.694]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.761, loss=0.681]\n",
      "EPOCH 4/15: Validation average loss: 0.6810800532499949 + AUC SCORE = 0.601288056206089 + AUC SCORE THRESH 0.4897959183673469 = 0.5913348946135831\n",
      "100%|███████████| 117/117 [10:28<00:00,  5.37s/it, batch_loss=0.679, loss=0.687]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:49<00:00,  1.64s/it, batch_loss=1.11, loss=0.727]\n",
      "EPOCH 5/15: Validation average loss: 0.7268936266501744 + AUC SCORE = 0.6387587822014053 + AUC SCORE THRESH 0.36734693877551017 = 0.6359777517564402\n",
      "100%|███████████| 117/117 [10:45<00:00,  5.52s/it, batch_loss=0.657, loss=0.692]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.65s/it, batch_loss=0.623, loss=0.677]\n",
      "EPOCH 6/15: Validation average loss: 0.6772445728381474 + AUC SCORE = 0.5872365339578454 + AUC SCORE THRESH 0.5102040816326531 = 0.6203161592505855\n",
      "100%|████████████| 117/117 [10:48<00:00,  5.54s/it, batch_loss=0.636, loss=0.69]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.63s/it, batch_loss=0.591, loss=0.708]\n",
      "EPOCH 7/15: Validation average loss: 0.7076821188131969 + AUC SCORE = 0.5117096018735363 + AUC SCORE THRESH 0.5306122448979591 = 0.545228337236534\n",
      "100%|███████████| 117/117 [10:59<00:00,  5.64s/it, batch_loss=0.713, loss=0.688]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:54<00:00,  1.80s/it, batch_loss=0.682, loss=0.696]\n",
      "EPOCH 8/15: Validation average loss: 0.6964038878679275 + AUC SCORE = 0.5433255269320842 + AUC SCORE THRESH 0.4897959183673469 = 0.5690866510538641\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.695, loss=0.686]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.72s/it, batch_loss=0.947, loss=0.743]\n",
      "EPOCH 9/15: Validation average loss: 0.7430156379938125 + AUC SCORE = 0.4651639344262295 + AUC SCORE THRESH 0.3469387755102041 = 0.5579625292740047\n",
      "100%|███████████| 117/117 [11:09<00:00,  5.73s/it, batch_loss=0.644, loss=0.669]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.66s/it, batch_loss=0.842, loss=0.726]\n",
      "EPOCH 10/15: Validation average loss: 0.7262662470340728 + AUC SCORE = 0.4475995316159251 + AUC SCORE THRESH 0.673469387755102 = 0.5163934426229508\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.743, loss=0.661]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:59<00:00,  1.97s/it, batch_loss=0.984, loss=0.767]\n",
      "EPOCH 11/15: Validation average loss: 0.7670036474863688 + AUC SCORE = 0.4142271662763466 + AUC SCORE THRESH 0.7755102040816326 = 0.5163934426229508\n",
      "100%|████████████| 117/117 [11:02<00:00,  5.66s/it, batch_loss=0.615, loss=0.66]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:55<00:00,  1.86s/it, batch_loss=0.638, loss=0.756]\n",
      "EPOCH 12/15: Validation average loss: 0.7560017724831899 + AUC SCORE = 0.4461358313817331 + AUC SCORE THRESH 0.5102040816326531 = 0.5117096018735363\n",
      "100%|███████████| 117/117 [11:09<00:00,  5.72s/it, batch_loss=0.768, loss=0.645]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.77s/it, batch_loss=0.748, loss=0.762]\n",
      "EPOCH 13/15: Validation average loss: 0.7621376474698385 + AUC SCORE = 0.474824355971897 + AUC SCORE THRESH 0.3877551020408163 = 0.5281030444964872\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.71s/it, batch_loss=0.608, loss=0.638]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.66s/it, batch_loss=0.651, loss=0.778]\n",
      "EPOCH 14/15: Validation average loss: 0.7779558042685191 + AUC SCORE = 0.39900468384074944 + AUC SCORE THRESH 0.0 = 0.5\n",
      "0.6548594847775177\n",
      "train_T1wCE_4\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 468/468 [01:07<00:00,  6.93it/s]\n",
      "Caulculating the best scans for every case...\n",
      "100%|█████████████████████████████████████████| 117/117 [00:17<00:00,  6.78it/s]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "2021-12-29 11:02:55.481912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "100%|███████████| 117/117 [07:37<00:00,  3.91s/it, batch_loss=0.681, loss=0.729]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:51<00:00,  1.71s/it, batch_loss=0.236, loss=0.69]\n",
      "EPOCH 0/15: Validation average loss: 0.6898635506629944 + AUC SCORE = 0.5685011709601874 + AUC SCORE THRESH 0.5306122448979591 = 0.5979215456674473\n",
      "Saving the model...\n",
      "100%|█████████████| 117/117 [11:02<00:00,  5.66s/it, batch_loss=0.769, loss=0.7]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.778, loss=0.694]\n",
      "EPOCH 1/15: Validation average loss: 0.6942250847816467 + AUC SCORE = 0.5377634660421545 + AUC SCORE THRESH 0.5918367346938775 = 0.5343969555035128\n",
      "100%|███████████| 117/117 [11:04<00:00,  5.68s/it, batch_loss=0.709, loss=0.703]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 30/30 [00:52<00:00,  1.76s/it, batch_loss=0.853, loss=0.713]\n",
      "EPOCH 2/15: Validation average loss: 0.7134011109670003 + AUC SCORE = 0.5362997658079625 + AUC SCORE THRESH 0.5918367346938775 = 0.5645491803278688\n",
      "100%|███████████| 117/117 [11:06<00:00,  5.70s/it, batch_loss=0.744, loss=0.699]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:50<00:00,  1.69s/it, batch_loss=0.375, loss=0.704]\n",
      "EPOCH 3/15: Validation average loss: 0.7035461147626241 + AUC SCORE = 0.5620608899297425 + AUC SCORE THRESH 0.44897959183673464 = 0.5769906323185011\n",
      "100%|███████████| 117/117 [11:05<00:00,  5.69s/it, batch_loss=0.766, loss=0.685]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:50<00:00,  1.69s/it, batch_loss=0.388, loss=0.697]\n",
      "EPOCH 4/15: Validation average loss: 0.6969916254281998 + AUC SCORE = 0.539519906323185 + AUC SCORE THRESH 0.5918367346938775 = 0.5560597189695549\n",
      "100%|███████████| 117/117 [11:07<00:00,  5.70s/it, batch_loss=0.462, loss=0.689]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:49<00:00,  1.66s/it, batch_loss=0.229, loss=0.721]\n",
      "EPOCH 5/15: Validation average loss: 0.721374407907327 + AUC SCORE = 0.5544496487119438 + AUC SCORE THRESH 0.5510204081632653 = 0.5665983606557377\n",
      "100%|███████████| 117/117 [11:14<00:00,  5.76s/it, batch_loss=0.525, loss=0.684]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.02s/it, batch_loss=0.629, loss=0.721]\n",
      "EPOCH 6/15: Validation average loss: 0.7210925231377284 + AUC SCORE = 0.5559133489461358 + AUC SCORE THRESH 0.6122448979591836 = 0.571135831381733\n",
      "100%|███████████| 117/117 [11:18<00:00,  5.80s/it, batch_loss=0.805, loss=0.688]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|█████████████| 30/30 [00:51<00:00,  1.73s/it, batch_loss=0.461, loss=0.694]\n",
      "EPOCH 7/15: Validation average loss: 0.6943967928489049 + AUC SCORE = 0.5415690866510539 + AUC SCORE THRESH 0.5714285714285714 = 0.5739168618266979\n",
      "100%|███████████| 117/117 [11:11<00:00,  5.74s/it, batch_loss=0.509, loss=0.673]\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "100%|██████████████| 30/30 [00:52<00:00,  1.75s/it, batch_loss=0.779, loss=0.71]\n",
      "EPOCH 8/15: Validation average loss: 0.7098765790462493 + AUC SCORE = 0.5128805620608898 + AUC SCORE THRESH 0.6122448979591836 = 0.5352751756440282\n",
      "100%|████████████| 117/117 [11:30<00:00,  5.90s/it, batch_loss=0.864, loss=0.68]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:53<00:00,  1.78s/it, batch_loss=0.783, loss=0.723]\n",
      "EPOCH 9/15: Validation average loss: 0.7228919426600139 + AUC SCORE = 0.5272248243559718 + AUC SCORE THRESH 0.5510204081632653 = 0.5584016393442623\n",
      "100%|███████████| 117/117 [11:38<00:00,  5.97s/it, batch_loss=0.595, loss=0.665]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|██████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.74, loss=0.742]\n",
      "EPOCH 10/15: Validation average loss: 0.7418981492519379 + AUC SCORE = 0.498536299765808 + AUC SCORE THRESH 0.5918367346938775 = 0.5383489461358314\n",
      "100%|███████████| 117/117 [11:34<00:00,  5.93s/it, batch_loss=0.704, loss=0.657]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:00<00:00,  2.03s/it, batch_loss=0.374, loss=0.738]\n",
      "EPOCH 11/15: Validation average loss: 0.7378725240627925 + AUC SCORE = 0.4795081967213115 + AUC SCORE THRESH 0.5306122448979591 = 0.5449355971896955\n",
      "100%|███████████| 117/117 [11:30<00:00,  5.90s/it, batch_loss=0.548, loss=0.652]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [01:01<00:00,  2.04s/it, batch_loss=0.774, loss=0.786]\n",
      "EPOCH 12/15: Validation average loss: 0.7856268147627513 + AUC SCORE = 0.42798594847775173 + AUC SCORE THRESH 0.836734693877551 = 0.5081967213114754\n",
      "100%|███████████| 117/117 [11:26<00:00,  5.87s/it, batch_loss=0.569, loss=0.651]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|██████████████| 30/30 [01:00<00:00,  2.02s/it, batch_loss=1.16, loss=0.806]\n",
      "EPOCH 13/15: Validation average loss: 0.8058923304080963 + AUC SCORE = 0.44057377049180335 + AUC SCORE THRESH 0.5306122448979591 = 0.5251756440281031\n",
      "100%|███████████| 117/117 [11:37<00:00,  5.96s/it, batch_loss=0.712, loss=0.631]\n",
      "Adjusting learning rate of group 0 to 5.0000e-05.\n",
      "100%|█████████████| 30/30 [00:57<00:00,  1.91s/it, batch_loss=0.796, loss=0.943]\n",
      "EPOCH 14/15: Validation average loss: 0.9430062651634217 + AUC SCORE = 0.4142271662763466 + AUC SCORE THRESH 0.18367346938775508 = 0.5177107728337236\n",
      "0.5685011709601874\n"
     ]
    }
   ],
   "source": [
    "!python3 ../rsnaresnet10/working/train.py --fold 0 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 1 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 2 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 3 --type T1wCE --model_name resnet10\n",
    "!python3 ../rsnaresnet10/working/train.py --fold 4 --type T1wCE --model_name resnet10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../rsnaresnet10/working/validation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.dataset_utils import *\n",
    "from utils.classifier_utils import *\n",
    "\n",
    "import os\n",
    "\n",
    "import monai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format='%(asctime)s - %(message)s', datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "#import config\n",
    "#from dataset import BrainRSNADataset\n",
    "\n",
    "dir_path = \"../../RSNA-BTC-Datasets/train_mat\"\n",
    "test_dir_path = \"../../RSNA-BTC-Datasets/test_mat\"\n",
    "tumor_only_dir_path = \"../../RSNA-BTC-Datasets/ec_train_mat\"\n",
    "tumor_only_test_dir_path = \"../../RSNA-BTC-Datasets/ec_test_mat\"\n",
    "no_tumor_dir_path = \"../../RSNA-BTC-Datasets/no_tumor_train_mat\"\n",
    "#ext_test_1_dir_path = \"../../RSNA-BTC-Datasets/brats18_mat\"\n",
    "#ext_test_0_dir_path = \"../../RSNA-BTC-Datasets/OpenNeuroDS000221_ss_mat\"\n",
    "new_dir_path = \"../../RSNA-BTC-Datasets/UPENN-GBM_mat\"\n",
    "\n",
    "def generate_datasets(types):\n",
    "    data_packs = {}\n",
    "    ext = \"mat\"\n",
    "    transform = None\n",
    "    dims = 3\n",
    "    sel_slices = None\n",
    "    for t in types:\n",
    "        print(\"Type: \"+t)\n",
    "        # Competition Train + Val + Test\n",
    "        m_dataset_0 = Dataset(dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        logging.info(\"m0 Train/Val datasets size: {}\".format(len(m_dataset_0)))\n",
    "\n",
    "        m_dataset_1 = Dataset(dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "        \n",
    "        logging.info(\"m1 Train/Val datasets size: {}\".format(len(m_dataset_1)))\n",
    "\n",
    "        # External Train + Val + Test\n",
    "        #t_dataset_0 = Dataset(ext_test_0_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        #logging.info(\"Train/Val datasets size: {}\".format(len(t_dataset_0)))\n",
    "\n",
    "        #t_dataset_1 = Dataset(ext_test_1_dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        #logging.info(\"Train/Val datasets size: {}\".format(len(t_dataset_1)))\n",
    "\n",
    "        # UPENN Train + Val + Test\n",
    "        n_dataset_0 = Dataset(new_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "        logging.info(\"n0 Train/Val datasets size: {}\".format(len(n_dataset_0)))\n",
    "\n",
    "        n_dataset_1 = Dataset(new_dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "        \n",
    "        logging.info(\"n1 Train/Val datasets size: {}\".format(len(n_dataset_1)))\n",
    "        \n",
    "        if t == \"KLF\" or t == \"T1wCE\":\n",
    "            # Competition (Tumor Only) Train + Val + Test\n",
    "            f_dataset_0 = Dataset(tumor_only_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "            logging.info(\"f0 Train/Val datasets size: {}\".format(len(f_dataset_0)))\n",
    "\n",
    "            f_dataset_1 = Dataset(tumor_only_dir_path, [t], list_classes=[\"1\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "            logging.info(\"f1 Train/Val datasets size: {}\".format(len(f_dataset_1)))\n",
    "            \n",
    "            # Competition (No Tumor) Train + Val + Test\n",
    "            h_dataset_0 = Dataset(no_tumor_dir_path, [t], list_classes=[\"0\"], transform=transform, ext=ext, dims=dims, sel_slices=sel_slices)\n",
    "\n",
    "            logging.info(\"h0 Train/Val datasets size: {}\".format(len(h_dataset_0)))\n",
    "            \n",
    "            # Competition (Tumor Only) + UPENN Train + Val + Test\n",
    "            fn_dataset_0 = Dataset().concat_datasets(f_dataset_0, n_dataset_0)\n",
    "            \n",
    "            logging.info(\"fn0 Train/Val datasets size: {}\".format(len(fn_dataset_0)))\n",
    "            \n",
    "            fn_dataset_1 = Dataset().concat_datasets(f_dataset_1, n_dataset_1)\n",
    "            \n",
    "            logging.info(\"fn1 Train/Val datasets size: {}\".format(len(fn_dataset_1)))\n",
    "        \n",
    "        if t == \"KLF\" or t == \"T1wCE\":\n",
    "            data_packs[t] = {\n",
    "                \"m_dataset_0\": m_dataset_0,\n",
    "                \"m_dataset_1\": m_dataset_1,\n",
    "                \"f_dataset_0\": f_dataset_0,\n",
    "                \"f_dataset_1\": f_dataset_1,\n",
    "                \"h_dataset_0\": h_dataset_0,\n",
    "                #\"t_dataset_0\": t_dataset_0,\n",
    "                #\"t_dataset_1\": t_dataset_1,\n",
    "                \"n_dataset_0\": n_dataset_0,\n",
    "                \"n_dataset_1\": n_dataset_1,\n",
    "                \"fn_dataset_0\": fn_dataset_0,\n",
    "                \"fn_dataset_1\": fn_dataset_1\n",
    "            }\n",
    "        else:\n",
    "            data_packs[t] = {\n",
    "                \"m_dataset_0\": m_dataset_0,\n",
    "                \"m_dataset_1\": m_dataset_1,\n",
    "                #\"t_dataset_0\": t_dataset_0,\n",
    "                #\"t_dataset_1\": t_dataset_1,\n",
    "                \"n_dataset_0\": n_dataset_0,\n",
    "                \"n_dataset_1\": n_dataset_1\n",
    "            }\n",
    "    return data_packs\n",
    "\n",
    "import importlib\n",
    "from utils import dataset_utils\n",
    "importlib.reload(dataset_utils)\n",
    "\n",
    "def get_merged_dataset(dataset_0, dataset_1, k=5):\n",
    "    dataset_merged = Dataset().concat_datasets(dataset_0, dataset_1)\n",
    "    dataset_merged_no_tr = Dataset().concat_datasets(dataset_0, dataset_1, import_transform=False)\n",
    "\n",
    "    val_total_ratio = 0.2\n",
    "    is_5_fold = True\n",
    "    splits = dataset_utils.get_splits(dataset_0, dataset_1, val_total_ratio, is_5_fold, 0.1, k)\n",
    "    print(splits)\n",
    "    return dataset_merged, dataset_merged_no_tr, splits\n",
    "\n",
    "def train_model(train_dl, validation_dl, fold_number, mri_type, model_name, epochs):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.5, last_epoch=-1, verbose=True)\n",
    "\n",
    "    model.zero_grad()\n",
    "    model.to(device)\n",
    "    best_loss = 9999\n",
    "    best_auc = 0\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    train_writer = SummaryWriter()\n",
    "    for counter in range(epochs):\n",
    "\n",
    "        epoch_iterator_train = tqdm(train_dl)\n",
    "        tr_loss = 0.0\n",
    "        for step, batch in enumerate(epoch_iterator_train):\n",
    "            model.train()\n",
    "            (img_ids, imgs, labels) = batch\n",
    "            images, targets = imgs[0].to(device), labels.to(device)\n",
    "            #images, targets = batch[\"image\"].to(device), batch[\"target\"].to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            targets = targets  # .view(-1, 1)\n",
    "            loss = criterion(outputs.squeeze(1), targets.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            epoch_iterator_train.set_postfix(\n",
    "                batch_loss=(loss.item()), loss=(tr_loss / (step + 1))\n",
    "            )\n",
    "\n",
    "        train_writer.add_scalar('loss', (tr_loss/(step+1)), counter+1)\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            preds = []\n",
    "            true_labels = []\n",
    "            case_ids = []\n",
    "            epoch_iterator_val = tqdm(validation_dl)\n",
    "            for step, batch in enumerate(epoch_iterator_val):\n",
    "                model.eval()\n",
    "                (img_ids, imgs, labels) = batch\n",
    "                images, targets = imgs[0].to(device), labels.to(device)\n",
    "                #images, targets = batch[\"image\"].to(device), batch[\"target\"].to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                targets = targets  # .view(-1, 1)\n",
    "                loss = criterion(outputs.squeeze(1), targets.float())\n",
    "                val_loss += loss.item()\n",
    "                epoch_iterator_val.set_postfix(\n",
    "                    batch_loss=(loss.item()), loss=(val_loss / (step + 1))\n",
    "                )\n",
    "                preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "                true_labels.append(targets.cpu().numpy())\n",
    "                #case_ids.append(batch[\"case_id\"])\n",
    "                if img_ids[0][0][0].isnumeric():\n",
    "                    img_ids_fixed = [img_id[:5] for img_id in img_ids[0]]\n",
    "                else:\n",
    "                    img_ids_fixed = [img_id[:-4] for img_id in img_ids[0]]\n",
    "                case_ids.append(img_ids_fixed)\n",
    "        preds = np.vstack(preds).T[0].tolist()\n",
    "        true_labels = np.hstack(true_labels).tolist()\n",
    "        case_ids = np.hstack(case_ids).tolist()\n",
    "        auc_score = roc_auc_score(true_labels, preds)\n",
    "        auc_score_adj_best = 0\n",
    "        for thresh in np.linspace(0, 1, 50):\n",
    "            auc_score_adj = roc_auc_score(true_labels, list(np.array(preds) > thresh))\n",
    "            if auc_score_adj > auc_score_adj_best:\n",
    "                best_thresh = thresh\n",
    "                auc_score_adj_best = auc_score_adj\n",
    "\n",
    "        print(\n",
    "            f\"EPOCH {counter+1}/{epochs}: Validation average loss: {val_loss/(step+1)} + AUC SCORE = {auc_score} + AUC SCORE THRESH {best_thresh} = {auc_score_adj_best}\"\n",
    "        )\n",
    "        train_writer.add_scalar('val_loss', val_loss/(step+1), counter+1)\n",
    "        train_writer.add_scalar('val_auc', auc_score, counter+1)\n",
    "        if auc_score > best_auc:\n",
    "            print(\"Saving the model...\")\n",
    "\n",
    "            if not os.path.exists(\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/\"):\n",
    "                os.mkdir(\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/\")\n",
    "            all_files = os.listdir(\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/\")\n",
    "\n",
    "            for f in all_files:\n",
    "                if f\"{model_name}_{mri_type}_fold{fold_number}\" in f:\n",
    "                    os.remove(f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/{f}\")\n",
    "\n",
    "            best_auc = auc_score\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                f\"../../RSNA-BTC-Datasets/rsnaresnet10_output_weights/3d-{model_name}_{mri_type}_fold{fold_number}_{round(best_auc,3)}.pth\",\n",
    "            )\n",
    "\n",
    "    print(best_auc)\n",
    "\n",
    "def train_folded_models(fold, mri_type, model_name, batch_size, epochs, train_origins):\n",
    "    #data = pd.read_csv(\"train.csv\")\n",
    "    #train_df = data[data.fold != fold].reset_index(drop=False)\n",
    "    #val_df = data[data.fold == fold].reset_index(drop=False)\n",
    "    \n",
    "    print(f\"train_{mri_type}_{fold}\")\n",
    "    #train_dataset = BrainRSNADataset(data=train_df, mri_type=args.type, ds_type=f\"train_{args.type}_{args.fold}\")\n",
    "\n",
    "    #valid_dataset = BrainRSNADataset(data=val_df, mri_type=args.type, ds_type=f\"val_{args.type}_{args.fold}\")\n",
    "\n",
    "    packs = generate_datasets([mri_type])\n",
    "    \n",
    "    loader_packs = {}\n",
    "    for t, pack in packs.items():\n",
    "        print(\"Type: \"+t)\n",
    "        m_dataset_merged, m_dataset_merged_no_tr, m_splits = get_merged_dataset(pack['m_dataset_0'], pack['m_dataset_1'], fold)\n",
    "        n_dataset_merged, n_dataset_merged_no_tr, n_splits = get_merged_dataset(pack['n_dataset_0'], pack['n_dataset_1'], fold)\n",
    "        fn_dataset_merged, fn_dataset_merged_no_tr, fn_splits = get_merged_dataset(pack['fn_dataset_0'], pack['fn_dataset_1'], fold)\n",
    "        print(\"SPLITS:\")\n",
    "        print(\"- folds:\")\n",
    "        print(len(m_splits))\n",
    "        print(\"- splits per fold:\")\n",
    "        print(len(m_splits[0]))\n",
    "        #print(len(n_splits))\n",
    "        for to in train_origins:\n",
    "            if to == \"m\":\n",
    "                i = 0\n",
    "                for split in m_splits:\n",
    "                    m_dataloader = get_all_split_loaders(m_dataset_merged, m_dataset_merged_no_tr, [split], batch_size)\n",
    "                    m_dataloaders = list(m_dataloader[0])\n",
    "                    print(f\"(M) Train validation splitted: {len(split[0])} {len(split[1])}\")\n",
    "                    print(m_dataloaders)\n",
    "                    train_dl = m_dataloaders[0]\n",
    "                    validation_dl = m_dataloaders[1]\n",
    "                    train_model(train_dl, validation_dl, i, mri_type, model_name+\"_m\", epochs)\n",
    "                    \"\"\"\n",
    "                    device = torch.device(\"cuda\")\n",
    "                    model = monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1)\n",
    "                    model.to(device)\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "                    criterion = nn.BCEWithLogitsLoss()\n",
    "                    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.5, last_epoch=-1, verbose=True)\n",
    "                    trainer = Trainer(\n",
    "                        model, \n",
    "                        device, \n",
    "                        optimizer, \n",
    "                        criterion,\n",
    "                        scheduler,\n",
    "                        1\n",
    "                    )\n",
    "\n",
    "                    history = trainer.fit(\n",
    "                        device,\n",
    "                        epochs, \n",
    "                        train_dl,\n",
    "                        validation_dl,\n",
    "                        model_name+\"_m\", \n",
    "                        15\n",
    "                    )\n",
    "\n",
    "                    trainer.train_writer.flush()\n",
    "                    \"\"\"\n",
    "                    i += 1\n",
    "\n",
    "            elif to == \"n\":\n",
    "                i = 0\n",
    "                for split in n_splits:\n",
    "                    n_dataloader = get_all_split_loaders(n_dataset_merged, n_dataset_merged_no_tr, [split], batch_size)\n",
    "                    n_dataloaders = list(n_dataloader[0])\n",
    "                    print(f\"(N) Train validation splitted: {len(split[0])} {len(split[1])}\")\n",
    "                    train_dl = n_dataloaders[0]\n",
    "                    validation_dl = n_dataloaders[1]\n",
    "                    train_model(train_dl, validation_dl, i, mri_type, model_name+\"_n\", epochs)\n",
    "                    i += 1\n",
    "            elif to == \"fn\":\n",
    "                i = 0\n",
    "                for split in fn_splits:\n",
    "                    print(f\"Fold n.{i} started\")\n",
    "                    fn_dataloader = get_all_split_loaders(fn_dataset_merged, fn_dataset_merged_no_tr, [split], batch_size)\n",
    "                    fn_dataloaders = list(fn_dataloader[0])\n",
    "                    print(f\"(FN) Train validation splitted: {len(split[0])} {len(split[1])}\")\n",
    "                    train_dl = fn_dataloaders[0]\n",
    "                    validation_dl = fn_dataloaders[1]\n",
    "                    train_model(train_dl, validation_dl, i, mri_type, model_name+\"_fn\", epochs)\n",
    "                    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14356929"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce RTX 3090\n",
      "1.12.1\n",
      "11.3\n",
      "tensor([-0.9929], device='cuda:0')\n",
      "2022-08-09 10:21:57 - Printing one: 1\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\"\"\"\n",
    "for file in os.listdir(no_tumor_dir_path+\"/KLF/0\"):\n",
    "    fixed_file = file[:-7]+\"T1wCE.mat\"\n",
    "    shutil.copy(dir_path+\"/T1wCE/0/\"+fixed_file, no_tumor_dir_path+\"/T1wCE/0/\"+fixed_file)\n",
    "    \n",
    "for file in os.listdir(tumor_only_dir_path+\"/KLF/0\"):\n",
    "    fixed_file = file[:-7]+\"T1wCE.mat\"\n",
    "    shutil.copy(dir_path+\"/T1wCE/0/\"+fixed_file, tumor_only_dir_path+\"/T1wCE/0/\"+fixed_file)\n",
    "    \n",
    "for file in os.listdir(tumor_only_dir_path+\"/KLF/1\"):\n",
    "    fixed_file = file[:-7]+\"T1wCE.mat\"\n",
    "    shutil.copy(dir_path+\"/T1wCE/1/\"+fixed_file, tumor_only_dir_path+\"/T1wCE/1/\"+fixed_file)\n",
    "\"\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "x = torch.randn(1).cuda()\n",
    "print(x)\n",
    "logging.info(\"Printing one: {}\".format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_T1wCE_5\n",
      "Type: T1wCE\n",
      "2022-08-09 10:21:59 - m0 Train/Val datasets size: 270\n",
      "2022-08-09 10:21:59 - m1 Train/Val datasets size: 303\n",
      "2022-08-09 10:21:59 - n0 Train/Val datasets size: 170\n",
      "2022-08-09 10:21:59 - n1 Train/Val datasets size: 121\n",
      "2022-08-09 10:21:59 - f0 Train/Val datasets size: 129\n",
      "2022-08-09 10:21:59 - f1 Train/Val datasets size: 273\n",
      "2022-08-09 10:21:59 - h0 Train/Val datasets size: 141\n",
      "Length of concatenated dataset: 340\n",
      "2022-08-09 10:21:59 - fn0 Train/Val datasets size: 340\n",
      "Length of concatenated dataset: 546\n",
      "2022-08-09 10:21:59 - fn1 Train/Val datasets size: 546\n",
      "Type: T1wCE\n",
      "Length of concatenated dataset: 606\n",
      "Length of concatenated dataset: 606\n",
      "[(array([  0,   2,   4,   6,   7,   8,   9,  10,  11,  12,  13,  15,  16,\n",
      "        17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  30,\n",
      "        32,  35,  36,  37,  38,  39,  40,  42,  43,  45,  46,  47,  48,\n",
      "        50,  51,  52,  53,  54,  56,  57,  58,  59,  60,  61,  62,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  85,  87,  88,  89,  90,  91,  93,\n",
      "        94,  95,  96,  98, 100, 102, 103, 105, 106, 107, 108, 109, 111,\n",
      "       114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "       128, 129, 130, 131, 132, 135, 136, 137, 138, 140, 141, 142, 144,\n",
      "       146, 147, 149, 150, 151, 152, 153, 154, 158, 159, 160, 161, 163,\n",
      "       165, 166, 167, 168, 169, 171, 173, 174, 175, 176, 177, 178, 179,\n",
      "       180, 182, 183, 185, 186, 187, 189, 190, 191, 192, 193, 194, 197,\n",
      "       199, 200, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214,\n",
      "       215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 227, 228, 229,\n",
      "       230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 243, 244,\n",
      "       245, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 266, 267, 268, 269, 270, 271, 273, 275,\n",
      "       276, 278, 280, 281, 283, 284, 285, 286, 287, 288, 289, 290, 291,\n",
      "       294, 295, 296, 297, 298, 299, 301, 302, 303, 304, 305, 306, 307,\n",
      "       308, 309, 310, 311, 313, 314, 315, 316, 317, 318, 319, 321, 322,\n",
      "       323, 324, 326, 327, 330, 331, 332, 333, 334, 335, 338, 339, 340,\n",
      "       344, 345, 346, 347, 348, 350, 351, 352, 353, 354, 355, 356, 357,\n",
      "       360, 361, 363, 365, 367, 368, 369, 370, 371, 372, 373, 374, 376,\n",
      "       378, 379, 380, 381, 382, 383, 386, 387, 388, 389, 390, 391, 392,\n",
      "       393, 394, 395, 396, 398, 399, 403, 404, 406, 407, 408, 409, 410,\n",
      "       411, 412, 414, 416, 417, 418, 420, 421, 423, 424, 425, 426, 427,\n",
      "       428, 429, 430, 431, 432, 434, 435, 436, 437, 439, 440, 441, 442,\n",
      "       444, 445, 446, 448, 450, 452, 453, 454, 455, 457, 458, 459, 460,\n",
      "       461, 462, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475,\n",
      "       476, 477, 479, 480, 481, 483, 484, 485, 486, 488, 489, 490, 492,\n",
      "       493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
      "       506, 507, 509, 510, 513, 514, 516, 518, 519, 520, 521, 522, 523,\n",
      "       524, 526, 527, 528, 529, 530, 531, 532, 534, 535, 536, 538, 539,\n",
      "       540, 541, 542, 543, 544, 548, 549, 551, 552, 554, 556, 557, 558,\n",
      "       559, 560, 561, 562, 564, 565, 566, 567, 568, 569, 570, 571, 572,\n",
      "       573, 574, 575, 577, 578, 579, 580, 581, 582, 583, 585, 586, 587,\n",
      "       588, 589, 590, 591, 592, 593, 594, 595, 596, 598, 599, 600, 602,\n",
      "       603, 604, 605]), array([  1,   3,   5,  14,  29,  31,  33,  34,  41,  44,  49,  55,  63,\n",
      "        84,  86,  92,  97,  99, 101, 104, 110, 112, 113, 116, 133, 134,\n",
      "       139, 143, 145, 148, 155, 156, 157, 162, 164, 170, 172, 181, 184,\n",
      "       188, 195, 196, 198, 201, 202, 203, 224, 226, 235, 242, 246, 253,\n",
      "       265, 272, 274, 277, 279, 282, 292, 293, 300, 312, 320, 325, 328,\n",
      "       329, 336, 337, 341, 342, 343, 349, 358, 359, 362, 364, 366, 375,\n",
      "       377, 384, 385, 397, 400, 401, 402, 405, 413, 415, 419, 422, 433,\n",
      "       438, 443, 447, 449, 451, 456, 463, 470, 478, 482, 487, 491, 508,\n",
      "       511, 512, 515, 517, 525, 533, 537, 545, 546, 547, 550, 553, 555,\n",
      "       563, 576, 584, 597, 601])), (array([  1,   2,   3,   4,   5,   6,   7,   9,  11,  12,  13,  14,  16,\n",
      "        17,  18,  20,  21,  22,  23,  24,  25,  27,  29,  31,  32,  33,\n",
      "        34,  35,  37,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,\n",
      "        49,  51,  52,  53,  55,  56,  57,  58,  59,  60,  61,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  76,  78,  79,\n",
      "        80,  81,  82,  83,  84,  85,  86,  87,  88,  90,  91,  92,  93,\n",
      "        94,  96,  97,  98,  99, 100, 101, 103, 104, 105, 107, 108, 110,\n",
      "       111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 124, 125, 126,\n",
      "       128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141,\n",
      "       143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157,\n",
      "       158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171,\n",
      "       172, 173, 175, 176, 177, 178, 179, 181, 182, 184, 185, 186, 187,\n",
      "       188, 189, 190, 191, 194, 195, 196, 197, 198, 200, 201, 202, 203,\n",
      "       205, 207, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220,\n",
      "       221, 224, 226, 228, 232, 233, 234, 235, 236, 237, 238, 239, 240,\n",
      "       242, 244, 245, 246, 247, 248, 250, 251, 253, 254, 256, 257, 258,\n",
      "       261, 262, 263, 264, 265, 268, 269, 270, 271, 272, 273, 274, 275,\n",
      "       276, 277, 278, 279, 281, 282, 283, 285, 286, 288, 289, 291, 292,\n",
      "       293, 294, 296, 297, 298, 299, 300, 301, 303, 305, 306, 307, 310,\n",
      "       311, 312, 313, 314, 315, 316, 317, 318, 320, 321, 323, 324, 325,\n",
      "       326, 327, 328, 329, 330, 331, 332, 333, 334, 336, 337, 338, 339,\n",
      "       341, 342, 343, 344, 345, 346, 348, 349, 350, 351, 352, 354, 355,\n",
      "       356, 358, 359, 360, 361, 362, 364, 365, 366, 368, 370, 371, 372,\n",
      "       375, 376, 377, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 392, 393, 394, 395, 397, 398, 399, 400, 401, 402, 403, 404,\n",
      "       405, 406, 407, 412, 413, 414, 415, 416, 419, 421, 422, 423, 424,\n",
      "       425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437,\n",
      "       438, 439, 440, 441, 442, 443, 444, 446, 447, 448, 449, 450, 451,\n",
      "       452, 454, 456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 475, 476, 478, 479, 480, 482, 483,\n",
      "       484, 485, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 498,\n",
      "       499, 501, 502, 503, 505, 506, 507, 508, 509, 510, 511, 512, 513,\n",
      "       514, 515, 516, 517, 519, 520, 522, 524, 525, 526, 527, 528, 529,\n",
      "       531, 532, 533, 535, 536, 537, 538, 539, 540, 541, 543, 544, 545,\n",
      "       546, 547, 548, 550, 552, 553, 555, 556, 557, 560, 562, 563, 564,\n",
      "       565, 567, 568, 570, 572, 574, 575, 576, 577, 578, 579, 580, 582,\n",
      "       584, 585, 586, 587, 588, 589, 590, 591, 592, 594, 596, 597, 598,\n",
      "       600, 601, 602, 604]), array([  0,   8,  10,  15,  19,  26,  28,  30,  36,  38,  50,  54,  62,\n",
      "        75,  77,  89,  95, 102, 106, 109, 119, 122, 123, 127, 135, 142,\n",
      "       147, 150, 166, 174, 180, 183, 192, 193, 199, 204, 206, 208, 214,\n",
      "       222, 223, 225, 227, 229, 230, 231, 241, 243, 249, 252, 255, 259,\n",
      "       260, 266, 267, 280, 284, 287, 290, 295, 302, 304, 308, 309, 319,\n",
      "       322, 335, 340, 347, 353, 357, 363, 367, 369, 373, 374, 378, 379,\n",
      "       391, 396, 408, 409, 410, 411, 417, 418, 420, 445, 453, 455, 464,\n",
      "       474, 477, 481, 486, 497, 500, 504, 518, 521, 523, 530, 534, 542,\n",
      "       549, 551, 554, 558, 559, 561, 566, 569, 571, 573, 581, 583, 593,\n",
      "       595, 599, 603, 605])), (array([  0,   1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "        14,  15,  16,  17,  19,  20,  21,  22,  24,  26,  27,  28,  29,\n",
      "        30,  31,  32,  33,  34,  36,  37,  38,  39,  40,  41,  42,  43,\n",
      "        44,  46,  48,  49,  50,  51,  54,  55,  56,  57,  61,  62,  63,\n",
      "        64,  65,  67,  68,  69,  70,  71,  72,  74,  75,  77,  78,  82,\n",
      "        84,  86,  87,  88,  89,  92,  94,  95,  96,  97,  98,  99, 100,\n",
      "       101, 102, 103, 104, 106, 107, 108, 109, 110, 112, 113, 116, 117,\n",
      "       119, 120, 122, 123, 124, 127, 128, 130, 131, 132, 133, 134, 135,\n",
      "       136, 137, 138, 139, 140, 142, 143, 144, 145, 147, 148, 149, 150,\n",
      "       151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
      "       165, 166, 167, 169, 170, 172, 173, 174, 176, 178, 180, 181, 182,\n",
      "       183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "       197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 212,\n",
      "       214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
      "       227, 228, 229, 230, 231, 232, 234, 235, 238, 240, 241, 242, 243,\n",
      "       244, 245, 246, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257,\n",
      "       259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 270, 272, 273,\n",
      "       274, 277, 279, 280, 281, 282, 284, 285, 286, 287, 289, 290, 291,\n",
      "       292, 293, 295, 296, 297, 300, 301, 302, 304, 305, 306, 307, 308,\n",
      "       309, 311, 312, 313, 315, 316, 317, 319, 320, 321, 322, 325, 326,\n",
      "       327, 328, 329, 330, 332, 334, 335, 336, 337, 339, 340, 341, 342,\n",
      "       343, 344, 345, 347, 348, 349, 350, 352, 353, 355, 356, 357, 358,\n",
      "       359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371,\n",
      "       372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 384, 385,\n",
      "       386, 388, 391, 392, 393, 394, 395, 396, 397, 400, 401, 402, 404,\n",
      "       405, 406, 408, 409, 410, 411, 413, 415, 417, 418, 419, 420, 421,\n",
      "       422, 423, 424, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435,\n",
      "       436, 437, 438, 439, 440, 441, 442, 443, 445, 446, 447, 448, 449,\n",
      "       450, 451, 452, 453, 454, 455, 456, 458, 459, 461, 462, 463, 464,\n",
      "       465, 467, 468, 470, 471, 474, 477, 478, 479, 481, 482, 485, 486,\n",
      "       487, 490, 491, 492, 493, 495, 496, 497, 498, 500, 501, 502, 503,\n",
      "       504, 505, 506, 507, 508, 511, 512, 514, 515, 516, 517, 518, 520,\n",
      "       521, 523, 524, 525, 526, 527, 530, 531, 532, 533, 534, 535, 536,\n",
      "       537, 538, 539, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
      "       551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 563, 566,\n",
      "       567, 568, 569, 571, 573, 574, 576, 577, 578, 579, 581, 583, 584,\n",
      "       585, 587, 588, 589, 590, 592, 593, 594, 595, 596, 597, 598, 599,\n",
      "       601, 603, 604, 605]), array([  2,  18,  23,  25,  35,  45,  47,  52,  53,  58,  59,  60,  66,\n",
      "        73,  76,  79,  80,  81,  83,  85,  90,  91,  93, 105, 111, 114,\n",
      "       115, 118, 121, 125, 126, 129, 141, 146, 153, 168, 171, 175, 177,\n",
      "       179, 186, 205, 209, 211, 213, 233, 236, 237, 239, 247, 258, 269,\n",
      "       271, 275, 276, 278, 283, 288, 294, 298, 299, 303, 310, 314, 318,\n",
      "       323, 324, 331, 333, 338, 346, 351, 354, 383, 387, 389, 390, 398,\n",
      "       399, 403, 407, 412, 414, 416, 425, 444, 457, 460, 466, 469, 472,\n",
      "       473, 475, 476, 480, 483, 484, 488, 489, 494, 499, 509, 510, 513,\n",
      "       519, 522, 528, 529, 540, 562, 564, 565, 570, 572, 575, 580, 582,\n",
      "       586, 591, 600, 602])), (array([  0,   1,   2,   3,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "        14,  15,  17,  18,  19,  22,  23,  25,  26,  28,  29,  30,  31,\n",
      "        33,  34,  35,  36,  38,  41,  43,  44,  45,  46,  47,  48,  49,\n",
      "        50,  51,  52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,\n",
      "        64,  65,  66,  67,  69,  73,  74,  75,  76,  77,  79,  80,  81,\n",
      "        83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  95,  96,\n",
      "        97,  98,  99, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111,\n",
      "       112, 113, 114, 115, 116, 118, 119, 121, 122, 123, 124, 125, 126,\n",
      "       127, 128, 129, 130, 131, 133, 134, 135, 139, 140, 141, 142, 143,\n",
      "       145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "       159, 160, 162, 163, 164, 166, 167, 168, 170, 171, 172, 174, 175,\n",
      "       176, 177, 179, 180, 181, 183, 184, 186, 187, 188, 190, 191, 192,\n",
      "       193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206,\n",
      "       207, 208, 209, 210, 211, 212, 213, 214, 215, 219, 220, 222, 223,\n",
      "       224, 225, 226, 227, 228, 229, 230, 231, 233, 235, 236, 237, 238,\n",
      "       239, 240, 241, 242, 243, 246, 247, 248, 249, 252, 253, 255, 257,\n",
      "       258, 259, 260, 262, 263, 265, 266, 267, 269, 271, 272, 274, 275,\n",
      "       276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 288, 290,\n",
      "       291, 292, 293, 294, 295, 298, 299, 300, 302, 303, 304, 305, 307,\n",
      "       308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 322,\n",
      "       323, 324, 325, 326, 328, 329, 330, 331, 333, 335, 336, 337, 338,\n",
      "       340, 341, 342, 343, 346, 347, 348, 349, 351, 352, 353, 354, 357,\n",
      "       358, 359, 360, 361, 362, 363, 364, 366, 367, 369, 370, 372, 373,\n",
      "       374, 375, 376, 377, 378, 379, 380, 383, 384, 385, 386, 387, 389,\n",
      "       390, 391, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405,\n",
      "       406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418,\n",
      "       419, 420, 422, 424, 425, 426, 428, 431, 432, 433, 438, 441, 442,\n",
      "       443, 444, 445, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456,\n",
      "       457, 458, 460, 462, 463, 464, 466, 467, 468, 469, 470, 471, 472,\n",
      "       473, 474, 475, 476, 477, 478, 480, 481, 482, 483, 484, 486, 487,\n",
      "       488, 489, 491, 492, 494, 496, 497, 499, 500, 502, 503, 504, 507,\n",
      "       508, 509, 510, 511, 512, 513, 515, 516, 517, 518, 519, 520, 521,\n",
      "       522, 523, 525, 528, 529, 530, 532, 533, 534, 536, 537, 538, 540,\n",
      "       542, 543, 544, 545, 546, 547, 549, 550, 551, 553, 554, 555, 556,\n",
      "       557, 558, 559, 561, 562, 563, 564, 565, 566, 568, 569, 570, 571,\n",
      "       572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 586,\n",
      "       588, 589, 590, 591, 593, 594, 595, 596, 597, 598, 599, 600, 601,\n",
      "       602, 603, 604, 605]), array([  4,  16,  20,  21,  24,  27,  32,  37,  39,  40,  42,  56,  68,\n",
      "        70,  71,  72,  78,  82,  94, 103, 108, 117, 120, 132, 136, 137,\n",
      "       138, 144, 149, 161, 165, 169, 173, 178, 182, 185, 189, 200, 216,\n",
      "       217, 218, 221, 232, 234, 244, 245, 250, 251, 254, 256, 261, 264,\n",
      "       268, 270, 273, 281, 289, 296, 297, 301, 306, 315, 321, 327, 332,\n",
      "       334, 339, 344, 345, 350, 355, 356, 365, 368, 371, 381, 382, 388,\n",
      "       392, 393, 404, 421, 423, 427, 429, 430, 434, 435, 436, 437, 439,\n",
      "       440, 446, 459, 461, 465, 479, 485, 490, 493, 495, 498, 501, 505,\n",
      "       506, 514, 524, 526, 527, 531, 535, 539, 541, 548, 552, 560, 567,\n",
      "       577, 585, 587, 592])), (array([  0,   1,   2,   3,   4,   5,   8,  10,  14,  15,  16,  18,  19,\n",
      "        20,  21,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,\n",
      "        34,  35,  36,  37,  38,  39,  40,  41,  42,  44,  45,  47,  49,\n",
      "        50,  52,  53,  54,  55,  56,  58,  59,  60,  62,  63,  66,  68,\n",
      "        70,  71,  72,  73,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "        84,  85,  86,  89,  90,  91,  92,  93,  94,  95,  97,  99, 101,\n",
      "       102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "       116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 129, 132,\n",
      "       133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149, 150, 153, 155, 156, 157, 161, 162, 164, 165, 166,\n",
      "       168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 188, 189, 192, 193, 195, 196, 198, 199,\n",
      "       200, 201, 202, 203, 204, 205, 206, 208, 209, 211, 213, 214, 216,\n",
      "       217, 218, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232,\n",
      "       233, 234, 235, 236, 237, 239, 241, 242, 243, 244, 245, 246, 247,\n",
      "       249, 250, 251, 252, 253, 254, 255, 256, 258, 259, 260, 261, 264,\n",
      "       265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
      "       278, 279, 280, 281, 282, 283, 284, 287, 288, 289, 290, 292, 293,\n",
      "       294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 306, 308,\n",
      "       309, 310, 312, 314, 315, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "       327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
      "       341, 342, 343, 344, 345, 346, 347, 349, 350, 351, 353, 354, 355,\n",
      "       356, 357, 358, 359, 362, 363, 364, 365, 366, 367, 368, 369, 371,\n",
      "       373, 374, 375, 377, 378, 379, 381, 382, 383, 384, 385, 387, 388,\n",
      "       389, 390, 391, 392, 393, 396, 397, 398, 399, 400, 401, 402, 403,\n",
      "       404, 405, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
      "       418, 419, 420, 421, 422, 423, 425, 427, 429, 430, 433, 434, 435,\n",
      "       436, 437, 438, 439, 440, 443, 444, 445, 446, 447, 449, 451, 453,\n",
      "       455, 456, 457, 459, 460, 461, 463, 464, 465, 466, 469, 470, 472,\n",
      "       473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
      "       486, 487, 488, 489, 490, 491, 493, 494, 495, 497, 498, 499, 500,\n",
      "       501, 504, 505, 506, 508, 509, 510, 511, 512, 513, 514, 515, 517,\n",
      "       518, 519, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,\n",
      "       533, 534, 535, 537, 539, 540, 541, 542, 545, 546, 547, 548, 549,\n",
      "       550, 551, 552, 553, 554, 555, 558, 559, 560, 561, 562, 563, 564,\n",
      "       565, 566, 567, 569, 570, 571, 572, 573, 575, 576, 577, 580, 581,\n",
      "       582, 583, 584, 585, 586, 587, 591, 592, 593, 595, 597, 599, 600,\n",
      "       601, 602, 603, 605]), array([  6,   7,   9,  11,  12,  13,  17,  22,  43,  46,  48,  51,  57,\n",
      "        61,  64,  65,  67,  69,  74,  87,  88,  96,  98, 100, 107, 124,\n",
      "       128, 130, 131, 140, 151, 152, 154, 158, 159, 160, 163, 167, 176,\n",
      "       187, 190, 191, 194, 197, 207, 210, 212, 215, 219, 220, 228, 238,\n",
      "       240, 248, 257, 262, 263, 285, 286, 291, 305, 307, 311, 313, 316,\n",
      "       317, 326, 330, 348, 352, 360, 361, 370, 372, 376, 380, 386, 394,\n",
      "       395, 406, 424, 426, 428, 431, 432, 441, 442, 448, 450, 452, 454,\n",
      "       458, 462, 467, 468, 471, 492, 496, 502, 503, 507, 516, 520, 532,\n",
      "       536, 538, 543, 544, 556, 557, 568, 574, 578, 579, 588, 589, 590,\n",
      "       594, 596, 598, 604]))]\n",
      "Length of concatenated dataset: 546\n",
      "Length of concatenated dataset: 546\n",
      "[(array([  1,   2,   3,   4,   6,   7,   8,   9,  10,  12,  13,  14,  15,\n",
      "        16,  17,  18,  19,  20,  21,  23,  24,  25,  26,  27,  28,  31,\n",
      "        32,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  46,  47,\n",
      "        49,  50,  51,  52,  54,  55,  56,  59,  60,  63,  64,  65,  66,\n",
      "        67,  68,  69,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
      "        82,  83,  84,  85,  86,  89,  91,  93,  94,  95,  97,  99, 100,\n",
      "       102, 103, 105, 106, 107, 109, 110, 114, 115, 116, 117, 118, 119,\n",
      "       120, 121, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134,\n",
      "       135, 136, 137, 138, 140, 141, 142, 143, 144, 146, 147, 148, 149,\n",
      "       150, 153, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 166,\n",
      "       167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 179, 180, 181,\n",
      "       182, 183, 184, 186, 187, 188, 189, 190, 191, 193, 195, 196, 197,\n",
      "       198, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212,\n",
      "       214, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227,\n",
      "       228, 229, 230, 232, 234, 235, 238, 239, 240, 241, 242, 244, 245,\n",
      "       246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 264, 265, 266, 267, 268, 269, 271, 272, 273, 275, 276,\n",
      "       277, 278, 279, 280, 281, 282, 283, 284, 287, 288, 289, 290, 291,\n",
      "       295, 297, 298, 299, 302, 303, 304, 305, 306, 308, 310, 311, 312,\n",
      "       313, 316, 317, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
      "       331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344,\n",
      "       345, 347, 350, 351, 352, 353, 354, 355, 356, 357, 359, 360, 361,\n",
      "       362, 363, 364, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375,\n",
      "       376, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 393, 394, 395, 396, 397, 399, 400, 401, 404, 405, 406,\n",
      "       407, 408, 409, 410, 411, 413, 414, 415, 417, 418, 419, 420, 421,\n",
      "       422, 423, 424, 427, 428, 429, 430, 432, 434, 435, 436, 437, 438,\n",
      "       439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 453,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479, 480, 482,\n",
      "       484, 485, 487, 488, 489, 490, 492, 493, 494, 496, 497, 498, 499,\n",
      "       500, 501, 503, 506, 510, 511, 512, 513, 514, 517, 519, 520, 521,\n",
      "       523, 524, 525, 526, 528, 529, 530, 531, 533, 534, 535, 536, 537,\n",
      "       538, 539, 540, 542, 543, 544, 545]), array([  0,   5,  11,  22,  29,  30,  33,  44,  45,  48,  53,  57,  58,\n",
      "        61,  62,  70,  71,  87,  88,  90,  92,  96,  98, 101, 104, 108,\n",
      "       111, 112, 113, 122, 130, 139, 145, 151, 152, 154, 158, 176, 178,\n",
      "       185, 192, 194, 199, 210, 213, 219, 231, 233, 236, 237, 243, 252,\n",
      "       262, 263, 270, 274, 285, 286, 292, 293, 294, 296, 300, 301, 307,\n",
      "       309, 314, 315, 318, 319, 330, 333, 346, 348, 349, 358, 371, 377,\n",
      "       392, 398, 402, 403, 412, 416, 425, 426, 431, 433, 440, 452, 454,\n",
      "       478, 481, 483, 486, 491, 495, 502, 504, 505, 507, 508, 509, 515,\n",
      "       516, 518, 522, 527, 532, 541])), (array([  0,   1,   2,   3,   4,   5,   6,   7,   9,  10,  11,  12,  14,\n",
      "        15,  16,  17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  28,\n",
      "        29,  30,  31,  32,  33,  34,  35,  36,  39,  40,  41,  42,  44,\n",
      "        45,  46,  48,  49,  52,  53,  54,  55,  56,  57,  58,  59,  60,\n",
      "        61,  62,  63,  64,  65,  67,  68,  69,  70,  71,  72,  73,  74,\n",
      "        77,  78,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
      "       118, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 132, 134,\n",
      "       135, 136, 137, 139, 140, 143, 144, 145, 146, 147, 148, 151, 152,\n",
      "       153, 154, 155, 158, 160, 161, 162, 164, 165, 166, 167, 168, 170,\n",
      "       171, 172, 173, 176, 178, 180, 184, 185, 186, 187, 188, 189, 190,\n",
      "       192, 194, 195, 196, 197, 199, 200, 202, 203, 206, 207, 208, 210,\n",
      "       211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 223, 224, 225,\n",
      "       226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239,\n",
      "       240, 242, 243, 246, 247, 248, 251, 252, 253, 254, 255, 258, 259,\n",
      "       261, 262, 263, 264, 266, 267, 268, 269, 270, 271, 273, 274, 275,\n",
      "       276, 278, 279, 281, 282, 284, 285, 286, 288, 289, 290, 291, 292,\n",
      "       293, 294, 295, 296, 299, 300, 301, 303, 304, 306, 307, 308, 309,\n",
      "       311, 313, 314, 315, 318, 319, 320, 321, 324, 325, 326, 327, 328,\n",
      "       329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 341, 342, 343,\n",
      "       344, 345, 346, 347, 348, 349, 351, 352, 353, 354, 356, 358, 359,\n",
      "       360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
      "       374, 375, 376, 377, 378, 379, 380, 382, 383, 384, 385, 387, 388,\n",
      "       389, 390, 391, 392, 393, 394, 395, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 408, 409, 411, 412, 413, 414, 415, 416, 418,\n",
      "       419, 420, 421, 422, 423, 424, 425, 426, 429, 431, 432, 433, 434,\n",
      "       435, 438, 439, 440, 441, 442, 443, 444, 445, 447, 449, 450, 451,\n",
      "       452, 454, 456, 457, 458, 459, 460, 461, 463, 466, 467, 468, 470,\n",
      "       471, 472, 473, 474, 475, 476, 477, 478, 480, 481, 482, 483, 484,\n",
      "       485, 486, 487, 488, 490, 491, 492, 493, 495, 497, 498, 499, 500,\n",
      "       501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 514,\n",
      "       515, 516, 518, 519, 520, 522, 524, 525, 527, 528, 529, 531, 532,\n",
      "       534, 539, 540, 541, 542, 543, 544, 545]), array([  8,  13,  21,  37,  38,  43,  47,  50,  51,  66,  75,  76,  79,\n",
      "        95, 119, 126, 131, 133, 138, 141, 142, 149, 150, 156, 157, 159,\n",
      "       163, 169, 174, 175, 177, 179, 181, 182, 183, 191, 193, 198, 201,\n",
      "       204, 205, 209, 221, 222, 238, 241, 244, 245, 249, 250, 256, 257,\n",
      "       260, 265, 272, 277, 280, 283, 287, 297, 298, 302, 305, 310, 312,\n",
      "       316, 317, 322, 323, 339, 340, 350, 355, 357, 364, 381, 386, 396,\n",
      "       407, 410, 417, 427, 428, 430, 436, 437, 446, 448, 453, 455, 462,\n",
      "       464, 465, 469, 479, 489, 494, 496, 513, 517, 521, 523, 526, 530,\n",
      "       533, 535, 536, 537, 538])), (array([  0,   2,   3,   4,   5,   6,   7,   8,  10,  11,  13,  14,  15,\n",
      "        16,  17,  21,  22,  23,  24,  26,  27,  28,  29,  30,  33,  34,\n",
      "        35,  36,  37,  38,  40,  43,  44,  45,  46,  47,  48,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  64,  66,\n",
      "        67,  68,  69,  70,  71,  73,  75,  76,  78,  79,  81,  82,  83,\n",
      "        85,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "        99, 100, 101, 103, 104, 107, 108, 109, 110, 111, 112, 113, 115,\n",
      "       116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
      "       131, 133, 135, 136, 138, 139, 141, 142, 143, 144, 145, 147, 148,\n",
      "       149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 163, 165,\n",
      "       167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180,\n",
      "       181, 182, 183, 185, 186, 188, 189, 190, 191, 192, 193, 194, 196,\n",
      "       197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 209, 210, 211,\n",
      "       213, 215, 216, 217, 218, 219, 221, 222, 223, 224, 225, 226, 227,\n",
      "       228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
      "       243, 244, 245, 247, 248, 249, 250, 252, 253, 254, 256, 257, 259,\n",
      "       260, 261, 262, 263, 265, 266, 267, 270, 271, 272, 273, 274, 275,\n",
      "       276, 277, 279, 280, 281, 283, 285, 286, 287, 288, 289, 292, 293,\n",
      "       294, 295, 296, 297, 298, 300, 301, 302, 304, 305, 306, 307, 308,\n",
      "       309, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 322, 323,\n",
      "       325, 326, 327, 328, 330, 331, 332, 333, 334, 335, 337, 339, 340,\n",
      "       341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354,\n",
      "       355, 356, 357, 358, 360, 363, 364, 366, 367, 368, 371, 372, 373,\n",
      "       376, 377, 380, 381, 382, 384, 385, 386, 390, 392, 394, 395, 396,\n",
      "       397, 398, 399, 400, 402, 403, 404, 406, 407, 408, 410, 412, 415,\n",
      "       416, 417, 418, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429,\n",
      "       430, 431, 432, 433, 434, 435, 436, 437, 440, 442, 443, 444, 445,\n",
      "       446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 459, 461,\n",
      "       462, 464, 465, 466, 467, 468, 469, 472, 473, 474, 476, 477, 478,\n",
      "       479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492,\n",
      "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
      "       507, 508, 509, 510, 511, 513, 514, 515, 516, 517, 518, 519, 520,\n",
      "       521, 522, 523, 526, 527, 528, 530, 531, 532, 533, 534, 535, 536,\n",
      "       537, 538, 539, 540, 541, 543, 544, 545]), array([  1,   9,  12,  18,  19,  20,  25,  31,  32,  39,  41,  42,  49,\n",
      "        63,  65,  72,  74,  77,  80,  84,  86, 102, 105, 106, 114, 118,\n",
      "       128, 132, 134, 137, 140, 146, 155, 161, 162, 164, 166, 168, 184,\n",
      "       187, 195, 206, 208, 212, 214, 220, 232, 242, 246, 251, 255, 258,\n",
      "       264, 268, 269, 278, 282, 284, 290, 291, 299, 303, 313, 321, 324,\n",
      "       329, 336, 338, 345, 359, 361, 362, 365, 369, 370, 374, 375, 378,\n",
      "       379, 383, 387, 388, 389, 391, 393, 401, 405, 409, 411, 413, 414,\n",
      "       421, 438, 439, 441, 447, 458, 460, 463, 470, 471, 475, 485, 493,\n",
      "       512, 524, 525, 529, 542])), (array([  0,   1,   2,   3,   4,   5,   7,   8,   9,  10,  11,  12,  13,\n",
      "        15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  27,  29,\n",
      "        30,  31,  32,  33,  34,  37,  38,  39,  41,  42,  43,  44,  45,\n",
      "        47,  48,  49,  50,  51,  53,  54,  55,  57,  58,  59,  60,  61,\n",
      "        62,  63,  64,  65,  66,  68,  70,  71,  72,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  86,  87,  88,  90,  92,  95,\n",
      "        96,  98, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112,\n",
      "       113, 114, 115, 116, 117, 118, 119, 122, 123, 124, 126, 127, 128,\n",
      "       129, 130, 131, 132, 133, 134, 137, 138, 139, 140, 141, 142, 144,\n",
      "       145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "       159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 173,\n",
      "       174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187,\n",
      "       190, 191, 192, 193, 194, 195, 196, 198, 199, 201, 203, 204, 205,\n",
      "       206, 207, 208, 209, 210, 212, 213, 214, 215, 216, 219, 220, 221,\n",
      "       222, 225, 226, 230, 231, 232, 233, 236, 237, 238, 241, 242, 243,\n",
      "       244, 245, 246, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258,\n",
      "       260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 272, 274, 276,\n",
      "       277, 278, 280, 281, 282, 283, 284, 285, 286, 287, 290, 291, 292,\n",
      "       293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306,\n",
      "       307, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "       322, 323, 324, 329, 330, 331, 333, 334, 335, 336, 338, 339, 340,\n",
      "       342, 343, 345, 346, 348, 349, 350, 352, 355, 356, 357, 358, 359,\n",
      "       361, 362, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 375,\n",
      "       376, 377, 378, 379, 381, 383, 385, 386, 387, 388, 389, 390, 391,\n",
      "       392, 393, 395, 396, 397, 398, 401, 402, 403, 404, 405, 406, 407,\n",
      "       408, 409, 410, 411, 412, 413, 414, 416, 417, 420, 421, 422, 425,\n",
      "       426, 427, 428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 439,\n",
      "       440, 441, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 458, 460, 461, 462, 463, 464, 465, 466, 467, 469, 470, 471,\n",
      "       473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
      "       486, 489, 491, 492, 493, 494, 495, 496, 497, 498, 502, 504, 505,\n",
      "       506, 507, 508, 509, 510, 512, 513, 515, 516, 517, 518, 519, 521,\n",
      "       522, 523, 524, 525, 526, 527, 529, 530, 532, 533, 534, 535, 536,\n",
      "       537, 538, 539, 540, 541, 542, 544, 545]), array([  6,  14,  26,  28,  35,  36,  40,  46,  52,  56,  67,  69,  73,\n",
      "        85,  89,  91,  93,  94,  97,  99, 100, 110, 120, 121, 125, 135,\n",
      "       136, 143, 147, 170, 172, 186, 188, 189, 197, 200, 202, 211, 217,\n",
      "       218, 223, 224, 227, 228, 229, 234, 235, 239, 240, 247, 254, 259,\n",
      "       267, 271, 273, 275, 279, 288, 289, 304, 308, 311, 325, 326, 327,\n",
      "       328, 332, 337, 341, 344, 347, 351, 353, 354, 360, 363, 366, 380,\n",
      "       382, 384, 394, 399, 400, 415, 418, 419, 423, 424, 434, 442, 445,\n",
      "       456, 457, 459, 468, 472, 487, 488, 490, 499, 500, 501, 503, 511,\n",
      "       514, 520, 528, 531, 543])), (array([  0,   1,   5,   6,   8,   9,  11,  12,  13,  14,  18,  19,  20,\n",
      "        21,  22,  25,  26,  28,  29,  30,  31,  32,  33,  35,  36,  37,\n",
      "        38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,\n",
      "        51,  52,  53,  56,  57,  58,  61,  62,  63,  65,  66,  67,  69,\n",
      "        70,  71,  72,  73,  74,  75,  76,  77,  79,  80,  84,  85,  86,\n",
      "        87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
      "       100, 101, 102, 104, 105, 106, 108, 110, 111, 112, 113, 114, 118,\n",
      "       119, 120, 121, 122, 125, 126, 128, 130, 131, 132, 133, 134, 135,\n",
      "       136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 149, 150,\n",
      "       151, 152, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 166,\n",
      "       168, 169, 170, 172, 174, 175, 176, 177, 178, 179, 181, 182, 183,\n",
      "       184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 197, 198,\n",
      "       199, 200, 201, 202, 204, 205, 206, 208, 209, 210, 211, 212, 213,\n",
      "       214, 217, 218, 219, 220, 221, 222, 223, 224, 227, 228, 229, 231,\n",
      "       232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
      "       245, 246, 247, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259,\n",
      "       260, 262, 263, 264, 265, 267, 268, 269, 270, 271, 272, 273, 274,\n",
      "       275, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 288, 289,\n",
      "       290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 303,\n",
      "       304, 305, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317,\n",
      "       318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 332,\n",
      "       333, 336, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349,\n",
      "       350, 351, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364,\n",
      "       365, 366, 369, 370, 371, 374, 375, 377, 378, 379, 380, 381, 382,\n",
      "       383, 384, 386, 387, 388, 389, 391, 392, 393, 394, 396, 398, 399,\n",
      "       400, 401, 402, 403, 405, 407, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 421, 423, 424, 425, 426, 427, 428, 430, 431,\n",
      "       433, 434, 436, 437, 438, 439, 440, 441, 442, 445, 446, 447, 448,\n",
      "       452, 453, 454, 455, 456, 457, 458, 459, 460, 462, 463, 464, 465,\n",
      "       468, 469, 470, 471, 472, 475, 478, 479, 481, 483, 485, 486, 487,\n",
      "       488, 489, 490, 491, 493, 494, 495, 496, 499, 500, 501, 502, 503,\n",
      "       504, 505, 507, 508, 509, 511, 512, 513, 514, 515, 516, 517, 518,\n",
      "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
      "       533, 535, 536, 537, 538, 541, 542, 543]), array([  2,   3,   4,   7,  10,  15,  16,  17,  23,  24,  27,  34,  54,\n",
      "        55,  59,  60,  64,  68,  78,  81,  82,  83, 103, 107, 109, 115,\n",
      "       116, 117, 123, 124, 127, 129, 144, 148, 153, 160, 165, 167, 171,\n",
      "       173, 180, 190, 196, 203, 207, 215, 216, 225, 226, 230, 248, 253,\n",
      "       261, 266, 276, 281, 295, 306, 320, 331, 334, 335, 342, 343, 352,\n",
      "       356, 367, 368, 372, 373, 376, 385, 390, 395, 397, 404, 406, 408,\n",
      "       420, 422, 429, 432, 435, 443, 444, 449, 450, 451, 461, 466, 467,\n",
      "       473, 474, 476, 477, 480, 482, 484, 492, 497, 498, 506, 510, 519,\n",
      "       534, 539, 540, 544, 545]))]\n",
      "Length of concatenated dataset: 1092\n",
      "Length of concatenated dataset: 1092\n",
      "[(array([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
      "         11,   12,   13,   14,   15,   16,   20,   21,   22,   23,   26,\n",
      "         27,   28,   29,   30,   31,   36,   37,   38,   39,   40,   42,\n",
      "         43,   44,   45,   46,   48,   49,   50,   51,   53,   54,   55,\n",
      "         57,   58,   59,   62,   63,   64,   65,   66,   67,   68,   70,\n",
      "         72,   73,   74,   75,   76,   77,   78,   79,   80,   81,   83,\n",
      "         84,   85,   86,   87,   88,   89,   90,   91,   92,   93,   94,\n",
      "         95,   97,   98,  100,  101,  102,  104,  105,  106,  107,  108,\n",
      "        109,  110,  114,  115,  116,  117,  118,  120,  121,  122,  123,\n",
      "        124,  125,  126,  127,  128,  130,  131,  132,  133,  134,  135,\n",
      "        136,  137,  138,  139,  140,  141,  142,  144,  148,  149,  150,\n",
      "        151,  152,  153,  154,  155,  156,  157,  158,  159,  160,  161,\n",
      "        162,  163,  164,  165,  166,  167,  168,  169,  170,  171,  172,\n",
      "        174,  177,  179,  180,  181,  184,  185,  186,  187,  188,  189,\n",
      "        190,  192,  193,  194,  195,  196,  197,  198,  199,  200,  203,\n",
      "        204,  205,  206,  207,  208,  209,  210,  211,  212,  214,  215,\n",
      "        216,  217,  218,  220,  221,  222,  223,  224,  225,  226,  227,\n",
      "        228,  229,  230,  232,  233,  234,  236,  237,  238,  239,  240,\n",
      "        241,  242,  243,  244,  245,  246,  247,  249,  250,  251,  252,\n",
      "        253,  254,  255,  256,  258,  259,  260,  261,  262,  265,  266,\n",
      "        267,  268,  269,  270,  271,  272,  275,  276,  278,  279,  282,\n",
      "        283,  285,  286,  287,  288,  289,  291,  292,  294,  295,  299,\n",
      "        300,  301,  302,  304,  305,  306,  307,  309,  314,  315,  316,\n",
      "        317,  318,  319,  320,  321,  322,  323,  324,  326,  327,  328,\n",
      "        329,  330,  331,  333,  334,  335,  336,  337,  340,  341,  342,\n",
      "        343,  344,  345,  346,  348,  349,  350,  351,  352,  353,  354,\n",
      "        355,  357,  358,  360,  361,  362,  364,  367,  370,  371,  372,\n",
      "        373,  374,  375,  376,  377,  378,  379,  380,  382,  384,  385,\n",
      "        386,  387,  388,  389,  390,  391,  392,  393,  394,  395,  396,\n",
      "        397,  398,  399,  400,  402,  404,  405,  407,  408,  409,  410,\n",
      "        411,  413,  414,  416,  418,  419,  420,  422,  423,  425,  426,\n",
      "        428,  429,  430,  431,  432,  433,  435,  436,  437,  439,  440,\n",
      "        441,  442,  443,  444,  445,  446,  447,  449,  450,  451,  452,\n",
      "        454,  455,  457,  458,  459,  460,  461,  463,  465,  466,  467,\n",
      "        469,  470,  471,  472,  473,  474,  475,  476,  477,  478,  480,\n",
      "        481,  482,  483,  484,  486,  487,  488,  489,  490,  491,  492,\n",
      "        493,  494,  496,  497,  498,  499,  500,  501,  502,  503,  504,\n",
      "        505,  507,  509,  510,  511,  512,  513,  514,  515,  516,  517,\n",
      "        518,  519,  520,  522,  524,  525,  527,  529,  530,  531,  533,\n",
      "        535,  536,  537,  538,  539,  540,  543,  546,  547,  548,  549,\n",
      "        550,  551,  552,  553,  554,  555,  556,  557,  558,  559,  560,\n",
      "        561,  562,  563,  564,  566,  567,  568,  571,  572,  573,  574,\n",
      "        575,  577,  578,  579,  580,  581,  582,  583,  584,  585,  586,\n",
      "        587,  589,  590,  593,  594,  595,  597,  600,  601,  602,  603,\n",
      "        604,  605,  606,  608,  609,  610,  611,  612,  613,  615,  617,\n",
      "        618,  619,  620,  621,  622,  625,  626,  628,  629,  630,  632,\n",
      "        633,  634,  635,  636,  637,  638,  639,  640,  641,  642,  643,\n",
      "        644,  646,  647,  648,  649,  650,  652,  653,  654,  655,  656,\n",
      "        657,  658,  659,  660,  661,  662,  663,  664,  666,  668,  669,\n",
      "        670,  671,  672,  674,  675,  676,  679,  680,  681,  682,  683,\n",
      "        684,  685,  686,  687,  689,  691,  692,  694,  695,  696,  697,\n",
      "        698,  699,  700,  701,  702,  703,  704,  705,  707,  711,  712,\n",
      "        714,  716,  717,  718,  719,  720,  721,  722,  723,  724,  726,\n",
      "        728,  729,  731,  732,  733,  734,  735,  736,  738,  740,  741,\n",
      "        742,  743,  744,  746,  748,  749,  750,  752,  754,  756,  757,\n",
      "        758,  759,  760,  761,  764,  766,  767,  769,  770,  773,  774,\n",
      "        775,  777,  778,  779,  780,  781,  783,  784,  785,  786,  787,\n",
      "        789,  790,  791,  792,  793,  794,  795,  796,  797,  798,  799,\n",
      "        800,  801,  802,  803,  805,  807,  808,  809,  810,  811,  812,\n",
      "        813,  814,  817,  819,  820,  822,  823,  825,  826,  827,  828,\n",
      "        830,  831,  833,  834,  835,  836,  837,  838,  839,  840,  841,\n",
      "        842,  844,  846,  847,  848,  849,  850,  852,  853,  854,  855,\n",
      "        856,  857,  858,  859,  860,  861,  863,  864,  865,  866,  867,\n",
      "        868,  869,  870,  871,  872,  874,  876,  877,  879,  882,  883,\n",
      "        884,  885,  886,  888,  889,  890,  892,  894,  895,  896,  897,\n",
      "        898,  900,  901,  902,  903,  904,  905,  906,  907,  908,  910,\n",
      "        911,  912,  913,  914,  915,  916,  917,  918,  919,  920,  921,\n",
      "        922,  923,  924,  925,  927,  928,  929,  930,  931,  932,  933,\n",
      "        934,  935,  938,  939,  940,  941,  942,  943,  944,  945,  946,\n",
      "        947,  948,  949,  950,  951,  953,  956,  957,  958,  959,  960,\n",
      "        961,  962,  963,  965,  966,  967,  968,  969,  971,  972,  974,\n",
      "        975,  978,  979,  980,  982,  984,  985,  988,  989,  990,  991,\n",
      "        992,  993,  994,  995,  996,  997,  998,  999, 1000, 1002, 1003,\n",
      "       1004, 1005, 1006, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015,\n",
      "       1016, 1017, 1022, 1024, 1025, 1026, 1027, 1028, 1030, 1031, 1032,\n",
      "       1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1042, 1043, 1044,\n",
      "       1045, 1047, 1048, 1049, 1050, 1052, 1053, 1054, 1055, 1056, 1057,\n",
      "       1058, 1059, 1061, 1062, 1063, 1064, 1066, 1069, 1071, 1072, 1074,\n",
      "       1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1086,\n",
      "       1087, 1088, 1089, 1091]), array([  17,   18,   19,   24,   25,   32,   33,   34,   35,   41,   47,\n",
      "         52,   56,   60,   61,   69,   71,   82,   96,   99,  103,  111,\n",
      "        112,  113,  119,  129,  143,  145,  146,  147,  173,  175,  176,\n",
      "        178,  182,  183,  191,  201,  202,  213,  219,  231,  235,  248,\n",
      "        257,  263,  264,  273,  274,  277,  280,  281,  284,  290,  293,\n",
      "        296,  297,  298,  303,  308,  310,  311,  312,  313,  325,  332,\n",
      "        338,  339,  347,  356,  359,  363,  365,  366,  368,  369,  381,\n",
      "        383,  401,  403,  406,  412,  415,  417,  421,  424,  427,  434,\n",
      "        438,  448,  453,  456,  462,  464,  468,  479,  485,  495,  506,\n",
      "        508,  521,  523,  526,  528,  532,  534,  541,  542,  544,  545,\n",
      "        565,  569,  570,  576,  588,  591,  592,  596,  598,  599,  607,\n",
      "        614,  616,  623,  624,  627,  631,  645,  651,  665,  667,  673,\n",
      "        677,  678,  688,  690,  693,  706,  708,  709,  710,  713,  715,\n",
      "        725,  727,  730,  737,  739,  745,  747,  751,  753,  755,  762,\n",
      "        763,  765,  768,  771,  772,  776,  782,  788,  804,  806,  815,\n",
      "        816,  818,  821,  824,  829,  832,  843,  845,  851,  862,  873,\n",
      "        875,  878,  880,  881,  887,  891,  893,  899,  909,  926,  936,\n",
      "        937,  952,  954,  955,  964,  970,  973,  976,  977,  981,  983,\n",
      "        986,  987, 1001, 1007, 1018, 1019, 1020, 1021, 1023, 1029, 1041,\n",
      "       1046, 1051, 1060, 1065, 1067, 1068, 1070, 1073, 1085, 1090])), (array([   0,    1,    2,    3,    4,    6,    7,    9,   10,   11,   15,\n",
      "         17,   18,   19,   20,   21,   22,   24,   25,   26,   27,   28,\n",
      "         29,   31,   32,   33,   34,   35,   37,   38,   39,   40,   41,\n",
      "         42,   43,   44,   45,   46,   47,   48,   49,   50,   52,   53,\n",
      "         54,   56,   58,   59,   60,   61,   62,   65,   66,   67,   68,\n",
      "         69,   71,   72,   73,   74,   75,   76,   78,   79,   80,   81,\n",
      "         82,   83,   84,   85,   86,   87,   89,   90,   91,   92,   94,\n",
      "         95,   96,   99,  100,  101,  102,  103,  104,  105,  107,  110,\n",
      "        111,  112,  113,  114,  115,  116,  117,  119,  121,  122,  123,\n",
      "        124,  125,  126,  128,  129,  132,  134,  135,  136,  137,  138,\n",
      "        139,  140,  142,  143,  145,  146,  147,  148,  149,  150,  151,\n",
      "        155,  156,  157,  158,  159,  161,  162,  164,  165,  166,  167,\n",
      "        170,  171,  172,  173,  174,  175,  176,  178,  179,  181,  182,\n",
      "        183,  185,  186,  188,  189,  191,  192,  193,  194,  196,  197,\n",
      "        198,  199,  200,  201,  202,  203,  204,  205,  206,  208,  210,\n",
      "        211,  213,  214,  215,  216,  219,  220,  223,  224,  225,  226,\n",
      "        227,  228,  229,  230,  231,  232,  233,  234,  235,  236,  237,\n",
      "        238,  241,  243,  244,  245,  246,  247,  248,  249,  250,  251,\n",
      "        252,  253,  254,  255,  257,  258,  259,  261,  262,  263,  264,\n",
      "        265,  266,  267,  268,  269,  271,  273,  274,  275,  276,  277,\n",
      "        278,  279,  280,  281,  282,  283,  284,  285,  287,  288,  290,\n",
      "        291,  292,  293,  295,  296,  297,  298,  299,  300,  301,  302,\n",
      "        303,  305,  306,  307,  308,  309,  310,  311,  312,  313,  315,\n",
      "        318,  320,  321,  325,  326,  327,  328,  329,  331,  332,  333,\n",
      "        334,  337,  338,  339,  340,  341,  342,  344,  345,  346,  347,\n",
      "        348,  349,  351,  354,  355,  356,  357,  358,  359,  361,  362,\n",
      "        363,  364,  365,  366,  367,  368,  369,  372,  373,  374,  376,\n",
      "        377,  378,  379,  380,  381,  382,  383,  384,  385,  386,  387,\n",
      "        388,  389,  390,  391,  392,  393,  394,  395,  397,  398,  399,\n",
      "        400,  401,  403,  404,  406,  407,  408,  409,  410,  411,  412,\n",
      "        413,  415,  416,  417,  418,  419,  420,  421,  422,  423,  424,\n",
      "        425,  426,  427,  430,  431,  432,  433,  434,  437,  438,  439,\n",
      "        441,  443,  445,  447,  448,  449,  450,  452,  453,  454,  455,\n",
      "        456,  457,  458,  459,  460,  461,  462,  463,  464,  465,  467,\n",
      "        468,  470,  471,  472,  473,  474,  475,  476,  477,  478,  479,\n",
      "        480,  481,  483,  484,  485,  486,  487,  489,  490,  491,  493,\n",
      "        494,  495,  496,  497,  499,  500,  501,  503,  505,  506,  508,\n",
      "        509,  510,  512,  513,  514,  515,  516,  518,  519,  520,  521,\n",
      "        523,  524,  525,  526,  528,  529,  530,  532,  533,  534,  537,\n",
      "        538,  539,  540,  541,  542,  543,  544,  545,  546,  548,  549,\n",
      "        551,  552,  553,  554,  556,  557,  558,  559,  562,  564,  565,\n",
      "        566,  568,  569,  570,  571,  572,  573,  574,  575,  576,  577,\n",
      "        578,  579,  580,  583,  585,  586,  588,  590,  591,  592,  593,\n",
      "        594,  595,  596,  598,  599,  600,  602,  603,  604,  607,  608,\n",
      "        609,  610,  611,  612,  613,  614,  615,  616,  617,  618,  619,\n",
      "        620,  623,  624,  625,  626,  627,  628,  629,  631,  632,  633,\n",
      "        634,  635,  637,  638,  640,  641,  642,  643,  644,  645,  647,\n",
      "        648,  649,  650,  651,  652,  653,  654,  655,  657,  658,  660,\n",
      "        663,  664,  665,  666,  667,  668,  669,  670,  671,  672,  673,\n",
      "        674,  675,  676,  677,  678,  681,  684,  685,  686,  688,  689,\n",
      "        690,  691,  692,  693,  694,  695,  697,  698,  699,  700,  702,\n",
      "        703,  704,  705,  706,  707,  708,  709,  710,  712,  713,  715,\n",
      "        717,  718,  719,  720,  721,  722,  723,  724,  725,  726,  727,\n",
      "        728,  729,  730,  731,  734,  735,  737,  738,  739,  740,  742,\n",
      "        743,  744,  745,  746,  747,  748,  750,  751,  752,  753,  754,\n",
      "        755,  756,  757,  758,  759,  762,  763,  765,  766,  767,  768,\n",
      "        771,  772,  773,  776,  778,  779,  780,  781,  782,  783,  784,\n",
      "        785,  788,  789,  790,  791,  792,  793,  794,  795,  800,  801,\n",
      "        802,  803,  804,  805,  806,  807,  810,  811,  812,  815,  816,\n",
      "        817,  818,  819,  820,  821,  822,  823,  824,  827,  828,  829,\n",
      "        831,  832,  833,  834,  835,  836,  837,  838,  840,  841,  842,\n",
      "        843,  844,  845,  846,  847,  849,  851,  852,  854,  855,  856,\n",
      "        857,  858,  859,  861,  862,  863,  866,  868,  869,  870,  871,\n",
      "        872,  873,  874,  875,  876,  877,  878,  879,  880,  881,  882,\n",
      "        883,  885,  886,  887,  888,  889,  890,  891,  893,  894,  895,\n",
      "        896,  897,  899,  901,  904,  905,  906,  907,  908,  909,  911,\n",
      "        912,  913,  914,  916,  917,  918,  919,  921,  922,  923,  924,\n",
      "        925,  926,  927,  928,  929,  930,  931,  933,  935,  936,  937,\n",
      "        939,  940,  941,  942,  943,  946,  947,  948,  949,  950,  951,\n",
      "        952,  953,  954,  955,  956,  958,  959,  960,  962,  963,  964,\n",
      "        965,  967,  968,  969,  970,  971,  972,  973,  974,  975,  976,\n",
      "        977,  978,  979,  981,  983,  984,  985,  986,  987,  988,  989,\n",
      "        990,  991,  992,  994,  996,  997,  998, 1001, 1002, 1004, 1005,\n",
      "       1007, 1009, 1011, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1020,\n",
      "       1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031,\n",
      "       1033, 1034, 1035, 1038, 1040, 1041, 1043, 1044, 1045, 1046, 1047,\n",
      "       1048, 1049, 1050, 1051, 1052, 1053, 1055, 1056, 1057, 1058, 1059,\n",
      "       1060, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1070, 1071, 1072,\n",
      "       1073, 1074, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1085, 1086,\n",
      "       1087, 1088, 1090, 1091]), array([   5,    8,   12,   13,   14,   16,   23,   30,   36,   51,   55,\n",
      "         57,   63,   64,   70,   77,   88,   93,   97,   98,  106,  108,\n",
      "        109,  118,  120,  127,  130,  131,  133,  141,  144,  152,  153,\n",
      "        154,  160,  163,  168,  169,  177,  180,  184,  187,  190,  195,\n",
      "        207,  209,  212,  217,  218,  221,  222,  239,  240,  242,  256,\n",
      "        260,  270,  272,  286,  289,  294,  304,  314,  316,  317,  319,\n",
      "        322,  323,  324,  330,  335,  336,  343,  350,  352,  353,  360,\n",
      "        370,  371,  375,  396,  402,  405,  414,  428,  429,  435,  436,\n",
      "        440,  442,  444,  446,  451,  466,  469,  482,  488,  492,  498,\n",
      "        502,  504,  507,  511,  517,  522,  527,  531,  535,  536,  547,\n",
      "        550,  555,  560,  561,  563,  567,  581,  582,  584,  587,  589,\n",
      "        597,  601,  605,  606,  621,  622,  630,  636,  639,  646,  656,\n",
      "        659,  661,  662,  679,  680,  682,  683,  687,  696,  701,  711,\n",
      "        714,  716,  732,  733,  736,  741,  749,  760,  761,  764,  769,\n",
      "        770,  774,  775,  777,  786,  787,  796,  797,  798,  799,  808,\n",
      "        809,  813,  814,  825,  826,  830,  839,  848,  850,  853,  860,\n",
      "        864,  865,  867,  884,  892,  898,  900,  902,  903,  910,  915,\n",
      "        920,  932,  934,  938,  944,  945,  957,  961,  966,  980,  982,\n",
      "        993,  995,  999, 1000, 1003, 1006, 1008, 1010, 1017, 1032, 1036,\n",
      "       1037, 1039, 1042, 1054, 1061, 1069, 1075, 1076, 1084, 1089])), (array([   0,    2,    3,    5,    6,    7,    8,    9,   11,   12,   13,\n",
      "         14,   15,   16,   17,   18,   19,   21,   22,   23,   24,   25,\n",
      "         26,   27,   28,   29,   30,   31,   32,   33,   34,   35,   36,\n",
      "         37,   38,   40,   41,   44,   47,   48,   49,   51,   52,   53,\n",
      "         55,   56,   57,   58,   60,   61,   63,   64,   65,   66,   67,\n",
      "         68,   69,   70,   71,   73,   74,   76,   77,   79,   80,   82,\n",
      "         83,   84,   86,   87,   88,   89,   90,   91,   92,   93,   95,\n",
      "         96,   97,   98,   99,  101,  102,  103,  104,  105,  106,  108,\n",
      "        109,  110,  111,  112,  113,  114,  115,  117,  118,  119,  120,\n",
      "        121,  122,  123,  124,  125,  126,  127,  128,  129,  130,  131,\n",
      "        133,  134,  135,  136,  137,  141,  143,  144,  145,  146,  147,\n",
      "        148,  149,  150,  151,  152,  153,  154,  155,  156,  157,  158,\n",
      "        159,  160,  161,  162,  163,  165,  166,  168,  169,  171,  172,\n",
      "        173,  174,  175,  176,  177,  178,  179,  180,  181,  182,  183,\n",
      "        184,  185,  186,  187,  189,  190,  191,  193,  194,  195,  196,\n",
      "        198,  200,  201,  202,  203,  204,  205,  206,  207,  208,  209,\n",
      "        211,  212,  213,  217,  218,  219,  220,  221,  222,  223,  224,\n",
      "        226,  227,  228,  231,  232,  233,  235,  238,  239,  240,  241,\n",
      "        242,  243,  244,  245,  246,  247,  248,  250,  251,  253,  255,\n",
      "        256,  257,  259,  260,  261,  262,  263,  264,  265,  267,  268,\n",
      "        269,  270,  271,  272,  273,  274,  275,  277,  278,  280,  281,\n",
      "        282,  284,  286,  288,  289,  290,  292,  293,  294,  295,  296,\n",
      "        297,  298,  299,  300,  301,  303,  304,  306,  307,  308,  309,\n",
      "        310,  311,  312,  313,  314,  316,  317,  318,  319,  320,  321,\n",
      "        322,  323,  324,  325,  326,  327,  328,  329,  330,  331,  332,\n",
      "        333,  334,  335,  336,  337,  338,  339,  341,  343,  344,  345,\n",
      "        347,  348,  350,  352,  353,  356,  358,  359,  360,  361,  363,\n",
      "        364,  365,  366,  368,  369,  370,  371,  373,  374,  375,  376,\n",
      "        378,  379,  381,  383,  386,  387,  388,  389,  391,  392,  393,\n",
      "        394,  395,  396,  397,  400,  401,  402,  403,  405,  406,  407,\n",
      "        410,  411,  412,  413,  414,  415,  417,  418,  419,  420,  421,\n",
      "        424,  425,  426,  427,  428,  429,  434,  435,  436,  437,  438,\n",
      "        439,  440,  441,  442,  443,  444,  445,  446,  447,  448,  449,\n",
      "        450,  451,  452,  453,  456,  459,  462,  464,  465,  466,  468,\n",
      "        469,  470,  471,  472,  473,  476,  477,  479,  480,  481,  482,\n",
      "        483,  485,  486,  487,  488,  489,  490,  491,  492,  493,  494,\n",
      "        495,  497,  498,  501,  502,  503,  504,  505,  506,  507,  508,\n",
      "        511,  513,  514,  515,  516,  517,  518,  520,  521,  522,  523,\n",
      "        526,  527,  528,  529,  530,  531,  532,  533,  534,  535,  536,\n",
      "        537,  538,  539,  540,  541,  542,  544,  545,  547,  548,  549,\n",
      "        550,  551,  553,  555,  558,  560,  561,  562,  563,  564,  565,\n",
      "        566,  567,  569,  570,  573,  574,  575,  576,  577,  579,  580,\n",
      "        581,  582,  584,  585,  587,  588,  589,  590,  591,  592,  593,\n",
      "        595,  596,  597,  598,  599,  601,  602,  603,  604,  605,  606,\n",
      "        607,  608,  609,  611,  612,  613,  614,  615,  616,  617,  618,\n",
      "        619,  620,  621,  622,  623,  624,  625,  626,  627,  628,  629,\n",
      "        630,  631,  635,  636,  637,  639,  640,  641,  642,  643,  644,\n",
      "        645,  646,  648,  649,  650,  651,  653,  654,  656,  657,  659,\n",
      "        660,  661,  662,  663,  665,  666,  667,  668,  670,  671,  672,\n",
      "        673,  675,  676,  677,  678,  679,  680,  681,  682,  683,  684,\n",
      "        686,  687,  688,  690,  691,  692,  693,  695,  696,  697,  698,\n",
      "        701,  703,  704,  705,  706,  707,  708,  709,  710,  711,  712,\n",
      "        713,  714,  715,  716,  717,  718,  720,  721,  722,  723,  724,\n",
      "        725,  726,  727,  728,  729,  730,  732,  733,  734,  736,  737,\n",
      "        738,  739,  740,  741,  743,  745,  747,  749,  750,  751,  753,\n",
      "        755,  756,  757,  758,  759,  760,  761,  762,  763,  764,  765,\n",
      "        766,  768,  769,  770,  771,  772,  773,  774,  775,  776,  777,\n",
      "        778,  779,  782,  784,  785,  786,  787,  788,  789,  790,  791,\n",
      "        792,  793,  795,  796,  797,  798,  799,  800,  801,  804,  806,\n",
      "        807,  808,  809,  810,  811,  812,  813,  814,  815,  816,  818,\n",
      "        820,  821,  822,  823,  824,  825,  826,  828,  829,  830,  831,\n",
      "        832,  833,  834,  835,  836,  837,  838,  839,  840,  841,  842,\n",
      "        843,  845,  846,  848,  849,  850,  851,  852,  853,  855,  856,\n",
      "        858,  860,  861,  862,  864,  865,  866,  867,  868,  869,  873,\n",
      "        874,  875,  876,  877,  878,  879,  880,  881,  883,  884,  887,\n",
      "        888,  890,  891,  892,  893,  894,  895,  896,  897,  898,  899,\n",
      "        900,  901,  902,  903,  904,  905,  907,  908,  909,  910,  911,\n",
      "        913,  915,  916,  917,  918,  919,  920,  922,  923,  924,  925,\n",
      "        926,  929,  932,  934,  936,  937,  938,  939,  941,  943,  944,\n",
      "        945,  946,  948,  949,  951,  952,  953,  954,  955,  956,  957,\n",
      "        958,  959,  960,  961,  963,  964,  965,  966,  968,  970,  971,\n",
      "        972,  973,  975,  976,  977,  979,  980,  981,  982,  983,  984,\n",
      "        986,  987,  988,  992,  993,  995,  996,  997,  998,  999, 1000,\n",
      "       1001, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1012, 1013,\n",
      "       1014, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1027,\n",
      "       1029, 1030, 1031, 1032, 1033, 1034, 1036, 1037, 1038, 1039, 1041,\n",
      "       1042, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1054, 1057,\n",
      "       1058, 1059, 1060, 1061, 1063, 1064, 1065, 1067, 1068, 1069, 1070,\n",
      "       1071, 1072, 1073, 1075, 1076, 1077, 1079, 1081, 1083, 1084, 1085,\n",
      "       1086, 1088, 1089, 1090, 1091]), array([   1,    4,   10,   20,   39,   42,   43,   45,   46,   50,   54,\n",
      "         59,   62,   72,   75,   78,   81,   85,   94,  100,  107,  116,\n",
      "        132,  138,  139,  140,  142,  164,  167,  170,  188,  192,  197,\n",
      "        199,  210,  214,  215,  216,  225,  229,  230,  234,  236,  237,\n",
      "        249,  252,  254,  258,  266,  276,  279,  283,  285,  287,  291,\n",
      "        302,  305,  315,  340,  342,  346,  349,  351,  354,  355,  357,\n",
      "        362,  367,  372,  377,  380,  382,  384,  385,  390,  398,  399,\n",
      "        404,  408,  409,  416,  422,  423,  430,  431,  432,  433,  454,\n",
      "        455,  457,  458,  460,  461,  463,  467,  474,  475,  478,  484,\n",
      "        496,  499,  500,  509,  510,  512,  519,  524,  525,  543,  546,\n",
      "        552,  554,  556,  557,  559,  568,  571,  572,  578,  583,  586,\n",
      "        594,  600,  610,  632,  633,  634,  638,  647,  652,  655,  658,\n",
      "        664,  669,  674,  685,  689,  694,  699,  700,  702,  719,  731,\n",
      "        735,  742,  744,  746,  748,  752,  754,  767,  780,  781,  783,\n",
      "        794,  802,  803,  805,  817,  819,  827,  844,  847,  854,  857,\n",
      "        859,  863,  870,  871,  872,  882,  885,  886,  889,  906,  912,\n",
      "        914,  921,  927,  928,  930,  931,  933,  935,  940,  942,  947,\n",
      "        950,  962,  967,  969,  974,  978,  985,  989,  990,  991,  994,\n",
      "       1002, 1011, 1015, 1025, 1026, 1028, 1035, 1040, 1043, 1045, 1053,\n",
      "       1055, 1056, 1062, 1066, 1074, 1078, 1080, 1082, 1087])), (array([   0,    1,    2,    4,    5,    6,    8,   10,   11,   12,   13,\n",
      "         14,   16,   17,   18,   19,   20,   22,   23,   24,   25,   26,\n",
      "         27,   28,   30,   32,   33,   34,   35,   36,   37,   39,   40,\n",
      "         41,   42,   43,   45,   46,   47,   48,   50,   51,   52,   54,\n",
      "         55,   56,   57,   58,   59,   60,   61,   62,   63,   64,   65,\n",
      "         66,   67,   68,   69,   70,   71,   72,   74,   75,   77,   78,\n",
      "         80,   81,   82,   85,   86,   87,   88,   89,   90,   93,   94,\n",
      "         96,   97,   98,   99,  100,  103,  104,  105,  106,  107,  108,\n",
      "        109,  111,  112,  113,  115,  116,  118,  119,  120,  121,  122,\n",
      "        124,  125,  126,  127,  128,  129,  130,  131,  132,  133,  137,\n",
      "        138,  139,  140,  141,  142,  143,  144,  145,  146,  147,  150,\n",
      "        151,  152,  153,  154,  157,  160,  161,  162,  163,  164,  165,\n",
      "        167,  168,  169,  170,  172,  173,  174,  175,  176,  177,  178,\n",
      "        180,  181,  182,  183,  184,  187,  188,  190,  191,  192,  193,\n",
      "        195,  196,  197,  199,  201,  202,  206,  207,  209,  210,  212,\n",
      "        213,  214,  215,  216,  217,  218,  219,  220,  221,  222,  223,\n",
      "        225,  227,  229,  230,  231,  232,  234,  235,  236,  237,  238,\n",
      "        239,  240,  241,  242,  245,  248,  249,  250,  251,  252,  253,\n",
      "        254,  256,  257,  258,  260,  262,  263,  264,  266,  267,  268,\n",
      "        269,  270,  271,  272,  273,  274,  275,  276,  277,  278,  279,\n",
      "        280,  281,  283,  284,  285,  286,  287,  288,  289,  290,  291,\n",
      "        293,  294,  295,  296,  297,  298,  302,  303,  304,  305,  306,\n",
      "        308,  310,  311,  312,  313,  314,  315,  316,  317,  319,  320,\n",
      "        321,  322,  323,  324,  325,  326,  327,  328,  330,  331,  332,\n",
      "        333,  335,  336,  338,  339,  340,  341,  342,  343,  345,  346,\n",
      "        347,  349,  350,  351,  352,  353,  354,  355,  356,  357,  359,\n",
      "        360,  362,  363,  365,  366,  367,  368,  369,  370,  371,  372,\n",
      "        373,  374,  375,  377,  379,  380,  381,  382,  383,  384,  385,\n",
      "        387,  388,  389,  390,  391,  392,  396,  398,  399,  401,  402,\n",
      "        403,  404,  405,  406,  408,  409,  410,  412,  413,  414,  415,\n",
      "        416,  417,  419,  420,  421,  422,  423,  424,  426,  427,  428,\n",
      "        429,  430,  431,  432,  433,  434,  435,  436,  437,  438,  440,\n",
      "        441,  442,  443,  444,  446,  447,  448,  449,  450,  451,  453,\n",
      "        454,  455,  456,  457,  458,  459,  460,  461,  462,  463,  464,\n",
      "        465,  466,  467,  468,  469,  471,  474,  475,  477,  478,  479,\n",
      "        482,  483,  484,  485,  486,  488,  489,  492,  495,  496,  498,\n",
      "        499,  500,  502,  503,  504,  505,  506,  507,  508,  509,  510,\n",
      "        511,  512,  513,  515,  516,  517,  519,  521,  522,  523,  524,\n",
      "        525,  526,  527,  528,  530,  531,  532,  533,  534,  535,  536,\n",
      "        537,  538,  540,  541,  542,  543,  544,  545,  546,  547,  548,\n",
      "        550,  551,  552,  554,  555,  556,  557,  558,  559,  560,  561,\n",
      "        563,  565,  566,  567,  568,  569,  570,  571,  572,  575,  576,\n",
      "        577,  578,  579,  580,  581,  582,  583,  584,  586,  587,  588,\n",
      "        589,  591,  592,  594,  596,  597,  598,  599,  600,  601,  603,\n",
      "        604,  605,  606,  607,  610,  611,  614,  615,  616,  617,  620,\n",
      "        621,  622,  623,  624,  627,  628,  630,  631,  632,  633,  634,\n",
      "        636,  638,  639,  645,  646,  647,  650,  651,  652,  653,  654,\n",
      "        655,  656,  658,  659,  661,  662,  663,  664,  665,  667,  668,\n",
      "        669,  672,  673,  674,  675,  676,  677,  678,  679,  680,  682,\n",
      "        683,  684,  685,  686,  687,  688,  689,  690,  693,  694,  696,\n",
      "        697,  699,  700,  701,  702,  703,  704,  705,  706,  707,  708,\n",
      "        709,  710,  711,  712,  713,  714,  715,  716,  718,  719,  725,\n",
      "        726,  727,  729,  730,  731,  732,  733,  734,  735,  736,  737,\n",
      "        738,  739,  741,  742,  743,  744,  745,  746,  747,  748,  749,\n",
      "        750,  751,  752,  753,  754,  755,  757,  759,  760,  761,  762,\n",
      "        763,  764,  765,  767,  768,  769,  770,  771,  772,  774,  775,\n",
      "        776,  777,  778,  780,  781,  782,  783,  785,  786,  787,  788,\n",
      "        792,  794,  795,  796,  797,  798,  799,  800,  801,  802,  803,\n",
      "        804,  805,  806,  808,  809,  810,  813,  814,  815,  816,  817,\n",
      "        818,  819,  820,  821,  823,  824,  825,  826,  827,  828,  829,\n",
      "        830,  832,  833,  834,  836,  837,  839,  841,  843,  844,  845,\n",
      "        847,  848,  850,  851,  852,  853,  854,  855,  856,  857,  859,\n",
      "        860,  862,  863,  864,  865,  866,  867,  868,  870,  871,  872,\n",
      "        873,  875,  876,  877,  878,  880,  881,  882,  883,  884,  885,\n",
      "        886,  887,  888,  889,  890,  891,  892,  893,  894,  896,  897,\n",
      "        898,  899,  900,  902,  903,  906,  908,  909,  910,  912,  913,\n",
      "        914,  915,  916,  917,  920,  921,  922,  924,  925,  926,  927,\n",
      "        928,  930,  931,  932,  933,  934,  935,  936,  937,  938,  939,\n",
      "        940,  941,  942,  943,  944,  945,  946,  947,  948,  949,  950,\n",
      "        952,  953,  954,  955,  956,  957,  959,  961,  962,  963,  964,\n",
      "        965,  966,  967,  968,  969,  970,  972,  973,  974,  975,  976,\n",
      "        977,  978,  979,  980,  981,  982,  983,  984,  985,  986,  987,\n",
      "        989,  990,  991,  993,  994,  995,  996,  997,  998,  999, 1000,\n",
      "       1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011,\n",
      "       1012, 1013, 1015, 1017, 1018, 1019, 1020, 1021, 1023, 1024, 1025,\n",
      "       1026, 1027, 1028, 1029, 1032, 1034, 1035, 1036, 1037, 1038, 1039,\n",
      "       1040, 1041, 1042, 1043, 1044, 1045, 1046, 1051, 1053, 1054, 1055,\n",
      "       1056, 1057, 1059, 1060, 1061, 1062, 1064, 1065, 1066, 1067, 1068,\n",
      "       1069, 1070, 1073, 1074, 1075, 1076, 1078, 1079, 1080, 1081, 1082,\n",
      "       1084, 1085, 1087, 1089, 1090]), array([   3,    7,    9,   15,   21,   29,   31,   38,   44,   49,   53,\n",
      "         73,   76,   79,   83,   84,   91,   92,   95,  101,  102,  110,\n",
      "        114,  117,  123,  134,  135,  136,  148,  149,  155,  156,  158,\n",
      "        159,  166,  171,  179,  185,  186,  189,  194,  198,  200,  203,\n",
      "        204,  205,  208,  211,  224,  226,  228,  233,  243,  244,  246,\n",
      "        247,  255,  259,  261,  265,  282,  292,  299,  300,  301,  307,\n",
      "        309,  318,  329,  334,  337,  344,  348,  358,  361,  364,  376,\n",
      "        378,  386,  393,  394,  395,  397,  400,  407,  411,  418,  425,\n",
      "        439,  445,  452,  470,  472,  473,  476,  480,  481,  487,  490,\n",
      "        491,  493,  494,  497,  501,  514,  518,  520,  529,  539,  549,\n",
      "        553,  562,  564,  573,  574,  585,  590,  593,  595,  602,  608,\n",
      "        609,  612,  613,  618,  619,  625,  626,  629,  635,  637,  640,\n",
      "        641,  642,  643,  644,  648,  649,  657,  660,  666,  670,  671,\n",
      "        681,  691,  692,  695,  698,  717,  720,  721,  722,  723,  724,\n",
      "        728,  740,  756,  758,  766,  773,  779,  784,  789,  790,  791,\n",
      "        793,  807,  811,  812,  822,  831,  835,  838,  840,  842,  846,\n",
      "        849,  858,  861,  869,  874,  879,  895,  901,  904,  905,  907,\n",
      "        911,  918,  919,  923,  929,  951,  958,  960,  971,  988,  992,\n",
      "       1014, 1016, 1022, 1030, 1031, 1033, 1047, 1048, 1049, 1050, 1052,\n",
      "       1058, 1063, 1071, 1072, 1077, 1083, 1086, 1088, 1091])), (array([   1,    3,    4,    5,    7,    8,    9,   10,   12,   13,   14,\n",
      "         15,   16,   17,   18,   19,   20,   21,   23,   24,   25,   29,\n",
      "         30,   31,   32,   33,   34,   35,   36,   38,   39,   41,   42,\n",
      "         43,   44,   45,   46,   47,   49,   50,   51,   52,   53,   54,\n",
      "         55,   56,   57,   59,   60,   61,   62,   63,   64,   69,   70,\n",
      "         71,   72,   73,   75,   76,   77,   78,   79,   81,   82,   83,\n",
      "         84,   85,   88,   91,   92,   93,   94,   95,   96,   97,   98,\n",
      "         99,  100,  101,  102,  103,  106,  107,  108,  109,  110,  111,\n",
      "        112,  113,  114,  116,  117,  118,  119,  120,  123,  127,  129,\n",
      "        130,  131,  132,  133,  134,  135,  136,  138,  139,  140,  141,\n",
      "        142,  143,  144,  145,  146,  147,  148,  149,  152,  153,  154,\n",
      "        155,  156,  158,  159,  160,  163,  164,  166,  167,  168,  169,\n",
      "        170,  171,  173,  175,  176,  177,  178,  179,  180,  182,  183,\n",
      "        184,  185,  186,  187,  188,  189,  190,  191,  192,  194,  195,\n",
      "        197,  198,  199,  200,  201,  202,  203,  204,  205,  207,  208,\n",
      "        209,  210,  211,  212,  213,  214,  215,  216,  217,  218,  219,\n",
      "        221,  222,  224,  225,  226,  228,  229,  230,  231,  233,  234,\n",
      "        235,  236,  237,  239,  240,  242,  243,  244,  246,  247,  248,\n",
      "        249,  252,  254,  255,  256,  257,  258,  259,  260,  261,  263,\n",
      "        264,  265,  266,  270,  272,  273,  274,  276,  277,  279,  280,\n",
      "        281,  282,  283,  284,  285,  286,  287,  289,  290,  291,  292,\n",
      "        293,  294,  296,  297,  298,  299,  300,  301,  302,  303,  304,\n",
      "        305,  307,  308,  309,  310,  311,  312,  313,  314,  315,  316,\n",
      "        317,  318,  319,  322,  323,  324,  325,  329,  330,  332,  334,\n",
      "        335,  336,  337,  338,  339,  340,  342,  343,  344,  346,  347,\n",
      "        348,  349,  350,  351,  352,  353,  354,  355,  356,  357,  358,\n",
      "        359,  360,  361,  362,  363,  364,  365,  366,  367,  368,  369,\n",
      "        370,  371,  372,  375,  376,  377,  378,  380,  381,  382,  383,\n",
      "        384,  385,  386,  390,  393,  394,  395,  396,  397,  398,  399,\n",
      "        400,  401,  402,  403,  404,  405,  406,  407,  408,  409,  411,\n",
      "        412,  414,  415,  416,  417,  418,  421,  422,  423,  424,  425,\n",
      "        427,  428,  429,  430,  431,  432,  433,  434,  435,  436,  438,\n",
      "        439,  440,  442,  444,  445,  446,  448,  451,  452,  453,  454,\n",
      "        455,  456,  457,  458,  460,  461,  462,  463,  464,  466,  467,\n",
      "        468,  469,  470,  472,  473,  474,  475,  476,  478,  479,  480,\n",
      "        481,  482,  484,  485,  487,  488,  490,  491,  492,  493,  494,\n",
      "        495,  496,  497,  498,  499,  500,  501,  502,  504,  506,  507,\n",
      "        508,  509,  510,  511,  512,  514,  517,  518,  519,  520,  521,\n",
      "        522,  523,  524,  525,  526,  527,  528,  529,  531,  532,  534,\n",
      "        535,  536,  539,  541,  542,  543,  544,  545,  546,  547,  549,\n",
      "        550,  552,  553,  554,  555,  556,  557,  559,  560,  561,  562,\n",
      "        563,  564,  565,  567,  568,  569,  570,  571,  572,  573,  574,\n",
      "        576,  578,  581,  582,  583,  584,  585,  586,  587,  588,  589,\n",
      "        590,  591,  592,  593,  594,  595,  596,  597,  598,  599,  600,\n",
      "        601,  602,  605,  606,  607,  608,  609,  610,  612,  613,  614,\n",
      "        616,  618,  619,  621,  622,  623,  624,  625,  626,  627,  629,\n",
      "        630,  631,  632,  633,  634,  635,  636,  637,  638,  639,  640,\n",
      "        641,  642,  643,  644,  645,  646,  647,  648,  649,  651,  652,\n",
      "        655,  656,  657,  658,  659,  660,  661,  662,  664,  665,  666,\n",
      "        667,  669,  670,  671,  673,  674,  677,  678,  679,  680,  681,\n",
      "        682,  683,  685,  687,  688,  689,  690,  691,  692,  693,  694,\n",
      "        695,  696,  698,  699,  700,  701,  702,  706,  708,  709,  710,\n",
      "        711,  713,  714,  715,  716,  717,  719,  720,  721,  722,  723,\n",
      "        724,  725,  727,  728,  730,  731,  732,  733,  735,  736,  737,\n",
      "        739,  740,  741,  742,  744,  745,  746,  747,  748,  749,  751,\n",
      "        752,  753,  754,  755,  756,  758,  760,  761,  762,  763,  764,\n",
      "        765,  766,  767,  768,  769,  770,  771,  772,  773,  774,  775,\n",
      "        776,  777,  779,  780,  781,  782,  783,  784,  786,  787,  788,\n",
      "        789,  790,  791,  793,  794,  796,  797,  798,  799,  802,  803,\n",
      "        804,  805,  806,  807,  808,  809,  811,  812,  813,  814,  815,\n",
      "        816,  817,  818,  819,  821,  822,  824,  825,  826,  827,  829,\n",
      "        830,  831,  832,  835,  838,  839,  840,  842,  843,  844,  845,\n",
      "        846,  847,  848,  849,  850,  851,  853,  854,  857,  858,  859,\n",
      "        860,  861,  862,  863,  864,  865,  867,  869,  870,  871,  872,\n",
      "        873,  874,  875,  878,  879,  880,  881,  882,  884,  885,  886,\n",
      "        887,  889,  891,  892,  893,  895,  898,  899,  900,  901,  902,\n",
      "        903,  904,  905,  906,  907,  909,  910,  911,  912,  914,  915,\n",
      "        918,  919,  920,  921,  923,  926,  927,  928,  929,  930,  931,\n",
      "        932,  933,  934,  935,  936,  937,  938,  940,  942,  944,  945,\n",
      "        947,  950,  951,  952,  954,  955,  957,  958,  960,  961,  962,\n",
      "        964,  966,  967,  969,  970,  971,  973,  974,  976,  977,  978,\n",
      "        980,  981,  982,  983,  985,  986,  987,  988,  989,  990,  991,\n",
      "        992,  993,  994,  995,  999, 1000, 1001, 1002, 1003, 1006, 1007,\n",
      "       1008, 1010, 1011, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021,\n",
      "       1022, 1023, 1025, 1026, 1028, 1029, 1030, 1031, 1032, 1033, 1035,\n",
      "       1036, 1037, 1039, 1040, 1041, 1042, 1043, 1045, 1046, 1047, 1048,\n",
      "       1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1058, 1060, 1061,\n",
      "       1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073,\n",
      "       1074, 1075, 1076, 1077, 1078, 1080, 1082, 1083, 1084, 1085, 1086,\n",
      "       1087, 1088, 1089, 1090, 1091]), array([   0,    2,    6,   11,   22,   26,   27,   28,   37,   40,   48,\n",
      "         58,   65,   66,   67,   68,   74,   80,   86,   87,   89,   90,\n",
      "        104,  105,  115,  121,  122,  124,  125,  126,  128,  137,  150,\n",
      "        151,  157,  161,  162,  165,  172,  174,  181,  193,  196,  206,\n",
      "        220,  223,  227,  232,  238,  241,  245,  250,  251,  253,  262,\n",
      "        267,  268,  269,  271,  275,  278,  288,  295,  306,  320,  321,\n",
      "        326,  327,  328,  331,  333,  341,  345,  373,  374,  379,  387,\n",
      "        388,  389,  391,  392,  410,  413,  419,  420,  426,  437,  441,\n",
      "        443,  447,  449,  450,  459,  465,  471,  477,  483,  486,  489,\n",
      "        503,  505,  513,  515,  516,  530,  533,  537,  538,  540,  548,\n",
      "        551,  558,  566,  575,  577,  579,  580,  603,  604,  611,  615,\n",
      "        617,  620,  628,  650,  653,  654,  663,  668,  672,  675,  676,\n",
      "        684,  686,  697,  703,  704,  705,  707,  712,  718,  726,  729,\n",
      "        734,  738,  743,  750,  757,  759,  778,  785,  792,  795,  800,\n",
      "        801,  810,  820,  823,  828,  833,  834,  836,  837,  841,  852,\n",
      "        855,  856,  866,  868,  876,  877,  883,  888,  890,  894,  896,\n",
      "        897,  908,  913,  916,  917,  922,  924,  925,  939,  941,  943,\n",
      "        946,  948,  949,  953,  956,  959,  963,  965,  968,  972,  975,\n",
      "        979,  984,  996,  997,  998, 1004, 1005, 1009, 1012, 1013, 1024,\n",
      "       1027, 1034, 1038, 1044, 1057, 1059, 1064, 1079, 1081]))]\n",
      "SPLITS:\n",
      "- folds:\n",
      "5\n",
      "- splits per fold:\n",
      "2\n",
      "Fold n.0 started\n",
      "(FN) Train validation splitted: 873 219\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 873/873 [03:19<00:00,  4.38it/s, batch_loss=0.67, loss=0.714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.49it/s, batch_loss=0.694, loss=0.706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0/15: Validation average loss: 0.706308607369253 + AUC SCORE = 0.5136780650542119 + AUC SCORE THRESH 0.0 = 0.5\n",
      "Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 873/873 [03:22<00:00,  4.32it/s, batch_loss=1.07, loss=0.702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.47it/s, batch_loss=0.839, loss=0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/15: Validation average loss: 0.701097651703717 + AUC SCORE = 0.5497080900750626 + AUC SCORE THRESH 0.42857142857142855 = 0.5434528773978315\n",
      "Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:22<00:00,  4.30it/s, batch_loss=0.489, loss=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.41it/s, batch_loss=0.576, loss=0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2/15: Validation average loss: 0.701483603754 + AUC SCORE = 0.4929941618015013 + AUC SCORE THRESH 0.44897959183673464 = 0.5000417014178482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:23<00:00,  4.30it/s, batch_loss=0.813, loss=0.706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 219/219 [00:17<00:00, 12.38it/s, batch_loss=0.69, loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3/15: Validation average loss: 0.6950331670508537 + AUC SCORE = 0.5055879899916598 + AUC SCORE THRESH 0.0 = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 873/873 [03:23<00:00,  4.29it/s, batch_loss=0.697, loss=0.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.37it/s, batch_loss=0.727, loss=0.706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4/15: Validation average loss: 0.7055670775507139 + AUC SCORE = 0.5195996663886572 + AUC SCORE THRESH 0.5102040816326531 = 0.5074228523769808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 873/873 [03:23<00:00,  4.29it/s, batch_loss=0.767, loss=0.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.38it/s, batch_loss=0.833, loss=0.702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5/15: Validation average loss: 0.7017849550399606 + AUC SCORE = 0.503419516263553 + AUC SCORE THRESH 0.0 = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:23<00:00,  4.29it/s, batch_loss=0.886, loss=0.697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.41it/s, batch_loss=0.871, loss=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6/15: Validation average loss: 0.7042858361109207 + AUC SCORE = 0.5155129274395329 + AUC SCORE THRESH 0.5918367346938775 = 0.5092994161801501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:23<00:00,  4.29it/s, batch_loss=0.715, loss=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.29it/s, batch_loss=0.714, loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 7/15: Validation average loss: 0.6950553993111876 + AUC SCORE = 0.4738115095913261 + AUC SCORE THRESH 0.5102040816326531 = 0.5039199332777314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.76, loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.31it/s, batch_loss=0.637, loss=0.697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 8/15: Validation average loss: 0.6970692002065649 + AUC SCORE = 0.4974145120934112 + AUC SCORE THRESH 0.0 = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.28it/s, batch_loss=0.588, loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.31it/s, batch_loss=0.806, loss=0.707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 9/15: Validation average loss: 0.7069300198119525 + AUC SCORE = 0.4884070058381985 + AUC SCORE THRESH 0.44897959183673464 = 0.5138031693077565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.726, loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 219/219 [00:17<00:00, 12.34it/s, batch_loss=0.67, loss=0.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 10/15: Validation average loss: 0.7096972611124657 + AUC SCORE = 0.4965804837364471 + AUC SCORE THRESH 0.0 = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.655, loss=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.34it/s, batch_loss=0.697, loss=0.788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 11/15: Validation average loss: 0.7883271382755885 + AUC SCORE = 0.5121768140116765 + AUC SCORE THRESH 0.4897959183673469 = 0.5245204336947457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.71, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 219/219 [00:17<00:00, 12.29it/s, batch_loss=0.268, loss=0.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 12/15: Validation average loss: 0.7196198754250731 + AUC SCORE = 0.5094245204336948 + AUC SCORE THRESH 0.5306122448979591 = 0.5095496246872394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.523, loss=0.689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.29it/s, batch_loss=0.776, loss=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 13/15: Validation average loss: 0.7040140551247008 + AUC SCORE = 0.49374478732276894 + AUC SCORE THRESH 0.5714285714285714 = 0.5150125104253545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.555, loss=0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.30it/s, batch_loss=0.634, loss=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 14/15: Validation average loss: 0.7036336563085313 + AUC SCORE = 0.5372810675562969 + AUC SCORE THRESH 0.4693877551020408 = 0.5256880733944954\n",
      "0.5497080900750626\n",
      "Fold n.1 started\n",
      "(FN) Train validation splitted: 873 219\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.67, loss=0.719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.30it/s, batch_loss=0.672, loss=0.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0/15: Validation average loss: 0.6907385307359913 + AUC SCORE = 0.5718098415346122 + AUC SCORE THRESH 0.4897959183673469 = 0.5655546288573812\n",
      "Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=1.06, loss=0.703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 219/219 [00:17<00:00, 12.28it/s, batch_loss=1.33, loss=0.812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/15: Validation average loss: 0.8118016210865212 + AUC SCORE = 0.45095913261050874 + AUC SCORE THRESH 0.3061224489795918 = 0.5180150125104254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.502, loss=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 219/219 [00:17<00:00, 12.31it/s, batch_loss=0.514, loss=0.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2/15: Validation average loss: 0.7201969095561058 + AUC SCORE = 0.5227689741451209 + AUC SCORE THRESH 0.3877551020408163 = 0.5055045871559632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 873/873 [03:24<00:00,  4.28it/s, batch_loss=0.763, loss=0.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.29it/s, batch_loss=0.728, loss=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3/15: Validation average loss: 0.6958681919939442 + AUC SCORE = 0.5041701417848207 + AUC SCORE THRESH 0.6326530612244897 = 0.5271476230191826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.65, loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.33it/s, batch_loss=0.619, loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4/15: Validation average loss: 0.6985484896457359 + AUC SCORE = 0.4822351959966638 + AUC SCORE THRESH 0.6122448979591836 = 0.5225187656380317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.806, loss=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 219/219 [00:17<00:00, 12.26it/s, batch_loss=0.698, loss=0.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5/15: Validation average loss: 0.7696704745981587 + AUC SCORE = 0.5128440366972477 + AUC SCORE THRESH 0.7551020408163265 = 0.5403669724770642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 873/873 [03:23<00:00,  4.28it/s, batch_loss=0.904, loss=0.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 219/219 [00:17<00:00, 12.30it/s, batch_loss=1.25, loss=0.739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6/15: Validation average loss: 0.7386410950797878 + AUC SCORE = 0.5252710592160134 + AUC SCORE THRESH 0.5918367346938775 = 0.539324437030859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.632, loss=0.687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.31it/s, batch_loss=0.417, loss=0.709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 7/15: Validation average loss: 0.7091856332130084 + AUC SCORE = 0.5266889074228523 + AUC SCORE THRESH 0.44897959183673464 = 0.5483736447039199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.28it/s, batch_loss=0.705, loss=0.686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.30it/s, batch_loss=0.625, loss=0.697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 8/15: Validation average loss: 0.6971697837250418 + AUC SCORE = 0.5359466221851543 + AUC SCORE THRESH 0.4081632653061224 = 0.5469557964970809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.607, loss=0.684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 219/219 [00:17<00:00, 12.30it/s, batch_loss=1, loss=0.754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 9/15: Validation average loss: 0.7539645918564165 + AUC SCORE = 0.523603002502085 + AUC SCORE THRESH 0.44897959183673464 = 0.5725604670558799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.741, loss=0.677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 219/219 [00:17<00:00, 12.30it/s, batch_loss=1.06, loss=0.705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 10/15: Validation average loss: 0.7049663613920343 + AUC SCORE = 0.5229357798165137 + AUC SCORE THRESH 0.5510204081632653 = 0.5406171809841535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.537, loss=0.672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.31it/s, batch_loss=0.298, loss=0.761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 11/15: Validation average loss: 0.7605277024311562 + AUC SCORE = 0.4975813177648039 + AUC SCORE THRESH 0.3469387755102041 = 0.5300667222685571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.671, loss=0.666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 219/219 [00:17<00:00, 12.33it/s, batch_loss=1.22, loss=0.716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 12/15: Validation average loss: 0.7161623868223739 + AUC SCORE = 0.5360300250208507 + AUC SCORE THRESH 0.5510204081632653 = 0.5439115929941618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.519, loss=0.662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.29it/s, batch_loss=0.535, loss=0.776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 13/15: Validation average loss: 0.7764871310119488 + AUC SCORE = 0.5433694745621351 + AUC SCORE THRESH 0.4897959183673469 = 0.5559633027522937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 873/873 [03:24<00:00,  4.27it/s, batch_loss=0.517, loss=0.656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 219/219 [00:17<00:00, 12.29it/s, batch_loss=0.226, loss=0.796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 14/15: Validation average loss: 0.7957978496948878 + AUC SCORE = 0.5190158465387823 + AUC SCORE THRESH 0.4693877551020408 = 0.5438281901584653\n",
      "0.5718098415346122\n",
      "Fold n.2 started\n",
      "(FN) Train validation splitted: 874 218\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.764, loss=0.715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.27it/s, batch_loss=0.679, loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0/15: Validation average loss: 0.6940559906150223 + AUC SCORE = 0.5129197878966416 + AUC SCORE THRESH 0.5102040816326531 = 0.5321100917431193\n",
      "Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.716, loss=0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.27it/s, batch_loss=0.659, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/15: Validation average loss: 0.6922547582092635 + AUC SCORE = 0.4899419240804646 + AUC SCORE THRESH 0.5714285714285714 = 0.5229357798165137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.701, loss=0.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.28it/s, batch_loss=0.693, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2/15: Validation average loss: 0.6934296800455916 + AUC SCORE = 0.5012204359902366 + AUC SCORE THRESH 0.5306122448979591 = 0.5137614678899083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.497, loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.30it/s, batch_loss=0.954, loss=0.723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3/15: Validation average loss: 0.7232399494002718 + AUC SCORE = 0.49322447605420416 + AUC SCORE THRESH 0.36734693877551017 = 0.536697247706422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.634, loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 218/218 [00:17<00:00, 12.30it/s, batch_loss=0.74, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4/15: Validation average loss: 0.6919765371248263 + AUC SCORE = 0.5371601717027186 + AUC SCORE THRESH 0.5102040816326531 = 0.5321100917431193\n",
      "Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.69, loss=0.703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.33it/s, batch_loss=0.739, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5/15: Validation average loss: 0.6919154997812499 + AUC SCORE = 0.45964144432286846 + AUC SCORE THRESH 0.5918367346938775 = 0.5275229357798166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.705, loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.32it/s, batch_loss=0.791, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6/15: Validation average loss: 0.6915668601836633 + AUC SCORE = 0.4954128440366973 + AUC SCORE THRESH 0.5306122448979591 = 0.5412844036697249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.659, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.29it/s, batch_loss=0.754, loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 7/15: Validation average loss: 0.6953568213849987 + AUC SCORE = 0.45711640434306877 + AUC SCORE THRESH 0.5714285714285714 = 0.5275229357798166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.822, loss=0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.27it/s, batch_loss=0.877, loss=0.776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 8/15: Validation average loss: 0.7756920006775528 + AUC SCORE = 0.4505513003955896 + AUC SCORE THRESH 0.8775510204081632 = 0.5321100917431193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.796, loss=0.687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.30it/s, batch_loss=0.666, loss=0.712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 9/15: Validation average loss: 0.7123996879256099 + AUC SCORE = 0.39365373285077015 + AUC SCORE THRESH 0.5102040816326531 = 0.518348623853211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.622, loss=0.663]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.27it/s, batch_loss=0.589, loss=0.835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 10/15: Validation average loss: 0.8349658678239852 + AUC SCORE = 0.4129282046965744 + AUC SCORE THRESH 0.9591836734693877 = 0.5275229357798165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.607, loss=0.651]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.27it/s, batch_loss=0.667, loss=0.899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 11/15: Validation average loss: 0.8991062978919117 + AUC SCORE = 0.4162107566703139 + AUC SCORE THRESH 0.9591836734693877 = 0.5321100917431192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.554, loss=0.633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 218/218 [00:17<00:00, 12.25it/s, batch_loss=1.63, loss=0.744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 12/15: Validation average loss: 0.7436096470700492 + AUC SCORE = 0.3905395168756839 + AUC SCORE THRESH 0.7142857142857142 = 0.5229357798165137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.26it/s, batch_loss=0.405, loss=0.614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 218/218 [00:17<00:00, 12.28it/s, batch_loss=3.38, loss=0.936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 13/15: Validation average loss: 0.9363349661991479 + AUC SCORE = 0.40552142075582864 + AUC SCORE THRESH 0.9591836734693877 = 0.5229357798165137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.28it/s, batch_loss=0.313, loss=0.592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 218/218 [00:17<00:00, 12.25it/s, batch_loss=1.33, loss=0.778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 14/15: Validation average loss: 0.7782238380163224 + AUC SCORE = 0.42134500462924 + AUC SCORE THRESH 0.7755102040816326 = 0.5229357798165137\n",
      "0.5371601717027186\n",
      "Fold n.3 started\n",
      "(FN) Train validation splitted: 874 218\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.722, loss=0.716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.27it/s, batch_loss=0.674, loss=0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0/15: Validation average loss: 0.7006377339226391 + AUC SCORE = 0.5403585556771315 + AUC SCORE THRESH 0.5102040816326531 = 0.536697247706422\n",
      "Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.69, loss=0.706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 218/218 [00:17<00:00, 12.26it/s, batch_loss=0.7, loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/15: Validation average loss: 0.6937759209663497 + AUC SCORE = 0.46738490026092083 + AUC SCORE THRESH 0.5102040816326531 = 0.5045871559633027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.686, loss=0.705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.24it/s, batch_loss=0.674, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2/15: Validation average loss: 0.6932087163312719 + AUC SCORE = 0.5117414359060686 + AUC SCORE THRESH 0.0 = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.493, loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 218/218 [00:17<00:00, 12.26it/s, batch_loss=1.01, loss=0.748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3/15: Validation average loss: 0.7482215911833519 + AUC SCORE = 0.523735375810117 + AUC SCORE THRESH 0.2857142857142857 = 0.518348623853211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.638, loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 218/218 [00:17<00:00, 12.27it/s, batch_loss=0.63, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4/15: Validation average loss: 0.6934631660990759 + AUC SCORE = 0.48396599612827196 + AUC SCORE THRESH 0.4693877551020408 = 0.5275229357798166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.705, loss=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.25it/s, batch_loss=0.712, loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5/15: Validation average loss: 0.6936002704528493 + AUC SCORE = 0.4590522683275818 + AUC SCORE THRESH 0.4897959183673469 = 0.5321100917431192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.781, loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.28it/s, batch_loss=0.795, loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6/15: Validation average loss: 0.6982763610575178 + AUC SCORE = 0.46990994024072047 + AUC SCORE THRESH 0.5918367346938775 = 0.5091743119266054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.666, loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.26it/s, batch_loss=0.716, loss=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 7/15: Validation average loss: 0.6959325833878386 + AUC SCORE = 0.48472350812221193 + AUC SCORE THRESH 0.5714285714285714 = 0.5137614678899082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.26it/s, batch_loss=0.857, loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.28it/s, batch_loss=0.831, loss=0.703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 8/15: Validation average loss: 0.7030924452007363 + AUC SCORE = 0.4897735880818113 + AUC SCORE THRESH 0.5918367346938775 = 0.5321100917431193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.869, loss=0.697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.25it/s, batch_loss=0.816, loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 9/15: Validation average loss: 0.6986745215884043 + AUC SCORE = 0.4592206043262351 + AUC SCORE THRESH 0.4693877551020408 = 0.5045871559633028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.882, loss=0.689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 218/218 [00:17<00:00, 12.26it/s, batch_loss=0.74, loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 10/15: Validation average loss: 0.6943950571051432 + AUC SCORE = 0.4919619560643043 + AUC SCORE THRESH 0.4897959183673469 = 0.5137614678899083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.27it/s, batch_loss=0.738, loss=0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.26it/s, batch_loss=0.658, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 11/15: Validation average loss: 0.6926766226597882 + AUC SCORE = 0.5103105799175154 + AUC SCORE THRESH 0.4897959183673469 = 0.5321100917431192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:24<00:00,  4.26it/s, batch_loss=0.594, loss=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.25it/s, batch_loss=0.778, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 12/15: Validation average loss: 0.6930618802888677 + AUC SCORE = 0.5244508038043936 + AUC SCORE THRESH 0.5510204081632653 = 0.5229357798165137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:25<00:00,  4.26it/s, batch_loss=0.744, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.24it/s, batch_loss=0.714, loss=0.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 13/15: Validation average loss: 0.6911583164142906 + AUC SCORE = 0.541705243666358 + AUC SCORE THRESH 0.4897959183673469 = 0.5412844036697249\n",
      "Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 874/874 [03:25<00:00,  4.26it/s, batch_loss=0.754, loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 218/218 [00:17<00:00, 12.23it/s, batch_loss=0.713, loss=0.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 14/15: Validation average loss: 0.6900783405391449 + AUC SCORE = 0.5488595236091239 + AUC SCORE THRESH 0.5510204081632653 = 0.5321100917431193\n",
      "Saving the model...\n",
      "0.5488595236091239\n",
      "Fold n.4 started\n",
      "(FN) Train validation splitted: 874 218\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:25<00:00,  4.26it/s, batch_loss=0.739, loss=0.713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.22it/s, batch_loss=0.581, loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0/15: Validation average loss: 0.6982571304938116 + AUC SCORE = 0.48994192408046455 + AUC SCORE THRESH 0.5306122448979591 = 0.5045871559633027\n",
      "Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:25<00:00,  4.25it/s, batch_loss=0.671, loss=0.703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 218/218 [00:17<00:00, 12.22it/s, batch_loss=0.72, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/15: Validation average loss: 0.6929281794149941 + AUC SCORE = 0.5231882838144938 + AUC SCORE THRESH 0.4897959183673469 = 0.5275229357798165\n",
      "Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:25<00:00,  4.26it/s, batch_loss=0.641, loss=0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 218/218 [00:17<00:00, 12.24it/s, batch_loss=0.67, loss=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2/15: Validation average loss: 0.6957195070358592 + AUC SCORE = 0.48640686810874506 + AUC SCORE THRESH 0.0 = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:25<00:00,  4.25it/s, batch_loss=0.506, loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.24it/s, batch_loss=0.944, loss=0.715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3/15: Validation average loss: 0.7149819145235446 + AUC SCORE = 0.5205790758353674 + AUC SCORE THRESH 0.3877551020408163 = 0.5045871559633028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:25<00:00,  4.26it/s, batch_loss=0.706, loss=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.26it/s, batch_loss=0.625, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4/15: Validation average loss: 0.6934969829856803 + AUC SCORE = 0.49920040400639676 + AUC SCORE THRESH 0.4693877551020408 = 0.5275229357798165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:25<00:00,  4.26it/s, batch_loss=0.669, loss=0.697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.23it/s, batch_loss=0.723, loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5/15: Validation average loss: 0.694901048316868 + AUC SCORE = 0.47554919619560637 + AUC SCORE THRESH 0.5306122448979591 = 0.5045871559633027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:25<00:00,  4.26it/s, batch_loss=0.821, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.21it/s, batch_loss=0.725, loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6/15: Validation average loss: 0.6987704019480889 + AUC SCORE = 0.46780574025755406 + AUC SCORE THRESH 0.0 = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:25<00:00,  4.25it/s, batch_loss=0.734, loss=0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 218/218 [00:17<00:00, 12.23it/s, batch_loss=0.765, loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 7/15: Validation average loss: 0.6953195180367986 + AUC SCORE = 0.46107230031142166 + AUC SCORE THRESH 0.0 = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 874/874 [03:25<00:00,  4.25it/s, batch_loss=0.848, loss=0.687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▍         | 45/218 [00:03<00:13, 12.45it/s, batch_loss=0.571, loss=0.723]"
     ]
    }
   ],
   "source": [
    "fold = 5\n",
    "mri_type = \"T1wCE\"\n",
    "batch_size = 1\n",
    "epochs = 15\n",
    "train_origins = [\"fn\"]\n",
    "train_folded_models(fold, mri_type, \"resnet10\", batch_size, epochs, train_origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
