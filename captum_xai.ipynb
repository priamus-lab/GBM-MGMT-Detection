{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {}\n",
    "info[\"ext\"] = \"mat\"\n",
    "#info[\"ext\"] = \"nii\"\n",
    "dir_path = \"../RSNA-BTC-Datasets/train_\"+info[\"ext\"]\n",
    "test_dir_path = \"../RSNA-BTC-Datasets/test_\"+info[\"ext\"]\n",
    "tumor_only_dir_path = \"../RSNA-BTC-Datasets/ec_train_\"+info[\"ext\"]\n",
    "tumor_only_test_dir_path = \"../RSNA-BTC-Datasets/ec_test_\"+info[\"ext\"]\n",
    "no_tumor_dir_path = \"../RSNA-BTC-Datasets/no_tumor_train_\"+info[\"ext\"]\n",
    "ext_test_1_dir_path = \"../RSNA-BTC-Datasets/brats18_\"+info[\"ext\"]\n",
    "ext_test_0_dir_path = \"../RSNA-BTC-Datasets/OpenNeuroDS000221_ss_\"+info[\"ext\"]\n",
    "new_dir_path = \"../RSNA-BTC-Datasets/UPENN-GBM_\"+info[\"ext\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c77999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from utils import classifier_utils\n",
    "from utils import dataset_utils\n",
    "from utils.neural_networks import *\n",
    "importlib.reload(classifier_utils)\n",
    "importlib.reload(dataset_utils)\n",
    "\n",
    "def predict_with_case_and_size(case, input_size):\n",
    "    if case == \"A\":\n",
    "        to = \"m\"#info[\"train_origin\"]\n",
    "        data_idx = 1\n",
    "        if input_size == \"3D\":\n",
    "            folder = \"fold1_RSNAClassifierSingle3D-DW-SO-KLF-mn_Aug22_14-52-37\"\n",
    "        else:\n",
    "            folder = \"fold1_RSNAAlternativeClassifierSingle2D-DW-SO-KLF-mn_Aug22_14-59-16\"\n",
    "    elif case == \"A_B\":\n",
    "        to = \"n\"\n",
    "        data_idx = 2 #full\n",
    "        if input_size == \"3D\":\n",
    "            folder = \"fold1_RSNAClassifierSingle3D-DW-SO-KLF-mn_Aug22_14-52-37\"\n",
    "        else:\n",
    "            folder = \"fold1_RSNAAlternativeClassifierSingle2D-DW-SO-KLF-mn_Aug22_14-59-16\"\n",
    "    elif case == \"B\":\n",
    "        to = \"n\"\n",
    "        data_idx = 1\n",
    "        if input_size == \"3D\":\n",
    "            folder = \"fold1_RSNAClassifierSingle3D-DW-SO-KLF-n_Aug19_14-43-40\"\n",
    "        else:\n",
    "            folder = \"fold1_RSNAAlternativeClassifierSingle2D-DW-SO-KLF-n_Aug19_14-45-29\"\n",
    "    elif case == \"B_A\":\n",
    "        to = \"m\"\n",
    "        data_idx = 2 #full\n",
    "        if input_size == \"3D\":\n",
    "            folder = \"fold1_RSNAClassifierSingle3D-DW-SO-KLF-n_Aug19_14-43-40\"\n",
    "        else:\n",
    "            folder = \"fold1_RSNAAlternativeClassifierSingle2D-DW-SO-KLF-n_Aug19_14-45-29\"\n",
    "    elif case == \"AB\":\n",
    "        to = \"mn\"\n",
    "        data_idx = 1\n",
    "        if input_size == \"3D\":\n",
    "            folder = \"fold1_RSNAClassifierSingle3D-DW-SO-KLF-mn_Aug20_15-38-50\"\n",
    "        else:\n",
    "            folder = \"fold1_RSNAAlternativeClassifierSingle2D-DW-SO-KLF-mn_Aug20_16-20-40\"\n",
    "\n",
    "    #folder = \"fold1_RSNAClassifierSingle3D-DW-SO-KLF-mn_Aug22_14-52-37\"\n",
    "    model_common_path = \"../RSNA-BTC-Datasets/out_models/\"\n",
    "    model_folder = model_common_path + folder\n",
    "\n",
    "    model_basefile, info = get_best_model(model_folder)\n",
    "    m_modelfile = model_folder + \"/\" + model_basefile\n",
    "    transform = None\n",
    "    size = len(info[\"mri_types\"])\n",
    "    sel_slices = 1 if info[\"dims\"] == 2 else None\n",
    "    chosen_net = \"alt\" if info[\"dims\"] == 2 else \"sim\"\n",
    "\n",
    "    m_model = try_and_get_model(chosen_net, info[\"dims\"], size, info[\"is_depth_wise\"], info[\"output_size\"])\n",
    "\n",
    "    #m_modelfile = m_modelfile_3d\n",
    "    print(m_modelfile)\n",
    "    print(info)\n",
    "\n",
    "    print(f\"Train origin: {to}\")\n",
    "    if to == \"m\":\n",
    "        packs = dataset_utils.generate_datasets(['KLF'], info, transform, sel_slices, m_path=dir_path) #m_path=dir_path, n_path=new_dir_path\n",
    "    elif to == \"n\":\n",
    "        packs = dataset_utils.generate_datasets(['KLF'], info, transform, sel_slices, n_path=new_dir_path)\n",
    "    elif to == \"mn\":\n",
    "        packs = dataset_utils.generate_datasets(['KLF'], info, transform, sel_slices, m_path=dir_path, n_path=new_dir_path)\n",
    "    print(packs)\n",
    "    loader_packs = dataset_utils.get_loaders(packs, info, is_fold=True, fold_num=1)\n",
    "    print(loader_packs)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(\"Using CUDA...\")\n",
    "\n",
    "    pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "    #print(loader_packs['KLF']['m_dataloaders'])\n",
    "    selected_type = info[\"mri_types\"][0]\n",
    "    print(selected_type)\n",
    "    dataloader = loader_packs[selected_type][f\"{to}_dataloaders\"]#m_dataloaders[0]\n",
    "    val_loader = dataloader[data_idx]\n",
    "    #val_loader = dataloader[2] #full\n",
    "\n",
    "    print(\"\\nPREDICTIONS:\")\n",
    "    print(folder)\n",
    "    #print(f\"Test set: {to} (B)\")\n",
    "    test_loader = val_loader\n",
    "    m_test_pred, ids, X, y, y_pred, y_prob = classifier_utils.predict(m_model, device, m_modelfile, test_loader, size)\n",
    "    #X_first = X[0].cpu().detach().numpy()\n",
    "    #plt.imshow(X_first[0,96,:,:], cmap=cm.Greys_r)\n",
    "    #plt.show()\n",
    "    return m_test_pred, ids, X, y, y_pred, y_prob, m_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05fd27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from captum.attr import GuidedGradCam, LayerGradCam, LayerAttribution\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import Occlusion\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_xai(case, input_size, m_test_pred, ids, X, y, y_pred, y_prob, m_model):\n",
    "    default_cmap = LinearSegmentedColormap.from_list('custom blue',\n",
    "                                                       [(0, '#ffffff'),\n",
    "                                                        (0.25, '#000000'),\n",
    "                                                        (1, '#000000')], N=256)\n",
    "    integrated_gradients = IntegratedGradients(m_model)\n",
    "    occlusion = Occlusion(m_model)\n",
    "\n",
    "    if input_size == \"3D\":\n",
    "        if case == \"A\":\n",
    "            sel_idx = {\n",
    "                #\"00532\": 80,\n",
    "                #\"00206\": 83,\n",
    "                #\"00389\": 101\n",
    "                \"00491\": 82,\n",
    "                \"00469\": 124,\n",
    "                \"00764\": 147\n",
    "            }\n",
    "        elif case == \"A_B\":\n",
    "            sel_idx = {\n",
    "                \"UPENN-GBM-00302_11\": 134,\n",
    "                \"UPENN-GBM-00604_11\": 95,\n",
    "                \"UPENN-GBM-00149_11\": 94\n",
    "            }\n",
    "        elif case == \"B\":\n",
    "            sel_idx = {\n",
    "                \"UPENN-GBM-00128_11\": 74,\n",
    "                \"UPENN-GBM-00410_11\": 97,\n",
    "                \"UPENN-GBM-00381_11\": 93\n",
    "            }\n",
    "        elif case == \"B_A\":\n",
    "            sel_idx = {\n",
    "                \"00062\": 79,\n",
    "                \"00090\": 128,\n",
    "                \"00444\": 100\n",
    "            }\n",
    "        elif case == \"AB\":\n",
    "            sel_idx = {\n",
    "                \"00062\": 79,\n",
    "                \"00269\": 107,\n",
    "                \"00684\": 96\n",
    "            }\n",
    "    else:\n",
    "        if case == \"A\":\n",
    "            sel_idx = {\n",
    "                \"00604\": 0,\n",
    "                \"00684\": 0,\n",
    "                \"00601\": 0\n",
    "            }\n",
    "        elif case == \"A_B\":\n",
    "            sel_idx = {\n",
    "                \"UPENN-GBM-00474_11\": 0,\n",
    "                \"UPENN-GBM-00482_11\": 0,\n",
    "                \"UPENN-GBM-00454_11\": 0\n",
    "            }\n",
    "        elif case == \"B\":\n",
    "            sel_idx = {\n",
    "                \"UPENN-GBM-00128_11\": 0,\n",
    "                \"UPENN-GBM-00448_11\": 0,\n",
    "                \"UPENN-GBM-00617_11\": 0\n",
    "            }\n",
    "        elif case == \"B_A\":\n",
    "            sel_idx = {\n",
    "                \"00144\": 0,\n",
    "                \"00269\": 0,\n",
    "                \"00800\": 0\n",
    "            }\n",
    "        elif case == \"AB\":\n",
    "            sel_idx = {\n",
    "                \"00470\": 0,\n",
    "                \"00687\": 0,\n",
    "                \"00251\": 0\n",
    "            }\n",
    "\n",
    "    for i in range(len(ids)):\n",
    "        idx = list(ids)[i]\n",
    "        if idx in sel_idx.keys():\n",
    "            print(\"Idx: \"+idx)\n",
    "            pred = y_pred[i]\n",
    "            real = y[i]\n",
    "            prob = y_prob[i][0]\n",
    "            #tumor = tumor_y[i]\n",
    "\n",
    "            print(\"Methylation pred value: \"+str(pred))\n",
    "            print(\"Methylation real value: \"+str(real))\n",
    "            print(\"Methylation prob value: \"+str(prob))\n",
    "            #print(\"Tumor real value: \"+str(tumor))\n",
    "            if input_size == \"2D\":\n",
    "                img_test = X[i].unsqueeze(0)\n",
    "            else:\n",
    "                img_test = X[i].unsqueeze(0)#X[i][:,:,sel_idx[idx],:,:].unsqueeze(0)\n",
    "                \n",
    "            #print(np.shape(img_test.cpu().detach().numpy().transpose(2, 3, 4, 1, 0)))\n",
    "\n",
    "            attributions_ig = integrated_gradients.attribute(img_test, target=0, n_steps=10)\n",
    "            if input_size == \"3D\":\n",
    "                attributions_occ = occlusion.attribute(img_test,\n",
    "                                                     strides=(1, 8, 8, 8),\n",
    "                                                     target=0,\n",
    "                                                     sliding_window_shapes=(1, 8, 8, 8), #1,15,15,15\n",
    "                                                     baselines=0)\n",
    "            else:\n",
    "                attributions_occ = occlusion.attribute(img_test,\n",
    "                                                     strides=(1, 8, 8),\n",
    "                                                     target=0,\n",
    "                                                     sliding_window_shapes=(1, 8, 8), #1,15,15,15\n",
    "                                                     baselines=0)\n",
    "            if input_size == \"2D\":\n",
    "                fig, axs = viz.visualize_image_attr(np.transpose(attributions_ig.squeeze(0).cpu().detach().numpy(), (1, 2, 0)), #1,2,0\n",
    "                                       img_test.cpu().detach().numpy().transpose(2, 3, 1, 0)[:, :, :, 0], #2,3,1,0\n",
    "                                       method='heat_map',\n",
    "                                       cmap=default_cmap,\n",
    "                                       show_colorbar=False,\n",
    "                                       sign='positive',\n",
    "                                       outlier_perc=1)\n",
    "                #fig.savefig(f\"captum_results/XAI_3D/ig_{idx}_pred{pred}_real{real}_tumor{tumor}_prob{prob}.png\")\n",
    "                fig.savefig(f\"captum_results/XAI_{input_size}/{case}/ig_{idx}_pred{pred}_real{real}_prob{prob}.png\")\n",
    "                try:\n",
    "                    fig, axs = viz.visualize_image_attr_multiple(np.transpose(attributions_occ.squeeze(0).cpu().detach().numpy(), (1, 2, 0)),\n",
    "                                            img_test.cpu().detach().numpy().transpose(2, 3, 1, 0)[:, :, :, 0],\n",
    "                                            [\"original_image\", \"heat_map\"],\n",
    "                                            [\"all\", \"positive\"],\n",
    "                                            show_colorbar=False,\n",
    "                                            outlier_perc=2,\n",
    "                                            )\n",
    "                    #fig.savefig(f\"captum_results/XAI_3D/occ_{idx}_pred{pred}_real{real}_tumor{tumor}_prob{prob}.png\")\n",
    "                    fig.savefig(f\"captum_results/XAI_{input_size}/{case}/occ_{idx}_pred{pred}_real{real}_prob{prob}.png\")\n",
    "                except: \n",
    "                    print(\"Error in saving the occlusions\")\n",
    "                    continue\n",
    "            else:\n",
    "                fig, axs = viz.visualize_image_attr(np.transpose(attributions_ig.squeeze(0).cpu().detach().numpy(), (2, 3, 1, 0)), #1,2,0\n",
    "                                       img_test.cpu().detach().numpy().transpose(2, 3, 4, 1, 0)[sel_idx[idx], :, :, :, 0], #2,3,1,0\n",
    "                                       method='heat_map',\n",
    "                                       cmap=default_cmap,\n",
    "                                       show_colorbar=False,\n",
    "                                       sign='positive',\n",
    "                                       outlier_perc=1)\n",
    "                fig.savefig(f\"captum_results/XAI_{input_size}/{case}/ig_{idx}_pred{pred}_real{real}_prob{prob}.png\")\n",
    "                try:\n",
    "                    fig, axs = viz.visualize_image_attr_multiple(np.transpose(attributions_occ.squeeze(0).cpu().detach().numpy(), (2, 3, 1, 0)),\n",
    "                                            img_test.cpu().detach().numpy().transpose(2, 3, 4, 1, 0)[sel_idx[idx], :, :, :, 0],\n",
    "                                            [\"original_image\", \"heat_map\"],\n",
    "                                            [\"all\", \"positive\"],\n",
    "                                            show_colorbar=False,\n",
    "                                            outlier_perc=2,\n",
    "                                            )\n",
    "                    #fig.savefig(f\"captum_results/XAI_3D/occ_{idx}_pred{pred}_real{real}_tumor{tumor}_prob{prob}.png\")\n",
    "                    fig.savefig(f\"captum_results/XAI_{input_size}/{case}/occ_{idx}_pred{pred}_real{real}_prob{prob}.png\")\n",
    "                except:\n",
    "                    print(\"Error in saving the occlusions\")\n",
    "                    continue\n",
    "            #else:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411058ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = [\"AB\"]#[\"A\", \"A_B\", \"B\", \"B_A\", \"AB\"]\n",
    "input_sizes = [\"2D\"] #[\"2D\", \"3D\"]\n",
    "\n",
    "for input_size in input_sizes:\n",
    "    for case in cases:\n",
    "        print(f\"\\t{input_size} {case}\")\n",
    "        m_test_pred, ids, X, y, y_pred, y_prob, m_model = predict_with_case_and_size(case, input_size)\n",
    "        get_xai(case, input_size, m_test_pred, ids, X, y, y_pred, y_prob, m_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
